{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TabPFN Rolling-Origin Workflow (with FE Grid, corr-spec variants, and target-only on/off)\n",
    "\n",
    "This notebook runs Stage A (calibration) and Stage B (final) for TabPFN\n",
    "over a **feature-engineering grid** in `tuning.py`, across **correlation specs**\n",
    "(expanding vs EWMA) and **target-only blocks** (TSFresh + Chronos) on/off.\n",
    "\n",
    "**Prereqs:** Your repo layout with `src/` (config, tuning, io_timesplits, models) is available.\n",
    "TSFresh/Chronos parquet files exist when `use_target_blocks=True` is selected.\n",
    "\n",
    "> If `tabpfn` is missing in your env: `pip install tabpfn torch`.\n"
   ],
   "id": "e1bcb3c9227d73"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T11:51:16.621366Z",
     "start_time": "2025-10-20T11:51:15.935343Z"
    }
   },
   "source": [
    "# --- Setup & Imports ---\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Try to locate repo root that contains `src/`\n",
    "def _locate_repo_root(start: Path) -> Path:\n",
    "    cur = start.resolve()\n",
    "    for _ in range(5):  # walk up to 5 levels\n",
    "        if (cur / 'src').exists():\n",
    "            return cur\n",
    "        if cur.parent == cur:\n",
    "            break\n",
    "        cur = cur.parent\n",
    "    return start.resolve()\n",
    "\n",
    "\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "PROJECT_ROOT = _locate_repo_root(NOTEBOOK_DIR)\n",
    "os.environ['PROJECT_ROOT'] = str(PROJECT_ROOT)\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from src.config import GlobalConfig, DEFAULT_CORR_SPEC, outputs_for_model\n",
    "from src.tuning import run_stageA, run_stageB\n",
    "from src.io_timesplits import load_target, load_ifo_features\n",
    "from src.models.tabpfn import ForecastModel\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# Ensure base output structure exists – nur EIN Modellname:\n",
    "MODEL_NAME = \"tabpfn\"\n",
    "outputs_for_model(MODEL_NAME)\n",
    "print('PROJECT_ROOT =', PROJECT_ROOT)\n",
    "print('Imports ok. If `tabpfn` is missing: `pip install tabpfn torch`.')"
   ],
   "id": "11a52f1b0544642",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT = /Users/jonasschernich/Documents/Masterarbeit/Code\n",
      "Imports ok. If `tabpfn` is missing: `pip install tabpfn torch`.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T11:51:21.827076Z",
     "start_time": "2025-10-20T11:51:21.799796Z"
    }
   },
   "source": [
    "# --- Load data ---\n",
    "y = load_target()  # ΔIP with DatetimeIndex\n",
    "X = load_ifo_features()  # ifo panel\n",
    "\n",
    "idx = y.index.intersection(X.index)\n",
    "y, X = y.loc[idx], X.loc[idx]\n",
    "print('Shapes:', X.shape, y.shape)\n",
    "display(y.describe())\n"
   ],
   "id": "63c3f20c77cc53a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (407, 20) (407,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    407.000000\n",
       "mean       0.042741\n",
       "std        1.905304\n",
       "min      -18.219895\n",
       "25%       -0.822431\n",
       "50%        0.105485\n",
       "75%        1.063048\n",
       "max       10.000000\n",
       "Name: IP_change, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T11:51:24.676579Z",
     "start_time": "2025-10-20T11:51:24.672029Z"
    }
   },
   "source": [
    "# --- Corr-spec helper ---\n",
    "def make_corr_spec(kind: str, window: int = 60, lam: float = 0.98) -> dict:\n",
    "    spec = dict(DEFAULT_CORR_SPEC)\n",
    "    spec['mode'] = kind\n",
    "    if kind == 'expanding':\n",
    "        spec.pop('window', None)\n",
    "        spec.pop('lambda', None)\n",
    "    elif kind == 'ewm':\n",
    "        spec['window'] = int(window)\n",
    "        spec['lambda'] = float(lam)\n",
    "    else:\n",
    "        raise ValueError(\"kind must be 'expanding' or 'ewm'\")\n",
    "    return spec\n",
    "\n",
    "# Corr-Optionen werden Teil des HP-Grids:\n",
    "corr_options = [\n",
    "    (\"ewm_098\", make_corr_spec(\"ewm\", window=40, lam=0.98)),\n",
    "    (\"ewm_098\", make_corr_spec(\"ewm\", window=60, lam=0.96)),\n",
    "    (\"expanding\", make_corr_spec(\"expanding\")),\n",
    "]\n"
   ],
   "id": "babc41f3dda34332",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T11:51:26.786848Z",
     "start_time": "2025-10-20T11:51:26.782046Z"
    }
   },
   "source": [
    "# --- Base config (splits & policy as in thesis) ---\n",
    "def base_cfg() -> GlobalConfig:\n",
    "    cfg = GlobalConfig()\n",
    "    # Stage A/B rolling-origin splits\n",
    "    cfg.W0_A     = 180\n",
    "    cfg.BLOCKS_A = [(181,200), (201,220), (221,240)]\n",
    "    cfg.W0_B     = 240\n",
    "    # FE refresh cadence (months)\n",
    "    cfg.refresh_cadence = 12\n",
    "    cfg.policy_window   = 24\n",
    "    cfg.policy_decay    = 0.95\n",
    "    cfg.policy_gain_min = 0.03\n",
    "    cfg.policy_cooldown = 3\n",
    "    # Target-only blocks (TSFresh + Chronos Parquet) per Variante – hier standardmäßig aus:\n",
    "    cfg.use_target_blocks = True\n",
    "    return cfg\n",
    "\n",
    "cfg0 = base_cfg()\n",
    "cfg0\n"
   ],
   "id": "24d83bcd3e06f0d7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GlobalConfig(seed=123, refresh_cadence_months=12, corr_spec={'mode': 'expanding', 'window': None, 'lam': None}, lag_candidates=(1, 2, 3, 4, 5, 6, 7, 8, 9, 10), top_k_lags_per_feature=1, use_rm3=True, k1_topk=50, screen_threshold=None, redundancy_method='greedy', redundancy_param=0.9, dr_method='none', pca_var_target=0.95, pca_kmax=25, pls_components=2, W0_A=180, BLOCKS_A=[(181, 200), (201, 220), (221, 240)], W0_B=240, policy_window=24, policy_gain_min=0.03, policy_cooldown=3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T11:51:44.308525Z",
     "start_time": "2025-10-20T11:51:44.301546Z"
    }
   },
   "source": [
    "# --- FE/DR/Screening grid (corr steckt jetzt im HP) ---\n",
    "# EINE Konfiguration getestet wird.\n",
    "target_block_options = [\n",
    "    None,                       # 1. Nur Ifo-Features (Baseline)\n",
    "    [\"AR1\"],                    # 2. Ifo + AR1\n",
    "    [\"Chronos\"],                # 3. Ifo + Chronos\n",
    "    [\"TSFresh\"],                # 4. Ifo + TSFresh     # 6. Ifo + Chronos + TSFresh\n",
    "    [\"AR1\", \"TSFresh\", \"Chronos\"] # 7. Alle zusammen\n",
    "]\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "\n",
    "lag_sets = [\n",
    "    (1, 2, 3, 4, 6, 12),\n",
    "]\n",
    "topk_lags     = [1]\n",
    "use_rm3_flags = [True]\n",
    "k1_topk_vals  = [20]\n",
    "redund_params = [0.99]\n",
    "\n",
    "dr_options = [\n",
    "    {\"dr_method\": \"none\"},\n",
    "    {\"dr_method\": \"pca\", \"pca_var_target\": 0.9, \"pca_kmax\": 50},\n",
    "    {\"dr_method\": \"pls\", \"pls_components\": 4},\n",
    "]\n",
    "\n",
    "def build_model_grid():\n",
    "    hp_grid = []\n",
    "    for corr_tag, corr_spec in corr_options:\n",
    "        for L in lag_sets:\n",
    "            for k_top in topk_lags:\n",
    "                for rm3 in use_rm3_flags:\n",
    "                    for k1 in k1_topk_vals:\n",
    "                        for red in redund_params:\n",
    "                            for dr in dr_options:\n",
    "                                # --- NEUE SCHLEIFE für Target Blocks ---\n",
    "                                for block_set in target_block_options:\n",
    "                                    hp = {\n",
    "                                        'lag_candidates': L,\n",
    "                                        'top_k_lags_per_feature': k_top,\n",
    "                                        'use_rm3': rm3,\n",
    "                                        'k1_topk': k1,\n",
    "                                        'screen_threshold': None,\n",
    "                                        'redundancy_method': 'greedy',\n",
    "                                        'redundancy_param': red,\n",
    "\n",
    "                                        # TabPFN specifics\n",
    "                                        'use_gpu': False,          # set True if CUDA is stable\n",
    "                                        'posterior_samples': 8,\n",
    "\n",
    "                                        # Corr als HP:\n",
    "                                        'corr_tag': corr_tag,\n",
    "                                        'corr_spec': corr_spec,\n",
    "\n",
    "                                        # --- NEUER HP ---\n",
    "                                        'target_block_set': block_set,\n",
    "                                    }\n",
    "                                    hp.update(dr)\n",
    "                                    hp_grid.append(hp)\n",
    "    return hp_grid\n",
    "\n",
    "model_grid = build_model_grid()\n",
    "print(\"HP-Kombinationen:\", len(model_grid))\n"
   ],
   "id": "348dec271d84523a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HP-Kombinationen: 45\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T12:10:39.301834Z",
     "start_time": "2025-10-20T11:51:47.119694Z"
    }
   },
   "source": [
    "# --- Stage A/B: EIN Lauf, EIN Ordner ---\n",
    "shortlist = run_stageA(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_ctor=lambda hp: ForecastModel(hp),\n",
    "    model_grid=model_grid,\n",
    "    X=X, y=y, cfg=cfg0,\n",
    "    keep_top_k_final=4,\n",
    "    min_survivors_per_block=3,\n",
    ")\n",
    "\n",
    "run_stageB(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_ctor=lambda hp: ForecastModel(hp),\n",
    "    shortlist=shortlist,\n",
    "    X=X, y=y, cfg=cfg0,\n",
    "    # max_months=24,   # optional throttling\n",
    ")\n",
    "\n",
    "print(\"\\nDone. Check outputs/stageA|stageB/tabpfn for results.\")"
   ],
   "id": "ed7ba2fea78220d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Stage A][Block 1] train_end=180, OOS=181-200 | configs=45\n",
      "  - Config 1/45\n",
      "    · Month 5/20 processed | running...RMSE=1.6210\n",
      "    · Month 10/20 processed | running...RMSE=1.2966\n",
      "    · Month 15/20 processed | running...RMSE=1.2222\n",
      "    · Month 20/20 processed | running...RMSE=1.0928\n",
      "  - Config 2/45\n",
      "    · Month 5/20 processed | running...RMSE=1.6210\n",
      "    · Month 10/20 processed | running...RMSE=1.2966\n",
      "    · Month 15/20 processed | running...RMSE=1.2222\n",
      "    · Month 20/20 processed | running...RMSE=1.0928\n",
      "  - Config 3/45\n",
      "    · Month 5/20 processed | running...RMSE=1.6006\n",
      "    · Month 10/20 processed | running...RMSE=1.2716\n",
      "    · Month 15/20 processed | running...RMSE=1.2068\n",
      "    · Month 20/20 processed | running...RMSE=1.1161\n",
      "  - Config 4/45\n",
      "    · Month 5/20 processed | running...RMSE=1.4624\n",
      "    · Month 10/20 processed | running...RMSE=1.1710\n",
      "    · Month 15/20 processed | running...RMSE=1.1116\n",
      "    · Month 20/20 processed | running...RMSE=0.9822\n",
      "  - Config 5/45\n",
      "    · Month 5/20 processed | running...RMSE=1.5669\n",
      "    · Month 10/20 processed | running...RMSE=1.2454\n",
      "    · Month 15/20 processed | running...RMSE=1.1674\n",
      "    · Month 20/20 processed | running...RMSE=1.0579\n",
      "  - Config 6/45\n",
      "    · Month 5/20 processed | running...RMSE=1.6353\n",
      "    · Month 10/20 processed | running...RMSE=1.3098\n",
      "    · Month 15/20 processed | running...RMSE=1.2358\n",
      "    · Month 20/20 processed | running...RMSE=1.1082\n",
      "  - Config 7/45\n",
      "    · Month 5/20 processed | running...RMSE=1.6353\n",
      "    · Month 10/20 processed | running...RMSE=1.3098\n",
      "    · Month 15/20 processed | running...RMSE=1.2358\n",
      "    · Month 20/20 processed | running...RMSE=1.1082\n",
      "  - Config 8/45\n",
      "    · Month 5/20 processed | running...RMSE=1.5436\n",
      "    · Month 10/20 processed | running...RMSE=1.2620\n",
      "    · Month 15/20 processed | running...RMSE=1.2093\n",
      "    · Month 20/20 processed | running...RMSE=1.1467\n",
      "  - Config 9/45\n",
      "    · Month 5/20 processed | running...RMSE=1.3032\n",
      "    · Month 10/20 processed | running...RMSE=1.0318\n",
      "    · Month 15/20 processed | running...RMSE=0.9616\n",
      "    · Month 20/20 processed | running...RMSE=0.8754\n",
      "  - Config 10/45\n",
      "    · Month 5/20 processed | running...RMSE=1.4875\n",
      "    · Month 10/20 processed | running...RMSE=1.1683\n",
      "    · Month 15/20 processed | running...RMSE=1.0906\n",
      "    · Month 20/20 processed | running...RMSE=1.0036\n",
      "  - Config 11/45\n",
      "    · Month 5/20 processed | running...RMSE=1.5820\n",
      "    · Month 10/20 processed | running...RMSE=1.2724\n",
      "    · Month 15/20 processed | running...RMSE=1.2085\n",
      "    · Month 20/20 processed | running...RMSE=1.0877\n",
      "  - Config 12/45\n",
      "    · Month 5/20 processed | running...RMSE=1.5820\n",
      "    · Month 10/20 processed | running...RMSE=1.2724\n",
      "    · Month 15/20 processed | running...RMSE=1.2085\n",
      "    · Month 20/20 processed | running...RMSE=1.0877\n",
      "  - Config 13/45\n",
      "    · Month 5/20 processed | running...RMSE=1.3857\n",
      "    · Month 10/20 processed | running...RMSE=1.1067\n",
      "    · Month 15/20 processed | running...RMSE=1.0692\n",
      "    · Month 20/20 processed | running...RMSE=1.0063\n",
      "  - Config 14/45\n",
      "    · Month 5/20 processed | running...RMSE=1.3821\n",
      "    · Month 10/20 processed | running...RMSE=1.0760\n",
      "    · Month 15/20 processed | running...RMSE=1.0914\n",
      "    · Month 20/20 processed | running...RMSE=1.1052\n",
      "  - Config 15/45\n",
      "    · Month 5/20 processed | running...RMSE=1.6012\n",
      "    · Month 10/20 processed | running...RMSE=1.3501\n",
      "    · Month 15/20 processed | running...RMSE=1.2790\n",
      "    · Month 20/20 processed | running...RMSE=1.2477\n",
      "  - Config 16/45\n",
      "    · Month 5/20 processed | running...RMSE=1.6111\n",
      "    · Month 10/20 processed | running...RMSE=1.2861\n",
      "    · Month 15/20 processed | running...RMSE=1.2149\n",
      "    · Month 20/20 processed | running...RMSE=1.0877\n",
      "  - Config 17/45\n",
      "    · Month 5/20 processed | running...RMSE=1.6111\n",
      "    · Month 10/20 processed | running...RMSE=1.2861\n",
      "    · Month 15/20 processed | running...RMSE=1.2149\n",
      "    · Month 20/20 processed | running...RMSE=1.0877\n",
      "  - Config 18/45\n",
      "    · Month 5/20 processed | running...RMSE=1.4374\n",
      "    · Month 10/20 processed | running...RMSE=1.1296\n",
      "    · Month 15/20 processed | running...RMSE=1.1018\n",
      "    · Month 20/20 processed | running...RMSE=1.0301\n",
      "  - Config 19/45\n",
      "    · Month 5/20 processed | running...RMSE=1.4326\n",
      "    · Month 10/20 processed | running...RMSE=1.1568\n",
      "    · Month 15/20 processed | running...RMSE=1.1022\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[0;32m~/Documents/Masterarbeit/Code/src/models/tabpfn.py:69\u001B[0m, in \u001B[0;36mForecastModel.predict\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 69\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_reg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mposterior_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_posterior_samples\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     70\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py:81\u001B[0m, in \u001B[0;36mContextDecorator.__call__.<locals>.inner\u001B[0;34m(*args, **kwds)\u001B[0m\n\u001B[1;32m     80\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_recreate_cm():\n\u001B[0;32m---> 81\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn_common_utils/telemetry/core/decorators.py:242\u001B[0m, in \u001B[0;36mtrack_model_call.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    240\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    241\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m--> 242\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_safe_call_with_telemetry\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    243\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_method\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparam_names\u001B[49m\n\u001B[1;32m    244\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn_common_utils/telemetry/core/decorators.py:286\u001B[0m, in \u001B[0;36m_safe_call_with_telemetry\u001B[0;34m(func, args, kwargs, model_method, param_names)\u001B[0m\n\u001B[1;32m    285\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[0;32m--> 286\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    287\u001B[0m duration_ms \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m((time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m1000\u001B[39m)\n",
      "\u001B[0;31mTypeError\u001B[0m: TabPFNRegressor.predict() got an unexpected keyword argument 'posterior_samples'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# --- Stage A/B: EIN Lauf, EIN Ordner ---\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m shortlist \u001B[38;5;241m=\u001B[39m \u001B[43mrun_stageA\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mMODEL_NAME\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel_ctor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mhp\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mForecastModel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhp\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel_grid\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_grid\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcfg\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcfg0\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkeep_top_k_final\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmin_survivors_per_block\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m run_stageB(\n\u001B[1;32m     12\u001B[0m     model_name\u001B[38;5;241m=\u001B[39mMODEL_NAME,\n\u001B[1;32m     13\u001B[0m     model_ctor\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m hp: ForecastModel(hp),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     16\u001B[0m     \u001B[38;5;66;03m# max_months=24,   # optional throttling\u001B[39;00m\n\u001B[1;32m     17\u001B[0m )\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mDone. Check outputs/stageA|stageB/tabpfn for results.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/Masterarbeit/Code/src/tuning.py:415\u001B[0m, in \u001B[0;36mrun_stageA\u001B[0;34m(model_name, model_ctor, model_grid, X, y, cfg, keep_top_k_final, min_survivors_per_block)\u001B[0m\n\u001B[1;32m    412\u001B[0m     hp_by_key[key] \u001B[38;5;241m=\u001B[39m hp\n\u001B[1;32m    414\u001B[0m \u001B[38;5;66;03m# CSV-Exports pro Block\u001B[39;00m\n\u001B[0;32m--> 415\u001B[0m preds_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(preds_records)\n\u001B[1;32m    416\u001B[0m rmse_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(rmse_records)\n\u001B[1;32m    417\u001B[0m preds_path \u001B[38;5;241m=\u001B[39m rs\u001B[38;5;241m.\u001B[39mout_stageA \u001B[38;5;241m/\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mblock\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mblock_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m/\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpreds.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m~/Documents/Masterarbeit/Code/src/models/tabpfn.py:75\u001B[0m, in \u001B[0;36mForecastModel.predict_one\u001B[0;34m(self, x_row)\u001B[0m\n\u001B[1;32m     73\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict_one\u001B[39m(\u001B[38;5;28mself\u001B[39m, x_row):\n\u001B[1;32m     74\u001B[0m     x \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(x_row)\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m---> 75\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mfloat\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m])\n",
      "File \u001B[0;32m~/Documents/Masterarbeit/Code/src/models/tabpfn.py:71\u001B[0m, in \u001B[0;36mForecastModel.predict\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reg\u001B[38;5;241m.\u001B[39mpredict(X, posterior_samples\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_posterior_samples)\n\u001B[1;32m     70\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m---> 71\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_reg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py:81\u001B[0m, in \u001B[0;36mContextDecorator.__call__.<locals>.inner\u001B[0;34m(*args, **kwds)\u001B[0m\n\u001B[1;32m     78\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[1;32m     79\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds):\n\u001B[1;32m     80\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_recreate_cm():\n\u001B[0;32m---> 81\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn_common_utils/telemetry/core/decorators.py:242\u001B[0m, in \u001B[0;36mtrack_model_call.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    240\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    241\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m--> 242\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_safe_call_with_telemetry\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    243\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_method\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparam_names\u001B[49m\n\u001B[1;32m    244\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn_common_utils/telemetry/core/decorators.py:286\u001B[0m, in \u001B[0;36m_safe_call_with_telemetry\u001B[0;34m(func, args, kwargs, model_method, param_names)\u001B[0m\n\u001B[1;32m    284\u001B[0m \u001B[38;5;66;03m# Step 2: Run the actual function\u001B[39;00m\n\u001B[1;32m    285\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[0;32m--> 286\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    287\u001B[0m duration_ms \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m((time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m1000\u001B[39m)\n\u001B[1;32m    289\u001B[0m \u001B[38;5;66;03m# Step 3: Send telemetry event\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/regressor.py:870\u001B[0m, in \u001B[0;36mTabPFNRegressor.predict\u001B[0;34m(self, X, output_type, quantiles)\u001B[0m\n\u001B[1;32m    863\u001B[0m X \u001B[38;5;241m=\u001B[39m process_text_na_dataframe(X, ord_encoder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreprocessor_)  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m    865\u001B[0m \u001B[38;5;66;03m# Runs over iteration engine\u001B[39;00m\n\u001B[1;32m    866\u001B[0m (\n\u001B[1;32m    867\u001B[0m     _,\n\u001B[1;32m    868\u001B[0m     outputs,  \u001B[38;5;66;03m# list of tensors [N_est, N_samples, N_borders] (after forward)\u001B[39;00m\n\u001B[1;32m    869\u001B[0m     borders,  \u001B[38;5;66;03m# list of numpy arrays containing borders for each estimator\u001B[39;00m\n\u001B[0;32m--> 870\u001B[0m ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_inference_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    872\u001B[0m \u001B[38;5;66;03m# --- Translate probs, average, get final logits ---\u001B[39;00m\n\u001B[1;32m    873\u001B[0m transformed_logits \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    874\u001B[0m     translate_probs_across_borders(\n\u001B[1;32m    875\u001B[0m         logits,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    879\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m logits, borders_t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(outputs, borders)\n\u001B[1;32m    880\u001B[0m ]\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/regressor.py:998\u001B[0m, in \u001B[0;36mTabPFNRegressor.forward\u001B[0;34m(self, X, use_inference_mode)\u001B[0m\n\u001B[1;32m    995\u001B[0m borders: \u001B[38;5;28mlist\u001B[39m[np\u001B[38;5;241m.\u001B[39mndarray] \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    997\u001B[0m \u001B[38;5;66;03m# Iterate over estimators\u001B[39;00m\n\u001B[0;32m--> 998\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43moutput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecutor_\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miter_outputs\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    999\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1000\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevices\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevices_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1001\u001B[0m \u001B[43m    \u001B[49m\u001B[43mautocast\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43muse_autocast_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1002\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m   1003\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msoftmax_temperature\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m!=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m:\u001B[49m\n\u001B[1;32m   1004\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43moutput\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msoftmax_temperature\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# noqa: PLW2901\u001B[39;49;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/inference.py:507\u001B[0m, in \u001B[0;36mInferenceEngineCachePreprocessing.iter_outputs\u001B[0;34m(self, X, devices, autocast, only_return_standard_out)\u001B[0m\n\u001B[1;32m    491\u001B[0m model_forward_functions \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    492\u001B[0m     partial(\n\u001B[1;32m    493\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_model,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    503\u001B[0m     )\n\u001B[1;32m    504\u001B[0m )\n\u001B[1;32m    505\u001B[0m outputs \u001B[38;5;241m=\u001B[39m parallel_execute(devices, model_forward_functions)\n\u001B[0;32m--> 507\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43moutput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mzip\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mensemble_configs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m    508\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m_move_and_squeeze_output\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevices\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\n\u001B[1;32m    510\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minference_mode:\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/parallel_execute.py:58\u001B[0m, in \u001B[0;36mparallel_execute\u001B[0;34m(devices, functions)\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Evaluate the given functions in parallel across `devices`.\u001B[39;00m\n\u001B[1;32m     40\u001B[0m \n\u001B[1;32m     41\u001B[0m \u001B[38;5;124;03mThe function evaluations are parallelised using Python threads, so this will only\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;124;03m    as `functions`.\u001B[39;00m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(devices) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m     57\u001B[0m     \u001B[38;5;66;03m# If we only have one device then just use the current thread to avoid overhead.\u001B[39;00m\n\u001B[0;32m---> 58\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m _execute_in_current_thread(devices[\u001B[38;5;241m0\u001B[39m], functions)\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m _execute_with_multithreading(devices, functions)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/parallel_execute.py:67\u001B[0m, in \u001B[0;36m_execute_in_current_thread\u001B[0;34m(device, functions)\u001B[0m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_execute_in_current_thread\u001B[39m(\n\u001B[1;32m     64\u001B[0m     device: torch\u001B[38;5;241m.\u001B[39mdevice, functions: Iterable[ParallelFunction[R_co]]\n\u001B[1;32m     65\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Generator[R_co]:\n\u001B[1;32m     66\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m function \u001B[38;5;129;01min\u001B[39;00m functions:\n\u001B[0;32m---> 67\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_parallel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/inference.py:555\u001B[0m, in \u001B[0;36mInferenceEngineCachePreprocessing._call_model\u001B[0;34m(self, device, is_parallel, X_train, X_test, y_train, cat_ix, autocast, only_return_standard_out)\u001B[0m\n\u001B[1;32m    541\u001B[0m     MemoryUsageEstimator\u001B[38;5;241m.\u001B[39mreset_peak_memory_if_required(\n\u001B[1;32m    542\u001B[0m         save_peak_mem\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msave_peak_mem,\n\u001B[1;32m    543\u001B[0m         model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    548\u001B[0m         safety_factor\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1.2\u001B[39m,\n\u001B[1;32m    549\u001B[0m     )\n\u001B[1;32m    551\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m (\n\u001B[1;32m    552\u001B[0m     get_autocast_context(device, enabled\u001B[38;5;241m=\u001B[39mautocast),\n\u001B[1;32m    553\u001B[0m     torch\u001B[38;5;241m.\u001B[39minference_mode(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minference_mode),\n\u001B[1;32m    554\u001B[0m ):\n\u001B[0;32m--> 555\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    556\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX_full\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    557\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    558\u001B[0m \u001B[43m        \u001B[49m\u001B[43monly_return_standard_out\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43monly_return_standard_out\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    559\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcategorical_inds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatched_cat_ix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    560\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/architectures/base/transformer.py:549\u001B[0m, in \u001B[0;36mPerFeatureTransformer.forward\u001B[0;34m(***failed resolving arguments***)\u001B[0m\n\u001B[1;32m    541\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    542\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThere should be no NaNs in the encoded x and y.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    543\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCheck that you do not feed NaNs or use a NaN-handling enocder.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    544\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYour embedded x and y returned the following:\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    545\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtorch\u001B[38;5;241m.\u001B[39misnan(embedded_x)\u001B[38;5;241m.\u001B[39many()\u001B[38;5;132;01m=}\u001B[39;00m\u001B[38;5;124m | \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtorch\u001B[38;5;241m.\u001B[39misnan(embedded_y)\u001B[38;5;241m.\u001B[39many()\u001B[38;5;132;01m=}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    546\u001B[0m     )\n\u001B[1;32m    547\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m embedded_y, embedded_x\n\u001B[0;32m--> 549\u001B[0m encoder_out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransformer_encoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    550\u001B[0m \u001B[43m    \u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    551\u001B[0m \u001B[43m        \u001B[49m\u001B[43membedded_input\u001B[49m\n\u001B[1;32m    552\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransformer_decoder\u001B[49m\n\u001B[1;32m    553\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43membedded_input\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43msingle_eval_pos\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m    554\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    555\u001B[0m \u001B[43m    \u001B[49m\u001B[43msingle_eval_pos\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msingle_eval_pos\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    556\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache_trainset_representation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcache_trainset_representation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    557\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# b s f+1 e -> b s f+1 e\u001B[39;00m\n\u001B[1;32m    559\u001B[0m \u001B[38;5;66;03m# If we are using a decoder\u001B[39;00m\n\u001B[1;32m    560\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransformer_decoder:\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/architectures/base/transformer.py:94\u001B[0m, in \u001B[0;36mLayerStack.forward\u001B[0;34m(self, x, **kwargs)\u001B[0m\n\u001B[1;32m     92\u001B[0m         x \u001B[38;5;241m=\u001B[39m checkpoint(partial(layer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs), x, use_reentrant\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m     93\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 94\u001B[0m         x \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     96\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/architectures/base/layer.py:421\u001B[0m, in \u001B[0;36mPerFeatureEncoderLayer.forward\u001B[0;34m(self, state, single_eval_pos, cache_trainset_representation, att_src)\u001B[0m\n\u001B[1;32m    411\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[1;32m    412\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPre-norm implementation is wrong, as the residual should never\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    413\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m be layer normed here.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    414\u001B[0m     )\n\u001B[1;32m    415\u001B[0m     state \u001B[38;5;241m=\u001B[39m layer_norm(\n\u001B[1;32m    416\u001B[0m         state,\n\u001B[1;32m    417\u001B[0m         allow_inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    418\u001B[0m         save_peak_mem_factor\u001B[38;5;241m=\u001B[39msave_peak_mem_factor,\n\u001B[1;32m    419\u001B[0m     )\n\u001B[0;32m--> 421\u001B[0m state \u001B[38;5;241m=\u001B[39m \u001B[43msublayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    422\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpre_norm:\n\u001B[1;32m    423\u001B[0m     state \u001B[38;5;241m=\u001B[39m layer_norm(\n\u001B[1;32m    424\u001B[0m         state,\n\u001B[1;32m    425\u001B[0m         allow_inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    426\u001B[0m         save_peak_mem_factor\u001B[38;5;241m=\u001B[39msave_peak_mem_factor,\n\u001B[1;32m    427\u001B[0m     )\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/architectures/base/mlp.py:132\u001B[0m, in \u001B[0;36mMLP.forward\u001B[0;34m(self, x, add_input, allow_inplace, save_peak_mem_factor)\u001B[0m\n\u001B[1;32m    130\u001B[0m input_shape \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mshape\n\u001B[1;32m    131\u001B[0m x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, x\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m))\n\u001B[0;32m--> 132\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_compute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    133\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    134\u001B[0m \u001B[43m    \u001B[49m\u001B[43madd_input\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43madd_input\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    135\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_inplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_inplace\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    136\u001B[0m \u001B[43m    \u001B[49m\u001B[43msave_peak_mem_factor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msave_peak_mem_factor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    137\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    138\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x\u001B[38;5;241m.\u001B[39mreshape(input_shape)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/architectures/base/memory.py:95\u001B[0m, in \u001B[0;36msupport_save_peak_mem_factor.<locals>.method_\u001B[0;34m(self, x, add_input, allow_inplace, save_peak_mem_factor, *args, **kwargs)\u001B[0m\n\u001B[1;32m     93\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m x_, \u001B[38;5;241m*\u001B[39margs_ \u001B[38;5;129;01min\u001B[39;00m split_args:\n\u001B[1;32m     94\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m add_input:\n\u001B[0;32m---> 95\u001B[0m         x_[:] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     96\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     97\u001B[0m         x_[:] \u001B[38;5;241m=\u001B[39m method(\u001B[38;5;28mself\u001B[39m, x_, \u001B[38;5;241m*\u001B[39margs_, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/architectures/base/mlp.py:97\u001B[0m, in \u001B[0;36mMLP._compute\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     95\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlinear1(x)\n\u001B[1;32m     96\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mactivation \u001B[38;5;129;01mis\u001B[39;00m Activation\u001B[38;5;241m.\u001B[39mGELU:\n\u001B[0;32m---> 97\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunctional\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgelu\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     98\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mactivation \u001B[38;5;129;01mis\u001B[39;00m Activation\u001B[38;5;241m.\u001B[39mRELU:\n\u001B[1;32m     99\u001B[0m     x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mfunctional\u001B[38;5;241m.\u001B[39mrelu(x)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
