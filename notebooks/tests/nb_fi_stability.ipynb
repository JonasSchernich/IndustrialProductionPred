{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# === Chunk 1: Setup & Daten laden ===\n",
    "# (Dieser Chunk lädt die ROHE Feature Importance)\n",
    "\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings  # KORREKTUR: Fehlender Import\n",
    "import pingouin as pg\n",
    "warnings.filterwarnings('ignore') # Jetzt funktioniert dieser Aufruf\n",
    "\n",
    "# --- 1. Pfad-Setup (Standard-Snippet) ---\n",
    "def _locate_repo_root(start: Path) -> Path:\n",
    "    cur = start.resolve()\n",
    "    for _ in range(5):  # walk up to 5 levels\n",
    "        if (cur / 'src').exists():\n",
    "            return cur\n",
    "        if cur.parent == cur: break\n",
    "        cur = cur.parent\n",
    "    return start.resolve()\n",
    "\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "PROJECT_ROOT = _locate_repo_root(NOTEBOOK_DIR)\n",
    "os.environ['PROJECT_ROOT'] = str(PROJECT_ROOT)\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "try:\n",
    "    # WICHTIG: _full_df laden! (benötigt angepasstes io_timesplits.py)\n",
    "    from src.io_timesplits import load_fi_full_df\n",
    "except ImportError:\n",
    "    print(\"FEHLER: src-Module nicht gefunden. Stellen Sie sicher, dass 'src' im PROJECT_ROOT liegt.\")\n",
    "    # Fallback für den Fall, dass der Pfad manuell gesetzt werden muss\n",
    "    PROJECT_ROOT = Path.cwd().parent  # Passen Sie dies bei Bedarf an\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "    from src.io_timesplits import load_fi_full_df\n",
    "\n",
    "# --- 2. Daten laden ---\n",
    "try:\n",
    "    # fi_full_df.parquet enthält die rohen, monatlichen Wichtigkeiten\n",
    "    df_fi_raw = load_fi_full_df()\n",
    "    print(f\"Rohe FI-Daten geladen: {df_fi_raw.shape}\")\n",
    "    display(df_fi_raw.head())\n",
    "except FileNotFoundError:\n",
    "    print(\"FEHLER: 'outputs/feature_importance/fi_full_df.parquet' nicht gefunden.\")\n",
    "    print(\"Bitte führen Sie zuerst 'feature_importance.ipynb' aus.\")\n",
    "\n",
    "# Wir fokussieren uns auf die Konsens-Wichtigkeit\n",
    "df_fi = df_fi_raw[[\"t\", \"feature\", \"importance_consensus\"]].copy()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# === Chunk 2: Top-K Features identifizieren ===\n",
    "# (Basierend auf der DURCHSCHNITTLICHEN Wichtigkeit)\n",
    "\n",
    "K = 20  # Anzahl der Top-Features, die wir tracken wollen\n",
    "\n",
    "# Berechne durchschnittliche Wichtigkeit über alle Zeiten\n",
    "mean_importance = df_fi.groupby(\"feature\")[\"importance_consensus\"].mean()\n",
    "top_k_features = mean_importance.nlargest(K).index.tolist()\n",
    "\n",
    "print(f\"Top {K} Features (basierend auf Ø-Wichtigkeit):\")\n",
    "print(top_k_features)"
   ],
   "id": "ec2eb67cd10458f8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# === Chunk 3: Rang-Berechnung & Stabilitäts-Plot (\"Spaghetti-Plot\") (KORRIGIERT) ===\n",
    "\n",
    "# KORREKTUR: Rang über den *gesamten* monatlichen Datensatz berechnen,\n",
    "# DANN filtern. Das gibt den \"wahren\" Rang und behebt die\n",
    "# Inkonsistenz zwischen Code und Kommentar.\n",
    "\n",
    "# 1. Berechne den Rang über ALLE Features für jeden Monat\n",
    "# (ascending=False -> hohe Wichtigkeit = niedriger Rang)\n",
    "df_fi[\"rank\"] = df_fi.groupby(\"t\")[\"importance_consensus\"].rank(ascending=False, method=\"min\")\n",
    "\n",
    "# 2. Filtere den DataFrame auf die K Features, die uns interessieren\n",
    "df_top_k_ranks = df_fi[df_fi[\"feature\"].isin(top_k_features)]\n",
    "\n",
    "# 3. Pivot für Plot\n",
    "df_pivot = df_top_k_ranks.pivot(index=\"t\", columns=\"feature\", values=\"rank\")\n",
    "\n",
    "# 4. Plot\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.lineplot(data=df_pivot, dashes=False, legend=\"full\")\n",
    "plt.title(f\"Rolling Rank Stability (Top {K} Features)\", fontsize=16)\n",
    "plt.ylabel(\"Wichtigkeits-Rang (Niedriger ist besser)\")\n",
    "plt.xlabel(\"Zeit\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.gca().invert_yaxis() # Niedrige Ränge (z.B. 1) oben\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ],
   "id": "168ea032de3425e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# === Chunk 4: Deskriptive Stabilitätsmetrik (Rang-StdAbw) ===\n",
    "\n",
    "# Berechne die Standardabweichung des Rangs für jedes Feature\n",
    "# (Verwendet das gepivotete df_pivot aus dem vorherigen Chunk)\n",
    "rank_stability = df_pivot.std().sort_values(ascending=True)\n",
    "\n",
    "print(f\"Stabilität der Top-{K} Features (StdAbw des Rangs):\")\n",
    "print(\"(Niedriger Wert = Stabiler)\")\n",
    "display(rank_stability.to_frame(\"Rank_StdDev\"))"
   ],
   "id": "e826b3d3542953b9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# === Chunk 5: Formaler Konkordanz-Test (Kendall's W) ===\n",
    "\n",
    "# 1. Pivot auf Wichtigkeit (nicht Rang) für die Top-K Features\n",
    "df_pivot_imp = df_top_k_ranks.pivot(index=\"t\", columns=\"feature\", values=\"importance_consensus\").fillna(0)\n",
    "\n",
    "# 2. Resample in Blöcke (z.B. 2-Jahres-Blöcke)\n",
    "# '2A' = 2 Jahre (endet am Jahresende), 'mean()' = durchschnittliche Wichtigkeit in dem Block\n",
    "df_blocks = df_pivot_imp.resample(\"2A\").mean().dropna()\n",
    "\n",
    "# 3. Berechne Kendall's W\n",
    "# `pg.kendall_w` erwartet Daten im Format: Subjekte (Features) x Rater (Zeitblöcke)\n",
    "# Wir müssen transponieren\n",
    "df_blocks_t = df_blocks.transpose()\n",
    "\n",
    "w_test = pg.kendall_w(data=df_blocks_t)\n",
    "\n",
    "print(f\"Kendall's W (Konkordanz der Feature-Wichtigkeit über {len(df_blocks)} Zeitblöcke)\")\n",
    "print(f\"W: {w_test['W'].item():.4f}\")\n",
    "print(f\"p-Wert: {w_test['pval'].item():.4f}\")\n",
    "\n",
    "# Interpretation:\n",
    "# W nahe 1: Perfekte Übereinstimmung (Features sind immer gleich wichtig)\n",
    "# W nahe 0: Keine Übereinstimmung (Chaos)"
   ],
   "id": "2133c645ccf4db29"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
