{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Imports (global)\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.cluster.hierarchy import linkage, leaves_list\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "# Output dir: <notebook_folder>/figures\n",
    "try:\n",
    "    import ipynbname  # optional\n",
    "\n",
    "    _NB_DIR = Path(ipynbname.path()).parent\n",
    "except Exception:\n",
    "    _NB_DIR = Path.cwd()\n",
    "\n",
    "OUT_DIR = _NB_DIR / \"figures\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Notebook dir:\", _NB_DIR)\n",
    "print(\"Figures dir:\", OUT_DIR)\n"
   ],
   "id": "17d5d4a0bdc821b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data profiling – missingness & correlations\n",
    "This notebook builds a panel from raw Excel files and analyzes missingness, correlations, and relationships to industrial production (IP).\n"
   ],
   "id": "51972ce993cb43f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## 1) Helpers: date parsing & missingness patterns\n",
    "def _to_month_start(ts):\n",
    "    if pd.isna(ts): return pd.NaT\n",
    "    ts = pd.Timestamp(ts)\n",
    "    return pd.Timestamp(ts.year, ts.month, 1)\n",
    "\n",
    "DOT_DDMMYY = re.compile(r'^\\s*\\d{2}\\.\\d{2}\\.(\\d{2}|\\d{4})\\s*$')\n",
    "\n",
    "def parse_month(x):\n",
    "    if pd.isna(x): return pd.NaT\n",
    "    if isinstance(x, (int, float)) and not np.isnan(x):\n",
    "        return _to_month_start(pd.to_datetime(x, unit='d', origin='1899-12-30', errors='coerce'))\n",
    "    s = str(x).strip()\n",
    "    if DOT_DDMMYY.fullmatch(s):\n",
    "        return _to_month_start(pd.to_datetime(s, dayfirst=True, errors='coerce'))\n",
    "    if re.fullmatch(r\"\\d{2}[./]\\d{4}\", s):\n",
    "        return _to_month_start(pd.to_datetime(s.replace(\".\", \"/\"), format=\"%m/%Y\", errors=\"coerce\"))\n",
    "    if re.fullmatch(r\"\\d{4}[./]\\d{2}\", s):\n",
    "        y, m = re.split(r\"[./]\", s); return pd.Timestamp(int(y), int(m), 1)\n",
    "    if re.fullmatch(r\"\\d{4}\", s):\n",
    "        return pd.Timestamp(int(s), 1, 1)\n",
    "    dt = pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
    "    return _to_month_start(dt) if pd.notna(dt) else pd.NaT\n",
    "\n",
    "def missing_pattern_report(df: pd.DataFrame):\n",
    "    lead_flags, trail_flags, mid_flags, any_flags, only_flags = [], [], [], [], []\n",
    "\n",
    "    for c in df.columns:\n",
    "        a = df[c].isna().to_numpy()\n",
    "\n",
    "        if not a.any():\n",
    "            lead_flags.append(False)\n",
    "            trail_flags.append(False)\n",
    "            mid_flags.append(False)\n",
    "            any_flags.append(False)\n",
    "            only_flags.append(False)\n",
    "            continue\n",
    "\n",
    "        if a.all():\n",
    "            only_flags.append(True)\n",
    "        else:\n",
    "            only_flags.append(False)\n",
    "\n",
    "        lead = 0\n",
    "        for v in a:\n",
    "            if v: lead += 1\n",
    "            else: break\n",
    "\n",
    "        trail = 0\n",
    "        for v in a[::-1]:\n",
    "            if v: trail += 1\n",
    "            else: break\n",
    "\n",
    "        mid = a[lead:len(a)-trail].any() if (lead+trail) < len(a) else False\n",
    "\n",
    "        lead_flags.append(lead > 0)\n",
    "        trail_flags.append(trail > 0)\n",
    "        mid_flags.append(mid)\n",
    "        any_flags.append(True)\n",
    "\n",
    "    lead_flags = np.array(lead_flags)\n",
    "    trail_flags = np.array(trail_flags)\n",
    "    mid_flags = np.array(mid_flags)\n",
    "    any_flags = np.array(any_flags)\n",
    "    only_flags = np.array(only_flags)\n",
    "\n",
    "    return {\n",
    "        \"completely_NA\": int(np.sum(only_flags)),\n",
    "        \"leading_only\": int(np.sum(lead_flags & ~trail_flags & ~mid_flags & ~only_flags)),\n",
    "        \"trailing_only\": int(np.sum(trail_flags & ~lead_flags & ~mid_flags & ~only_flags)),\n",
    "        \"mid_only\": int(np.sum(mid_flags & ~lead_flags & ~trail_flags & ~only_flags)),\n",
    "        \"leading_and_trailing\": int(np.sum(lead_flags & trail_flags & ~mid_flags & ~only_flags)),\n",
    "        \"leading_and_mid\": int(np.sum(lead_flags & mid_flags & ~trail_flags & ~only_flags)),\n",
    "        \"trailing_and_mid\": int(np.sum(trail_flags & mid_flags & ~lead_flags & ~only_flags)),\n",
    "        \"leading_trailing_mid\": int(np.sum(lead_flags & trail_flags & mid_flags & ~only_flags)),\n",
    "        \"any_NA\": int(np.sum(any_flags)),\n",
    "    }"
   ],
   "id": "72765f7674eb106c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2) Build panel from raw Excel files",
   "id": "b1716f0fcc6a7e08"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "DATA_DIR = pathlib.Path(\"../../data/raw/features\")\n",
    "files = sorted(map(pathlib.Path, glob.glob(str(DATA_DIR / \"bdi1a_*.xlsx\"))))\n",
    "if not files:\n",
    "    raise FileNotFoundError(\"No bdi1a_*.xlsx files found\")\n",
    "\n",
    "long_frames = []\n",
    "for p in files:\n",
    "    df = pd.read_excel(p, skiprows=2, engine=\"openpyxl\")\n",
    "    date_col = df.columns[0]\n",
    "    df = df.rename(columns={date_col: \"date\"})\n",
    "    df[\"date\"] = df[\"date\"].map(parse_month)\n",
    "    long_frames.append(df.melt(id_vars=\"date\", var_name=\"title_raw\", value_name=\"value\"))\n",
    "\n",
    "panel_long = pd.concat(long_frames, ignore_index=True).dropna(subset=[\"date\"])\n",
    "\n",
    "full_df = panel_long.pivot_table(\n",
    "    index=\"date\", columns=\"title_raw\", values=\"value\", aggfunc=\"last\", dropna=False\n",
    ")\n",
    "full_df.index = pd.to_datetime(full_df.index, errors=\"coerce\").to_period(\"M\").to_timestamp()\n",
    "full_df = full_df[~full_df.index.duplicated(keep=\"last\")]\n",
    "\n",
    "print(\"Full merged shape:\", full_df.shape)\n",
    "\n",
    "report = missing_pattern_report(full_df)\n",
    "print(\"Missingness report (columns):\")\n",
    "for k, v in report.items():\n",
    "    print(f\"{k}: {v}\")"
   ],
   "id": "a675d82b9ced7fd6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3) Paths & global settings",
   "id": "6035e8727c1de19e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "features_file = \"../../data/processed/features.csv\"  # all features incl. missing\n",
    "target_file   = \"../../data/processed/target.csv\"    # IP (level + change?)\n",
    "\n",
    "industry_whitelist = [\n",
    "    # \"Verarbeitendes_Gewerbe\",\n",
    "    # \"Herstellung_von_Investitionsgütern\",\n",
    "]\n",
    "\n",
    "rm_window = 12  # months"
   ],
   "id": "f810665126aa48ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4) Target diagnostics: stationarity tests",
   "id": "d1316f4e82dd4e6d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(target_file, parse_dates=[\"date\"])\n",
    "mom = df[\"IP_change\"].dropna()\n",
    "print(\"Mean:\", mom.mean())\n",
    "print(\"Variance:\", mom.var())\n",
    "\n",
    "def adf_test(series, title=''):\n",
    "    result = adfuller(series.dropna())\n",
    "    print(f\"--- {title} ---\")\n",
    "    print(\"ADF statistic:\", result[0])\n",
    "    print(\"p-value:\", result[1])\n",
    "    for key, value in result[4].items():\n",
    "        print(f\"Critical value {key}: {value}\")\n",
    "    print()\n",
    "\n",
    "adf_test(df[\"IP\"], \"IP (Level)\")\n",
    "adf_test(df[\"IP_change\"], \"IP_change (MoM)\")\n",
    "adf_test(df[\"IP_yoy\"], \"IP_yoy (YoY)\")"
   ],
   "id": "895c3436ad76e4ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5) Feature naming: canonical question types & splitting",
   "id": "9f8c91a92de996ed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "QUESTION_CANON = [\n",
    "    \"auftragsbestand_beurteilung\",\n",
    "    \"auftragsbestand_beurteilung_export\",\n",
    "    \"auftragsbestand_gegen_vormonat\",\n",
    "    \"beschaeftigtenerwartungen\",\n",
    "    \"exporterwartungen\",\n",
    "    \"fertigwarenlager_beurteilung\",\n",
    "    \"geschaeftsklima\",\n",
    "    \"geschaeftslage_beurteilung\",\n",
    "    \"geschaeftslage_erwartungen\",\n",
    "    \"nachfrage_gegen_vormonat\",\n",
    "    \"preise_gegen_vormonat\",\n",
    "    \"preiserwartungen\",\n",
    "    \"produktion_gegen_vormonat\",\n",
    "    \"produktionsplaene\",\n",
    "    \"produktivitaetserwartungen\"\n",
    "]\n",
    "\n",
    "def _slug(s: str) -> str:\n",
    "    s = s.lower()\n",
    "    s = (s.replace(\"ä\",\"ae\").replace(\"ö\",\"oe\").replace(\"ü\",\"ue\").replace(\"ß\",\"ss\")\n",
    "           .replace(\" \", \"_\").replace(\"-\", \"_\"))\n",
    "    s = re.sub(r\"[^a-z0-9_\\.]+\", \"\", s)\n",
    "    s = re.sub(r\"\\.+\", \".\", s)\n",
    "    s = re.sub(r\"_+\", \"_\", s)\n",
    "    return s.strip(\"._\")\n",
    "\n",
    "def split_norm(col: str):\n",
    "    s = _slug(col)\n",
    "    for q in QUESTION_CANON:\n",
    "        if s.endswith(\".\" + q):\n",
    "            ind = s[:-(len(q)+1)].strip(\"._\")\n",
    "            return ind, q\n",
    "        if s.endswith(q):\n",
    "            before = s[:-(len(q))]\n",
    "            if before.endswith(\".\"):\n",
    "                ind = before[:-1].strip(\"._\")\n",
    "                return ind, q\n",
    "    if \".\" in s:\n",
    "        ind, qraw = s.rsplit(\".\", 1)\n",
    "        q = re.sub(r\"^(?:\\d+\\.|n\\.?g\\.?|ng\\.?)+\", \"\", qraw)\n",
    "        q = q.strip(\"._\")\n",
    "        return ind.strip(\"._\"), q\n",
    "    return \"\", s"
   ],
   "id": "e7750de911b609c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6) Load processed features/targets and align time index",
   "id": "d8450e541b5dde89"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def _read_timeseries_csv(path):\n",
    "    df = pd.read_csv(path)\n",
    "    if 'date' in df.columns:\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df = df.set_index('date')\n",
    "    else:\n",
    "        df.iloc[:,0] = pd.to_datetime(df.iloc[:,0])\n",
    "        df = df.set_index(df.columns[0])\n",
    "    return df.sort_index()\n",
    "\n",
    "X_full = _read_timeseries_csv(features_file)\n",
    "y_df   = _read_timeseries_csv(target_file)\n",
    "\n",
    "X_original = _read_timeseries_csv(\"../../data/processed/features.csv\")\n",
    "\n",
    "X_original_NA_cutted = X_original.copy()\n",
    "while X_original_NA_cutted.iloc[0].isna().any():\n",
    "    X_original_NA_cutted = X_original_NA_cutted.iloc[1:]\n",
    "while X_original_NA_cutted.iloc[-1].isna().any():\n",
    "    X_original_NA_cutted = X_original_NA_cutted.iloc[:-1]\n",
    "\n",
    "y_cols = list(y_df.columns)\n",
    "if len(y_cols) >= 2:\n",
    "    y_level  = y_df.iloc[:,0].astype(float)\n",
    "    y_change = y_df.iloc[:,1].astype(float)\n",
    "else:\n",
    "    y_level  = y_df.iloc[:,0].astype(float)\n",
    "    y_change = y_level.diff()\n",
    "\n",
    "if industry_whitelist:\n",
    "    wl = set(industry_whitelist)\n",
    "    keep = [c for c in X_full.columns if c.split('.',1)[0] in wl]\n",
    "    X_full = X_full[keep]\n",
    "    X_original = X_original[keep]\n",
    "    X_original_NA_cutted = X_original_NA_cutted[keep]\n",
    "    print(f\"Filtered columns: {len(keep)}\")\n",
    "\n",
    "idx = X_full.index.intersection(y_df.index)\n",
    "X_full = X_full.loc[idx]\n",
    "y_level = y_level.loc[idx]\n",
    "y_change = y_change.loc[idx]\n",
    "\n",
    "print(\"X_full\", X_full.shape, \"y_change\", y_change.shape)\n",
    "print(\"X_original_NA_cutted\", X_original_NA_cutted.shape)\n"
   ],
   "id": "890bdb1831ff9441",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 7) Missingness summary on X_full",
   "id": "614ee6e4794c1753"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def missing_pattern_report(df: pd.DataFrame):\n",
    "    lead_flags, trail_flags, mid_flags, any_flags = [], [], [], []\n",
    "\n",
    "    for c in df.columns:\n",
    "        a = df[c].isna().to_numpy()\n",
    "        if not a.any():\n",
    "            lead_flags.append(False)\n",
    "            trail_flags.append(False)\n",
    "            mid_flags.append(False)\n",
    "            any_flags.append(False)\n",
    "            continue\n",
    "\n",
    "        lead = 0\n",
    "        for v in a:\n",
    "            if v: lead += 1\n",
    "            else: break\n",
    "\n",
    "        trail = 0\n",
    "        for v in a[::-1]:\n",
    "            if v: trail += 1\n",
    "            else: break\n",
    "\n",
    "        mid = a[lead:len(a)-trail].any() if (lead+trail) < len(a) else False\n",
    "\n",
    "        lead_flags.append(lead > 0)\n",
    "        trail_flags.append(trail > 0)\n",
    "        mid_flags.append(mid)\n",
    "        any_flags.append(True)\n",
    "\n",
    "    lead_flags = np.array(lead_flags)\n",
    "    trail_flags = np.array(trail_flags)\n",
    "    mid_flags = np.array(mid_flags)\n",
    "    any_flags = np.array(any_flags)\n",
    "\n",
    "    report = {\n",
    "        \"leading_only\": int(np.sum(lead_flags & ~trail_flags & ~mid_flags)),\n",
    "        \"trailing_only\": int(np.sum(trail_flags & ~lead_flags & ~mid_flags)),\n",
    "        \"mid_only\": int(np.sum(mid_flags & ~lead_flags & ~trail_flags)),\n",
    "        \"leading_and_trailing\": int(np.sum(lead_flags & trail_flags & ~mid_flags)),\n",
    "        \"leading_and_mid\": int(np.sum(lead_flags & mid_flags & ~trail_flags)),\n",
    "        \"trailing_and_mid\": int(np.sum(trail_flags & mid_flags & ~lead_flags)),\n",
    "        \"leading_trailing_mid\": int(np.sum(lead_flags & trail_flags & mid_flags)),\n",
    "        \"any_NA\": int(np.sum(any_flags)),\n",
    "    }\n",
    "    return report\n",
    "\n",
    "report = missing_pattern_report(X_full)\n",
    "for k,v in report.items():\n",
    "    print(f\"{k}: {v}\")"
   ],
   "id": "a342c8bf2792d397",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 8) Correlation structure: clustered heatmap + extreme pairs",
   "id": "537a93c0e670c658"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "corr = X_full.corr()\n",
    "\n",
    "linkage_matrix = linkage(corr, method=\"ward\")\n",
    "ordered_idx = leaves_list(linkage_matrix)\n",
    "corr_sorted = corr.iloc[ordered_idx, ordered_idx]\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(\n",
    "    corr_sorted,\n",
    "    cmap=\"RdBu_r\",\n",
    "    center=0,\n",
    "    vmin=-1, vmax=1,\n",
    "    cbar=True,\n",
    "    xticklabels=False,\n",
    "    yticklabels=False\n",
    ")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "save_path = OUT_DIR / \"corr_heatmap_clustered.png\"\n",
    "plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "print(f\"Saved to: {save_path}\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "mask = np.tril(np.ones(corr.shape, dtype=bool))\n",
    "corr_unstacked = corr.where(~mask).unstack().dropna()\n",
    "\n",
    "max_pair = corr_unstacked.idxmax(), corr_unstacked.max()\n",
    "min_pair = corr_unstacked.idxmin(), corr_unstacked.min()\n",
    "\n",
    "print(\"Strongest positive correlation:\", max_pair)\n",
    "print(\"Strongest negative correlation:\", min_pair)\n",
    "\n",
    "high_pos = (corr_unstacked > 0.99).sum()\n",
    "high_neg = (corr_unstacked < -0.9).sum()\n",
    "\n",
    "print(f\"Count correlations > 0.9: {high_pos}\")\n",
    "print(f\"Count correlations < -0.9: {high_neg}\")"
   ],
   "id": "36127d8543744425",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 9) Correlation distribution (pairwise)",
   "id": "c0d62ae1668c99cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "corr_full = X_full.corr()\n",
    "corr_cut  = X_original_NA_cutted.corr()\n",
    "\n",
    "mask = np.tril(np.ones(corr_full.shape, dtype=bool))\n",
    "vals_full = corr_full.where(~mask).stack().values\n",
    "vals_cut  = corr_cut.where(~mask).stack().values\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "sns.kdeplot(\n",
    "    vals_full,\n",
    "    fill=True,\n",
    "    bw_adjust=0.6,\n",
    "    label=\"ifo features without missing values\"\n",
    ")\n",
    "sns.kdeplot(\n",
    "    vals_cut,\n",
    "    fill=True,\n",
    "    bw_adjust=0.6,\n",
    "    alpha=0.35,\n",
    "    label=\"Full panel (common window)\"\n",
    ")\n",
    "\n",
    "plt.xlim(-1, 1)\n",
    "plt.xlabel(\"Pairwise Pearson Correlation\")\n",
    "plt.ylabel(\"Kernel density\")\n",
    "plt.title(\"Distribution of pairwise correlations across ifo Business Survey features\")\n",
    "plt.legend(frameon=True, title=\"Feature set\")\n",
    "plt.grid(True, alpha=0.25)\n",
    "plt.tight_layout()\n",
    "\n",
    "save_path = OUT_DIR / \"correlation_distribution.png\"\n",
    "plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "print(f\"Saved to: {save_path}\")\n",
    "\n",
    "plt.show()"
   ],
   "id": "2a24ba96722d81ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 10) Missingness flags per column (lead/mid/trail)",
   "id": "7eb89c2bb95d7f50"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def missing_pattern_flags(s: pd.Series):\n",
    "    a = s.isna().to_numpy()\n",
    "    if not a.any():\n",
    "        return False, False, False, False  # has, lead, mid, trail\n",
    "    lead = 0\n",
    "    for v in a:\n",
    "        if v: lead += 1\n",
    "        else: break\n",
    "    trail = 0\n",
    "    for v in a[::-1]:\n",
    "        if v: trail += 1\n",
    "        else: break\n",
    "    has = True\n",
    "    if lead + trail >= len(a):\n",
    "        mid = False\n",
    "    else:\n",
    "        mid = a[lead:len(a)-trail].any()\n",
    "    return has, (lead>0), mid, (trail>0)\n",
    "\n",
    "flags = np.array([missing_pattern_flags(X_full[c]) for c in X_full.columns], dtype=bool)\n",
    "if flags.size == 0:\n",
    "    raise ValueError(\"No columns in X_full.\")\n",
    "\n",
    "has_miss = flags[:,0]\n",
    "lead = flags[:,1]\n",
    "mid  = flags[:,2]\n",
    "trail= flags[:,3]\n",
    "\n",
    "n = X_full.shape[1]\n",
    "pct = lambda k: 100.0 * k / n\n",
    "\n",
    "print(f\"% with ≥1 missing:  {pct(has_miss.sum()):.1f}\")\n",
    "print(f\"% missing at start: {pct(lead.sum()):.1f}\")\n",
    "print(f\"% missing in middle:{pct(mid.sum()):.1f}\")\n",
    "print(f\"% missing at end:   {pct(trail.sum()):.1f}\")\n",
    "print(\"-- combinations --\")\n",
    "print(f\"% start & end:      {pct((lead & trail).sum()):.1f}\")\n",
    "print(f\"% start & middle:   {pct((lead & mid).sum()):.1f}\")\n",
    "print(f\"% end & middle:     {pct((trail & mid).sum()):.1f}\")"
   ],
   "id": "243a11b54ba2810c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 11) Leading NAs over time: still-missing share (abs/rel)",
   "id": "4d0c802ed793e682"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lead_cols = [c for c, l in zip(X_full.columns, lead) if l]\n",
    "if len(lead_cols) == 0:\n",
    "    print(\"No columns with leading NAs\")\n",
    "else:\n",
    "    fvi = {}\n",
    "    arr_index = np.arange(len(X_full.index))\n",
    "    for c in lead_cols:\n",
    "        a = X_full[c].isna().to_numpy()\n",
    "        lv = 0\n",
    "        for v in a:\n",
    "            if v:\n",
    "                lv += 1\n",
    "            else:\n",
    "                break\n",
    "        fvi[c] = lv\n",
    "\n",
    "    fvi_vals = np.array(list(fvi.values()))\n",
    "\n",
    "    abs_curve = []\n",
    "    for t in arr_index:\n",
    "        still_missing = (fvi_vals > t).sum()\n",
    "        abs_curve.append(still_missing / len(lead_cols))\n",
    "\n",
    "    rel_curve = []\n",
    "    denom = X_full.shape[1]\n",
    "    for t in arr_index:\n",
    "        still_missing = (fvi_vals > t).sum()\n",
    "        rel_curve.append(still_missing / denom)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(X_full.index, abs_curve)\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(\"Share\")\n",
    "    plt.title(\"Leading NAs: Share still missing within leading-NA group\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    save_path1 = OUT_DIR / \"leading_NA_share_abs.png\"\n",
    "    plt.savefig(save_path1, dpi=300, bbox_inches=\"tight\")\n",
    "    print(f\"Saved to: {save_path1}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(X_full.index, rel_curve)\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(\"Share (relative to all columns)\")\n",
    "    plt.title(\"Leading NAs: Share still missing within all time series\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    save_path2 = OUT_DIR / \"leading_NA_share_rel.png\"\n",
    "    plt.savefig(save_path2, dpi=300, bbox_inches=\"tight\")\n",
    "    print(f\"Saved to: {save_path2}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "jump_counts = pd.Series(fvi_vals).value_counts().sort_index()\n",
    "for pos, count in jump_counts.items():\n",
    "    print(f\"{count} series start at {X_full.index[pos].date()}\")"
   ],
   "id": "22e1b2413ca2966",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 12) Missing rate per question + leading-NA share per question",
   "id": "5c62148d6ff04687"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mapping = {\n",
    "    \"geschaeftsklima\": \"Business Climate\",\n",
    "    \"geschaeftslage_beurteilung\": \"Business Situation Assessment\",\n",
    "    \"geschaeftslage_erwartungen\": \"Business Expectations\",\n",
    "    \"beschaeftigungserwartung\": \"Employment Expectations\",\n",
    "    \"fertigwarenlager_beurteilung\": \"Assessment of Stock of Finished Goods\",\n",
    "    \"auftragsbestand_beurteilung\": \"Assessment of Order Backlog\",\n",
    "    \"auftragsbestand_beurteilung_export\": \"Assessment of Export Order Backlog\",\n",
    "    \"nachfrage_gegen_vormonat\": \"Demand Compared to Previous Month\",\n",
    "    \"auftragsbestand_gegen_vormonat\": \"Order Backlog Compared to Previous Month\",\n",
    "    \"produktion_gegen_vormonat\": \"Production Compared to Previous Month\",\n",
    "    \"preise_gegen_vormonat\": \"Prices Compared to Previous Month\",\n",
    "    \"produktionsplaene\": \"Production Plans\",\n",
    "    \"preiserwartungen\": \"Price Expectations\",\n",
    "    \"exporterwartungen\": \"Export Expectations\",\n",
    "    \"beschaeftigtenerwartungen\": \"Employment Expectations\",\n",
    "    \"produktivitaetserwartungen\": \"Productivity Expectations\"\n",
    "}\n",
    "\n",
    "def missing_pattern_flags(s: pd.Series):\n",
    "    a = s.isna().to_numpy()\n",
    "    if not a.any(): return False, False, False, False\n",
    "    lead = 0\n",
    "    for v in a:\n",
    "        if v: lead += 1\n",
    "        else: break\n",
    "    trail = 0\n",
    "    for v in a[::-1]:\n",
    "        if v: trail += 1\n",
    "        else: break\n",
    "    mid = a[lead:len(a)-trail].any() if (lead+trail) < len(a) else False\n",
    "    return True, (lead>0), mid, (trail>0)\n",
    "\n",
    "by_qnorm = {}\n",
    "for c in X_full.columns:\n",
    "    _, qn = split_norm(c)\n",
    "    if qn:\n",
    "        by_qnorm.setdefault(qn, []).append(c)\n",
    "\n",
    "q_missing_rate, q_leading_share = {}, {}\n",
    "for qn, cols in by_qnorm.items():\n",
    "    sub = X_full[cols]\n",
    "    miss_rate = sub.isna().sum().sum() / (sub.shape[0]*sub.shape[1])\n",
    "    lead_mask = [missing_pattern_flags(X_full[c])[1] for c in cols]\n",
    "    q_missing_rate[qn] = miss_rate\n",
    "    q_leading_share[qn] = (np.sum(lead_mask) / len(cols)) if cols else 0.0\n",
    "\n",
    "qs = list(q_missing_rate.keys())\n",
    "\n",
    "vals = [q_missing_rate[q]*100 for q in qs]\n",
    "labels = [mapping.get(q, q) for q in qs]\n",
    "\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.bar(labels, vals)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"% Missing (all cells)\")\n",
    "plt.title(\"Missing rate per question (normalized)\")\n",
    "plt.tight_layout()\n",
    "\n",
    "save_path1 = OUT_DIR / \"missing_rate_per_question.png\"\n",
    "plt.savefig(save_path1, dpi=300, bbox_inches='tight')\n",
    "print(f\"Saved to: {save_path1}\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "vals2 = [q_leading_share[q]*100 for q in qs]\n",
    "\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.bar(labels, vals2)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"% Columns with initial NA\")\n",
    "plt.title(\"Share of Leading NAs per question\")\n",
    "plt.tight_layout()\n",
    "\n",
    "save_path2 = OUT_DIR / \"leading_NA_share_per_question.png\"\n",
    "plt.savefig(save_path2, dpi=300, bbox_inches='tight')\n",
    "print(f\"Saved to: {save_path2}\")\n",
    "\n",
    "plt.show()"
   ],
   "id": "f477f04811343842",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 13) Leading & trailing NAs over time: still-missing share (abs/rel)",
   "id": "24d5d07f050d21a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lead_cols = [c for c, l in zip(X_full.columns, lead) if l]\n",
    "if len(lead_cols) == 0:\n",
    "    print(\"No columns with leading NAs\")\n",
    "else:\n",
    "    fvi_lead, fvi_trail = {}, {}\n",
    "    arr_index = np.arange(len(X_full.index))\n",
    "\n",
    "    for c in lead_cols:\n",
    "        a = X_full[c].isna().to_numpy()\n",
    "\n",
    "        lv = 0\n",
    "        for v in a:\n",
    "            if v: lv += 1\n",
    "            else: break\n",
    "        fvi_lead[c] = lv\n",
    "\n",
    "        tv = 0\n",
    "        for v in a[::-1]:\n",
    "            if v: tv += 1\n",
    "            else: break\n",
    "        fvi_trail[c] = tv\n",
    "\n",
    "    fvi_lead_vals = np.array(list(fvi_lead.values()))\n",
    "    fvi_trail_vals = np.array(list(fvi_trail.values()))\n",
    "\n",
    "    abs_curve = []\n",
    "    for t in arr_index:\n",
    "        still_missing = (fvi_lead_vals > t).sum() + (fvi_trail_vals > (len(arr_index)-1-t)).sum()\n",
    "        abs_curve.append(still_missing / len(lead_cols))\n",
    "\n",
    "    rel_curve = []\n",
    "    denom = X_full.shape[1]\n",
    "    for t in arr_index:\n",
    "        still_missing = (fvi_lead_vals > t).sum() + (fvi_trail_vals > (len(arr_index)-1-t)).sum()\n",
    "        rel_curve.append(still_missing / denom)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(X_full.index, abs_curve)\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(\"Share\")\n",
    "    plt.title(\"Leading & trailing NAs: Share missing within leading-NA group\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    save_path1 = OUT_DIR / \"leading_trailing_NA_share_abs.png\"\n",
    "    plt.savefig(save_path1, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Saved to: {save_path1}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(X_full.index, rel_curve)\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(\"Share (relative to all columns)\")\n",
    "    plt.title(\"Leading & trailing NAs: Share missing within all time series\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    save_path2 = OUT_DIR / \"leading_trailing_NA_share_rel.png\"\n",
    "    plt.savefig(save_path2, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Saved to: {save_path2}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "jump_counts_lead = pd.Series(fvi_lead_vals).value_counts().sort_index()\n",
    "for pos, count in jump_counts_lead.items():\n",
    "    print(f\"{count} series start at {X_full.index[pos].date()}\")\n",
    "\n",
    "jump_counts_trail = pd.Series(fvi_trail_vals).value_counts().sort_index()\n",
    "for pos, count in jump_counts_trail.items():\n",
    "    print(f\"{count} series end at {X_full.index[-pos-1].date()}\")"
   ],
   "id": "996286cccbc7fa89",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 14) Target plots: IP level and MoM change",
   "id": "5d59f33afde156a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure()\n",
    "plt.plot(y_level.index, y_level.values, color=\"black\")\n",
    "plt.title(\"Industrial Production\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Index\")\n",
    "plt.tight_layout()\n",
    "\n",
    "save_path1 = OUT_DIR / \"industrial_production.png\"\n",
    "plt.savefig(save_path1, dpi=300, bbox_inches='tight')\n",
    "print(f\"Saved to: {save_path1}\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "rm = y_change.rolling(rm_window, min_periods=1).mean()\n",
    "plt.figure()\n",
    "plt.scatter(y_change.index, y_change.values, s=8, color=\"blue\")\n",
    "plt.plot(rm.index, rm.values, color=\"black\")\n",
    "plt.title(\"IP – Month over Month Change (Dots) + 12-Month Running Mean (Line)\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"MoM-Change\")\n",
    "plt.tight_layout()\n",
    "\n",
    "save_path2 = OUT_DIR / \"ip_mom_change_running_mean.png\"\n",
    "plt.savefig(save_path2, dpi=300, bbox_inches='tight')\n",
    "print(f\"Saved to: {save_path2}\")\n",
    "\n",
    "plt.show()"
   ],
   "id": "56f66bab81f01fa2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 15) Feature–target correlations by question (lags 0–12)",
   "id": "93ea41e54a543978"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def corr_lag(x, y, lag, min_obs=24):\n",
    "    xs = x.shift(lag)\n",
    "    df = pd.concat([xs, y], axis=1).dropna()\n",
    "    if df.shape[0] < min_obs:\n",
    "        return np.nan\n",
    "    return float(np.corrcoef(df.iloc[:, 0], df.iloc[:, 1])[0, 1])\n",
    "\n",
    "lags = range(0, 13)\n",
    "cand = {}\n",
    "for c in X_full.columns:\n",
    "    _, qn = split_norm(c)\n",
    "    if qn in QUESTION_CANON:\n",
    "        cand.setdefault(qn, []).append(c)\n",
    "\n",
    "mats = {}\n",
    "for qn, cols in cand.items():\n",
    "    if not cols:\n",
    "        continue\n",
    "    M = np.full((len(lags), len(cols)), np.nan)\n",
    "    for j, col in enumerate(cols):\n",
    "        x = X_full[col].astype(float)\n",
    "        for i, lag in enumerate(lags):\n",
    "            M[i, j] = corr_lag(x, y_change, lag)\n",
    "    mats[qn] = pd.DataFrame(M, index=[str(l) for l in lags], columns=cols)\n",
    "\n",
    "records = []\n",
    "for qn, M in mats.items():\n",
    "    for lag in M.index:\n",
    "        vals = M.loc[lag].dropna().astype(float)\n",
    "        for v in vals:\n",
    "            records.append({\"question\": qn, \"corr\": v})\n",
    "df_corrs = pd.DataFrame(records)\n",
    "if df_corrs.empty:\n",
    "    raise ValueError(\"No correlations calculated.\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df_corrs, x=\"question\", y=\"corr\", color=\"lightsteelblue\")\n",
    "plt.axhline(0, color=\"k\", lw=1)\n",
    "plt.title(\"Distribution of Correlations per Question (across all Lags & Industries)\")\n",
    "plt.xlabel(\"Question (QUESTION_CANON)\")\n",
    "plt.ylabel(\"Correlation Coefficient (ΔIP)\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "\n",
    "save_path1 = OUT_DIR / \"corr_distribution_per_question_boxplot.png\"\n",
    "plt.savefig(save_path1, dpi=300, bbox_inches='tight')\n",
    "print(f\"Saved to: {save_path1}\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=df_corrs, x=\"corr\", hue=\"question\", element=\"step\", stat=\"density\", common_norm=False)\n",
    "plt.axvline(0, color=\"k\", lw=1)\n",
    "plt.title(\"Histogram of Correlations per Question\")\n",
    "plt.xlabel(\"Correlation Coefficient (ΔIP)\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.tight_layout()\n",
    "\n",
    "save_path2 = OUT_DIR / \"corr_distribution_per_question_hist.png\"\n",
    "plt.savefig(save_path2, dpi=300, bbox_inches='tight')\n",
    "print(f\"Saved to: {save_path2}\")\n",
    "\n",
    "plt.show()"
   ],
   "id": "1cfc4abe3b128817",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 16) Best (absolute) correlation per series (from mats)",
   "id": "633e549185ae3964"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "corr_values = []\n",
    "for qn, M in mats.items():\n",
    "    for col in M.columns:\n",
    "        series_corrs = M[col].astype(float)\n",
    "        if series_corrs.isna().all():\n",
    "            continue\n",
    "        best_corr = series_corrs.loc[series_corrs.abs().idxmax()]\n",
    "        corr_values.append(best_corr)\n",
    "\n",
    "corr_values = pd.Series(corr_values, name=\"best_corr\")\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(corr_values, bins=40, kde=True, color=\"steelblue\")\n",
    "plt.title(\"Distribution of Highest Correlations per Time Series (Lags 0–12)\")\n",
    "plt.xlabel(\"Correlation Coefficient (ΔIP)\")\n",
    "plt.ylabel(\"Count of Time Series\")\n",
    "plt.axvline(0, color=\"k\", lw=1)\n",
    "plt.tight_layout()\n",
    "\n",
    "save_path1 = OUT_DIR / \"best_correlation_distribution.png\"\n",
    "plt.savefig(save_path1, dpi=300, bbox_inches='tight')\n",
    "print(f\"Saved to: {save_path1}\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(corr_values.abs(), bins=40, kde=True, color=\"darkorange\")\n",
    "plt.title(\"Distribution of Highest Absolute Correlations per Time Series (Lags 0–12)\")\n",
    "plt.xlabel(\"|Correlation Coefficient|\")\n",
    "plt.ylabel(\"Count of Time Series\")\n",
    "plt.tight_layout()\n",
    "\n",
    "save_path2 = OUT_DIR / \"best_abs_correlation_distribution.png\"\n",
    "plt.savefig(save_path2, dpi=300, bbox_inches='tight')\n",
    "print(f\"Saved to: {save_path2}\")\n",
    "\n",
    "plt.show()"
   ],
   "id": "5726d53934d9dcc2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 17) Correlations by lag (lags 1–6) for NA-free features",
   "id": "f81bcc86b36b2eba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "complete_feats = X_full.columns[X_full.notna().all(axis=0)]\n",
    "print(f\"NA-free features: {len(complete_feats)} / {X_full.shape[1]}\")\n",
    "\n",
    "mats_complete = {}\n",
    "complete_set = set(complete_feats)\n",
    "for qn, M in mats.items():\n",
    "    keep_cols = [c for c in M.columns if c in complete_set]\n",
    "    if keep_cols:\n",
    "        mats_complete[qn] = M[keep_cols]\n",
    "\n",
    "records = []\n",
    "for qn, M in mats_complete.items():\n",
    "    for lag in M.index:\n",
    "        lag_int = int(lag)\n",
    "        if not (1 <= lag_int <= 6):\n",
    "            continue\n",
    "        vals = M.loc[lag].dropna().astype(float).values\n",
    "        records.extend([{\"lag\": lag_int, \"corr\": v} for v in vals])\n",
    "\n",
    "df_corrs = pd.DataFrame(records)\n",
    "if df_corrs.empty:\n",
    "    raise ValueError(\"No correlations left — likely no completely NA-free feature series in mats.\")\n",
    "\n",
    "df_corrs[\"lag\"] = pd.Categorical(df_corrs[\"lag\"], categories=list(range(1, 7)), ordered=True)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.boxplot(data=df_corrs, x=\"lag\", y=\"corr\", color=\"lightsteelblue\")\n",
    "plt.axhline(0, color=\"k\", lw=1)\n",
    "\n",
    "plt.title(\"Correlation between IP & ifo features by lag\")\n",
    "plt.xlabel(\"Lag (months)\")\n",
    "plt.ylabel(\"Pearson correlation coefficient\")\n",
    "plt.tight_layout()\n",
    "\n",
    "save_path1 = OUT_DIR / \"correlation_distribution_per_lag_nona_features.png\"\n",
    "plt.savefig(save_path1, dpi=300, bbox_inches=\"tight\")\n",
    "print(f\"Saved to: {save_path1}\")\n",
    "plt.show()\n",
    "\n",
    "df_abs = df_corrs.assign(abs_corr=lambda d: d[\"corr\"].abs())\n",
    "lag_summary = df_abs.groupby(\"lag\")[\"abs_corr\"].median().reset_index()\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.lineplot(data=lag_summary, x=\"lag\", y=\"abs_corr\", marker=\"o\")\n",
    "\n",
    "plt.title(\"Median absolute feature–target correlation by lag\")\n",
    "plt.xlabel(\"Lag (months)\")\n",
    "plt.ylabel(\"Median absolute Pearson correlation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "save_path2 = OUT_DIR / \"median_abs_correlation_per_lag_nona_features.png\"\n",
    "plt.savefig(save_path2, dpi=300, bbox_inches=\"tight\")\n",
    "print(f\"Saved to: {save_path2}\")\n",
    "plt.show()"
   ],
   "id": "ee05c8d4b2013024",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 18) Sanity summary for lag 1–6 correlation sample",
   "id": "ea2214c70941339"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "corr = df_corrs[\"corr\"].astype(float).to_numpy()\n",
    "\n",
    "max_corr = np.nanmax(corr)\n",
    "min_corr = np.nanmin(corr)\n",
    "max_abs_corr = np.nanmax(np.abs(corr))\n",
    "pct_abs_lt_01 = 100 * np.mean(np.abs(corr) < 0.1)\n",
    "\n",
    "print(\"Summary for BOXPlot data only (lags 1–6)\")\n",
    "print(f\"N = {len(corr):,}\")\n",
    "print(f\"Max corr            = {max_corr:.4f}\")\n",
    "print(f\"Min corr            = {min_corr:.4f}\")\n",
    "print(f\"Max |corr|          = {max_abs_corr:.4f}\")\n",
    "print(f\"% with |corr| < 0.1 = {pct_abs_lt_01:.2f}%\")\n",
    "\n",
    "i_max = int(np.nanargmax(corr))\n",
    "i_abs = int(np.nanargmax(np.abs(corr)))\n",
    "print(f\"Max corr occurs at lag={df_corrs.iloc[i_max]['lag']}, corr={df_corrs.iloc[i_max]['corr']:.4f}\")\n",
    "print(f\"Max |corr| occurs at lag={df_corrs.iloc[i_abs]['lag']}, corr={df_corrs.iloc[i_abs]['corr']:.4f}\")\n",
    "\n",
    "print(f\"Any corr > 0.2? {bool(np.any(corr > 0.2))}\")\n",
    "print(f\"Any |corr| > 0.2? {bool(np.any(np.abs(corr) > 0.2))}\")"
   ],
   "id": "d6bbab2f72733dea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 20) Autocorrelation of ΔIP (lags 1–6) + Ljung–Box",
   "id": "e8659a101779d6c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_change = df[\"IP_change\"].dropna()\n",
    "\n",
    "lags = range(1, 7)\n",
    "vals = []\n",
    "for k in lags:\n",
    "    a = pd.concat([y_change.shift(k), y_change], axis=1).dropna()\n",
    "    if len(a) < 3:\n",
    "        vals.append(np.nan)\n",
    "    else:\n",
    "        vals.append(float(np.corrcoef(a.iloc[:, 0], a.iloc[:, 1])[0, 1]))\n",
    "\n",
    "plt.figure()\n",
    "plt.stem(list(lags), vals)\n",
    "plt.title(\"Autocorrelation ΔIP (1..6)\")\n",
    "plt.xlabel(\"Lag\")\n",
    "plt.ylabel(\"ACF\")\n",
    "plt.tight_layout()\n",
    "\n",
    "save_path1 = OUT_DIR / \"autocorrelation_delta_ip_1-6.png\"\n",
    "plt.savefig(save_path1, dpi=300, bbox_inches=\"tight\")\n",
    "print(f\"Saved to: {save_path1}\")\n",
    "plt.show()\n",
    "\n",
    "n = len(y_change)\n",
    "conf = 1.96 / np.sqrt(n)\n",
    "\n",
    "plt.figure()\n",
    "plt.stem(list(lags), vals)\n",
    "plt.axhline(y=0, color=\"black\", linewidth=1)\n",
    "plt.axhline(y=conf, color=\"red\", linestyle=\"--\")\n",
    "plt.axhline(y=-conf, color=\"red\", linestyle=\"--\")\n",
    "plt.title(\"Autocorrelation ΔIP (1..6) with 95% band (white-noise approx.)\")\n",
    "plt.xlabel(\"Lag\")\n",
    "plt.ylabel(\"ACF\")\n",
    "plt.tight_layout()\n",
    "\n",
    "save_path2 = OUT_DIR / \"autocorrelation_delta_ip_confband_1-6.png\"\n",
    "plt.savefig(save_path2, dpi=300, bbox_inches=\"tight\")\n",
    "print(f\"Saved to: {save_path2}\")\n",
    "plt.show()\n",
    "\n",
    "lb = acorr_ljungbox(y_change, lags=list(lags), return_df=True)\n",
    "print(\"\\nLjung–Box test (H0: no autocorrelation up to lag h):\")\n",
    "print(lb)"
   ],
   "id": "8b43f02f8071d8db",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
