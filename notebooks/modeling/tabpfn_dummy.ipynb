{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-09T18:28:12.235163Z",
     "start_time": "2025-11-09T17:44:02.163097Z"
    }
   },
   "source": [
    "# ============================\n",
    "# TabPFN – Minimaler Debug-Workflow\n",
    "# ============================\n",
    "# Ziel:\n",
    "# - Gleiche Logik wie ET/EN/LGBM-Notebooks (run_stageA / run_stageB)\n",
    "# - Aber: preset=\"debug\" + extrem kleines Grid\n",
    "# - Kein Dynamic-FI, nur Full-FE (Gleis 1/2)\n",
    "# ============================\n",
    "\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "\n",
    "# --- 1) Pfad-Setup (analog ET.ipynb) --------------------------------------\n",
    "def _locate_repo_root(start: Path) -> Path:\n",
    "    cur = start.resolve()\n",
    "    for _ in range(6):\n",
    "        if (cur / \"src\").exists():\n",
    "            return cur\n",
    "        if cur.parent == cur:\n",
    "            break\n",
    "        cur = cur.parent\n",
    "    return start.resolve()\n",
    "\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "PROJECT_ROOT = _locate_repo_root(NOTEBOOK_DIR)\n",
    "os.environ[\"PROJECT_ROOT\"] = str(PROJECT_ROOT)\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(\"PROJECT_ROOT =\", PROJECT_ROOT)\n",
    "\n",
    "# --- 2) Repo-Imports -------------------------------------------------------\n",
    "from src.config import (\n",
    "    GlobalConfig,\n",
    "    DEFAULT_CORR_SPEC,\n",
    "    EWMA_CORR_SPEC,\n",
    "    outputs_for_model,\n",
    ")\n",
    "from src.tuning import run_stageA, run_stageB\n",
    "from src.io_timesplits import (\n",
    "    load_target,\n",
    "    load_ifo_features,\n",
    "    # Für Debug: wir nutzen hier nur Full-FE, also KEIN Dynamic-FI\n",
    "    # load_full_lagged_features, load_rolling_importance\n",
    ")\n",
    "from src.models.TabPFN import ForecastModel   # dein TabPFN-Wrapper\n",
    "\n",
    "# --- 3) Debug-Meta ---------------------------------------------------------\n",
    "USE_DYNAMIC_FI_PIPELINE = False   # Für diesen Debug-Workflow: NUR Full-FE\n",
    "SEED   = 42\n",
    "\n",
    "if USE_DYNAMIC_FI_PIPELINE:\n",
    "    MODEL_NAME = \"tabpfn_dynamic_fi_debug\"\n",
    "else:\n",
    "    MODEL_NAME = \"tabpfn_debug\"\n",
    "\n",
    "outputs_for_model(MODEL_NAME)\n",
    "print(f\"Modell {MODEL_NAME} (Debug) wird getunt.\")\n",
    "\n",
    "# --- 4) Daten laden (Full-FE / Gleis 1+2) ---------------------------------\n",
    "y = load_target()\n",
    "X_ifo = load_ifo_features()\n",
    "\n",
    "# Nur Full-FE: Indizes matchen, Dynamic-FI-Objekte bleiben None\n",
    "idx = y.index.intersection(X_ifo.index)\n",
    "y = y.loc[idx]\n",
    "X_ifo = X_ifo.loc[idx]\n",
    "X_full_lagged = None\n",
    "rolling_imp   = None\n",
    "\n",
    "print(\"Full-FE Debug-Daten geladen. Shapes:\", X_ifo.shape, y.shape)\n",
    "\n",
    "# --- 5) Debug-Config (kleiner als Thesis) ---------------------------------\n",
    "def base_cfg_debug() -> GlobalConfig:\n",
    "    \"\"\"\n",
    "    GlobalConfig im 'debug'-Preset (muss in src.config definiert sein).\n",
    "    Falls du dort kein 'debug'-Preset hast, kannst du auch\n",
    "    GlobalConfig(preset=\"thesis\") nehmen und einzelne Dinge manuell kleiner machen.\n",
    "    \"\"\"\n",
    "    cfg = GlobalConfig(preset=\"debug\")\n",
    "    # Du KANNST hier noch weiter schärfen, z.B. kleinere policy_window etc.,\n",
    "    # aber typischerweise ist im debug-Preset schon alles reduziert.\n",
    "    cfg.policy_window   = 12     # optional: kleiner als 24\n",
    "    cfg.policy_decay    = 0.95\n",
    "    cfg.policy_gain_min = 0.03\n",
    "    cfg.policy_cooldown = 3\n",
    "    return cfg\n",
    "\n",
    "cfg0 = base_cfg_debug()\n",
    "\n",
    "# --- 6) Korrelations-Helper (wie ET/EN/LGBM) ------------------------------\n",
    "def make_corr_spec(kind: str) -> dict:\n",
    "    if kind == \"expanding\":\n",
    "        return dict(DEFAULT_CORR_SPEC)\n",
    "    elif kind == \"ewm\":\n",
    "        return dict(EWMA_CORR_SPEC)\n",
    "    else:\n",
    "        raise ValueError(\"kind must be 'expanding' or 'ewm'\")\n",
    "\n",
    "# --- 7) Minimal-Grid (Full FE, TabPFN-HP klein gehalten) ------------------\n",
    "if USE_DYNAMIC_FI_PIPELINE:\n",
    "    # Für diesen Debug-Workflow lassen wir Dynamic-FI ABSICHTLICH weg.\n",
    "    # Wenn du es testen willst, kannst du später analog EN/LGBM ein kleines\n",
    "    # Dynamic-FI Grid bauen.\n",
    "    raise RuntimeError(\"Debug-Notebook ist nur für Full-FE (USE_DYNAMIC_FI_PIPELINE=False) gedacht.\")\n",
    "else:\n",
    "    print(\"Erstelle MINIMALES HP-Grid für 'Full FE' (Debug)...\")\n",
    "\n",
    "    # A) FE/DR-Listen – JEWEILS NUR EINE OPTION\n",
    "    corr_options = [\n",
    "        (\"expanding\", make_corr_spec(\"expanding\")),  # nur expanding\n",
    "        # Wenn du ewm testen willst: (\"ewm\", make_corr_spec(\"ewm\")),\n",
    "    ]\n",
    "    lag_candidates_list   = [(1, 2, 3, 6, 12)]   # kannst du auch auf (1, 3) reduzieren\n",
    "    top_k_lags_list       = [1]\n",
    "    use_rm3_list          = [True]               # oder [False] – egal für Debug\n",
    "    k1_topk_list          = [100]                # nur eine Variante\n",
    "    redundancy_param_list = [0.90]\n",
    "    dr_options_list       = [\n",
    "        {\"dr_method\": \"none\"},                   # kein PCA/PLS in Debug\n",
    "    ]\n",
    "\n",
    "    # B) TabPFN-spezifische HPs – MINIMAL\n",
    "    #    (wir nehmen hier BEWUSST nur EINE Kombination, um Rechenzeit zu sparen)\n",
    "    n_estimators_list = [1]                      # nur 1 Ensemble-Konfiguration\n",
    "    # ggf. weitere TabPFN-HPs hier, falls du sie im Wrapper nutzt:\n",
    "    # z.B. max_time_list = [None] o.ä.\n",
    "\n",
    "    # C) Keine Target Blocks / einfaches Weighting für Debug\n",
    "    target_block_options = [None]\n",
    "    weighting_options    = [{\"sample_weight_decay\": None}]\n",
    "\n",
    "    def build_model_grid_full_fe_debug():\n",
    "        hp_grid = []\n",
    "\n",
    "        fe_lists = [\n",
    "            lag_candidates_list,\n",
    "            top_k_lags_list,\n",
    "            use_rm3_list,\n",
    "            k1_topk_list,\n",
    "            redundancy_param_list,\n",
    "            dr_options_list,\n",
    "        ]\n",
    "\n",
    "        for (corr_tag, corr_spec) in corr_options:\n",
    "            for (lags, k_lags, rm3, k1, red, dr_opt) in product(*fe_lists):\n",
    "                # keine speziellen Einschränkungen mehr nötig, da alles = 'none'\n",
    "                base_fe = {\n",
    "                    \"lag_candidates\": lags,\n",
    "                    \"top_k_lags_per_feature\": k_lags,\n",
    "                    \"use_rm3\": rm3,\n",
    "                    \"k1_topk\": k1,\n",
    "                    \"redundancy_param\": red,\n",
    "                    **dr_opt,            # 'dr_method': 'none'\n",
    "                    \"corr_tag\": corr_tag,\n",
    "                    \"corr_spec\": corr_spec,\n",
    "                }\n",
    "\n",
    "                for n_est in n_estimators_list:\n",
    "                    base_model = {\n",
    "                        \"n_estimators\": n_est,\n",
    "                        \"seed\": SEED,\n",
    "                        # falls dein TabPFN-Wrapper weitere keys braucht,\n",
    "                        # kannst du sie hier hinzufügen, z.B.:\n",
    "                        # \"use_gpu\": False,\n",
    "                    }\n",
    "\n",
    "                    for block_set in target_block_options:\n",
    "                        for w in weighting_options:\n",
    "                            hp = {\n",
    "                                **base_fe,\n",
    "                                **base_model,\n",
    "                                \"target_block_set\": block_set,\n",
    "                                **w,\n",
    "                            }\n",
    "                            hp_grid.append(hp)\n",
    "\n",
    "        return hp_grid\n",
    "\n",
    "    model_grid = build_model_grid_full_fe_debug()\n",
    "\n",
    "print(\"Anzahl HP-Kombinationen (Debug):\", len(model_grid))\n",
    "print(\"Erstes HP-Set (Debug):\", model_grid[0] if model_grid else \"Grid ist leer\")\n",
    "\n",
    "# --- 8) Stage A/B – identische Logik wie bei ET/EN/LGBM -------------------\n",
    "if model_grid:\n",
    "    shortlist = run_stageA(\n",
    "        model_name=MODEL_NAME,\n",
    "        model_ctor=lambda hp: ForecastModel(hp),\n",
    "        model_grid=model_grid,\n",
    "        X=X_ifo,\n",
    "        y=y,\n",
    "        cfg=cfg0,\n",
    "        # winzig halten:\n",
    "        keep_top_k_final=min(2, len(model_grid)),\n",
    "        min_survivors_per_block=1,\n",
    "    )\n",
    "\n",
    "    run_stageB(\n",
    "        model_name=MODEL_NAME,\n",
    "        model_ctor=lambda hp: ForecastModel(hp),\n",
    "        shortlist=shortlist,\n",
    "        X=X_ifo,\n",
    "        y=y,\n",
    "        cfg=cfg0,\n",
    "    )\n",
    "else:\n",
    "    print(\"Keine gültigen HP-Kombinationen gefunden, Stages übersprungen.\")\n",
    "\n",
    "print(f\"\\nDebug-Run fertig. Check outputs/stageA|stageB/{MODEL_NAME} für Ergebnisse.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT = /Users/jonasschernich/Documents/Masterarbeit/Code\n",
      "Modell tabpfn_debug (Debug) wird getunt.\n",
      "INFO in load_ifo_features: Renaming columns to ensure validity.\n",
      "Full-FE Debug-Daten geladen. Shapes: (407, 2160) (407,)\n",
      "Erstelle MINIMALES HP-Grid für 'Full FE' (Debug)...\n",
      "Anzahl HP-Kombinationen (Debug): 1\n",
      "Erstes HP-Set (Debug): {'lag_candidates': (1, 2, 3, 6, 12), 'top_k_lags_per_feature': 1, 'use_rm3': True, 'k1_topk': 100, 'redundancy_param': 0.9, 'dr_method': 'none', 'corr_tag': 'expanding', 'corr_spec': {'mode': 'expanding', 'window': None, 'lam': None}, 'n_estimators': 1, 'seed': 42, 'target_block_set': None, 'sample_weight_decay': None}\n",
      "[Stage A] Using FULL FE pipeline (Gleis 1 & 2).\n",
      "[Stage A][Block 1] train_end=48, OOS=49-60 | configs=1\n",
      "  - Config 1/1\n",
      "    · Month 5/12 processed | running...RMSE=0.8429\n",
      "    · Month 10/12 processed | running...RMSE=1.1182\n",
      "    · Month 12/12 processed | running...RMSE=1.1768\n",
      "[Stage A][Block 1] kept 1 configs (floor=1).\n",
      "[Stage A][Block 2] train_end=60, OOS=61-72 | configs=1\n",
      "  - Config 1/1\n",
      "    · Month 5/12 processed | running...RMSE=1.1280\n",
      "    · Month 10/12 processed | running...RMSE=1.1196\n",
      "    · Month 12/12 processed | running...RMSE=1.5256\n",
      "[Stage A][Block 2] kept 1 configs (floor=1).\n",
      "[Stage A] Shortlist saved with 1 configs.\n",
      "[Stage B] Using FULL FE pipeline (Gleis 1 & 2).\n",
      "[Stage B] Month origin t=73 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=74 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=75 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=76 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=77 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=78 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=79 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=80 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=81 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=82 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=83 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=84 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=85 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=86 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=87 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=88 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=89 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=90 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=91 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=92 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=93 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=94 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=95 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=96 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=97 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=98 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=99 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=100 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=101 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=102 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=103 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=104 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=105 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=106 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=107 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=108 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=109 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=110 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=111 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=112 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=113 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=114 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=115 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=116 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=117 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=118 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=119 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=120 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=121 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=122 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=123 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=124 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=125 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=126 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=127 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=128 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=129 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=130 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=131 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=132 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=133 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=134 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=135 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=136 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=137 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=138 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=139 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=140 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=141 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=142 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=143 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=144 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=145 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=146 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=147 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=148 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=149 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=150 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=151 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=152 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=153 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=154 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=155 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=156 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=157 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=158 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=159 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=160 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=161 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=162 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=163 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=164 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=165 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=166 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=167 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=168 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=169 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=170 | evaluating 1 configs | active=1\n",
      "[Stage B] Month origin t=171 | evaluating 1 configs | active=1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 202\u001B[0m\n\u001B[1;32m    189\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_grid:\n\u001B[1;32m    190\u001B[0m     shortlist \u001B[38;5;241m=\u001B[39m run_stageA(\n\u001B[1;32m    191\u001B[0m         model_name\u001B[38;5;241m=\u001B[39mMODEL_NAME,\n\u001B[1;32m    192\u001B[0m         model_ctor\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m hp: ForecastModel(hp),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    199\u001B[0m         min_survivors_per_block\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m    200\u001B[0m     )\n\u001B[0;32m--> 202\u001B[0m     \u001B[43mrun_stageB\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    203\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mMODEL_NAME\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    204\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_ctor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mhp\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mForecastModel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhp\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    205\u001B[0m \u001B[43m        \u001B[49m\u001B[43mshortlist\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshortlist\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    206\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_ifo\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    207\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    208\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcfg\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcfg0\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    209\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    210\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    211\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mKeine gültigen HP-Kombinationen gefunden, Stages übersprungen.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/Masterarbeit/Code/src/tuning.py:716\u001B[0m, in \u001B[0;36mrun_stageB\u001B[0;34m(model_name, model_ctor, shortlist, X, y, cfg, max_months, X_full_lagged, rolling_imp)\u001B[0m\n\u001B[1;32m    710\u001B[0m     result_dict \u001B[38;5;241m=\u001B[39m _fit_predict_one_origin_DYNAMIC_FI(\n\u001B[1;32m    711\u001B[0m         model_ctor\u001B[38;5;241m=\u001B[39mmodel_ctor, model_hp\u001B[38;5;241m=\u001B[39mhp,\n\u001B[1;32m    712\u001B[0m         X_full_lagged\u001B[38;5;241m=\u001B[39mX_full_lagged, y\u001B[38;5;241m=\u001B[39my, rolling_imp\u001B[38;5;241m=\u001B[39mrolling_imp,\n\u001B[1;32m    713\u001B[0m         t_origin\u001B[38;5;241m=\u001B[39mt, cfg\u001B[38;5;241m=\u001B[39mcfg\n\u001B[1;32m    714\u001B[0m     )\n\u001B[1;32m    715\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 716\u001B[0m     result_dict \u001B[38;5;241m=\u001B[39m \u001B[43m_fit_predict_one_origin_FULL_FE\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    717\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_ctor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_ctor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_hp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhp\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    718\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt_origin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcfg\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcfg\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    719\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcorr_spec\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcorr_spec\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcfg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcorr_spec\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    720\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    721\u001B[0m \u001B[38;5;66;03m# --- ENDE LOGIK-SWITCH ---\u001B[39;00m\n\u001B[1;32m    723\u001B[0m y_hat \u001B[38;5;241m=\u001B[39m result_dict[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_pred\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/Documents/Masterarbeit/Code/src/tuning.py:268\u001B[0m, in \u001B[0;36m_fit_predict_one_origin_FULL_FE\u001B[0;34m(model_ctor, model_hp, X, y, t_origin, cfg, corr_spec)\u001B[0m\n\u001B[1;32m    265\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    266\u001B[0m     model\u001B[38;5;241m.\u001B[39mfit(np\u001B[38;5;241m.\u001B[39masarray(Xb_tr), np\u001B[38;5;241m.\u001B[39masarray(y_tr)\u001B[38;5;241m.\u001B[39mravel())\n\u001B[0;32m--> 268\u001B[0m y_hat \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mfloat\u001B[39m(\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_one\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mXb_ev\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    270\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[1;32m    271\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_pred\u001B[39m\u001B[38;5;124m\"\u001B[39m: y_hat,\n\u001B[1;32m    272\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mn_features_sis\u001B[39m\u001B[38;5;124m\"\u001B[39m: n_sis,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    276\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mchronos_sigma_t\u001B[39m\u001B[38;5;124m\"\u001B[39m: chronos_sigma\n\u001B[1;32m    277\u001B[0m }\n",
      "File \u001B[0;32m~/Documents/Masterarbeit/Code/src/models/TabPFN.py:172\u001B[0m, in \u001B[0;36mForecastModel.predict_one\u001B[0;34m(self, x_row)\u001B[0m\n\u001B[1;32m    170\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict_one\u001B[39m(\u001B[38;5;28mself\u001B[39m, x_row):\n\u001B[1;32m    171\u001B[0m     x \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(x_row)\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m--> 172\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mfloat\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m])\n",
      "File \u001B[0;32m~/Documents/Masterarbeit/Code/src/models/TabPFN.py:167\u001B[0m, in \u001B[0;36mForecastModel.predict\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    165\u001B[0m     X_np \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(X)\n\u001B[1;32m    166\u001B[0m X_np \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_clean(X_np)\n\u001B[0;32m--> 167\u001B[0m yhat \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_np\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    168\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39masarray(yhat, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mfloat\u001B[39m)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py:81\u001B[0m, in \u001B[0;36mContextDecorator.__call__.<locals>.inner\u001B[0;34m(*args, **kwds)\u001B[0m\n\u001B[1;32m     78\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[1;32m     79\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds):\n\u001B[1;32m     80\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_recreate_cm():\n\u001B[0;32m---> 81\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn_common_utils/telemetry/core/decorators.py:242\u001B[0m, in \u001B[0;36mtrack_model_call.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    240\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    241\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m--> 242\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_safe_call_with_telemetry\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    243\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_method\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparam_names\u001B[49m\n\u001B[1;32m    244\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn_common_utils/telemetry/core/decorators.py:286\u001B[0m, in \u001B[0;36m_safe_call_with_telemetry\u001B[0;34m(func, args, kwargs, model_method, param_names)\u001B[0m\n\u001B[1;32m    284\u001B[0m \u001B[38;5;66;03m# Step 2: Run the actual function\u001B[39;00m\n\u001B[1;32m    285\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[0;32m--> 286\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    287\u001B[0m duration_ms \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m((time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m1000\u001B[39m)\n\u001B[1;32m    289\u001B[0m \u001B[38;5;66;03m# Step 3: Send telemetry event\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/regressor.py:870\u001B[0m, in \u001B[0;36mTabPFNRegressor.predict\u001B[0;34m(self, X, output_type, quantiles)\u001B[0m\n\u001B[1;32m    863\u001B[0m X \u001B[38;5;241m=\u001B[39m process_text_na_dataframe(X, ord_encoder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreprocessor_)  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m    865\u001B[0m \u001B[38;5;66;03m# Runs over iteration engine\u001B[39;00m\n\u001B[1;32m    866\u001B[0m (\n\u001B[1;32m    867\u001B[0m     _,\n\u001B[1;32m    868\u001B[0m     outputs,  \u001B[38;5;66;03m# list of tensors [N_est, N_samples, N_borders] (after forward)\u001B[39;00m\n\u001B[1;32m    869\u001B[0m     borders,  \u001B[38;5;66;03m# list of numpy arrays containing borders for each estimator\u001B[39;00m\n\u001B[0;32m--> 870\u001B[0m ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_inference_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    872\u001B[0m \u001B[38;5;66;03m# --- Translate probs, average, get final logits ---\u001B[39;00m\n\u001B[1;32m    873\u001B[0m transformed_logits \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    874\u001B[0m     translate_probs_across_borders(\n\u001B[1;32m    875\u001B[0m         logits,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    879\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m logits, borders_t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(outputs, borders)\n\u001B[1;32m    880\u001B[0m ]\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/regressor.py:998\u001B[0m, in \u001B[0;36mTabPFNRegressor.forward\u001B[0;34m(self, X, use_inference_mode)\u001B[0m\n\u001B[1;32m    995\u001B[0m borders: \u001B[38;5;28mlist\u001B[39m[np\u001B[38;5;241m.\u001B[39mndarray] \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    997\u001B[0m \u001B[38;5;66;03m# Iterate over estimators\u001B[39;00m\n\u001B[0;32m--> 998\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43moutput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecutor_\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miter_outputs\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    999\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1000\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevices\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevices_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1001\u001B[0m \u001B[43m    \u001B[49m\u001B[43mautocast\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43muse_autocast_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1002\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m   1003\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msoftmax_temperature\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m!=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m:\u001B[49m\n\u001B[1;32m   1004\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43moutput\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msoftmax_temperature\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# noqa: PLW2901\u001B[39;49;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/inference.py:507\u001B[0m, in \u001B[0;36mInferenceEngineCachePreprocessing.iter_outputs\u001B[0;34m(self, X, devices, autocast, only_return_standard_out)\u001B[0m\n\u001B[1;32m    491\u001B[0m model_forward_functions \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    492\u001B[0m     partial(\n\u001B[1;32m    493\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_model,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    503\u001B[0m     )\n\u001B[1;32m    504\u001B[0m )\n\u001B[1;32m    505\u001B[0m outputs \u001B[38;5;241m=\u001B[39m parallel_execute(devices, model_forward_functions)\n\u001B[0;32m--> 507\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43moutput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mzip\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mensemble_configs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m    508\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m_move_and_squeeze_output\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevices\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\n\u001B[1;32m    510\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minference_mode:\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/parallel_execute.py:58\u001B[0m, in \u001B[0;36mparallel_execute\u001B[0;34m(devices, functions)\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Evaluate the given functions in parallel across `devices`.\u001B[39;00m\n\u001B[1;32m     40\u001B[0m \n\u001B[1;32m     41\u001B[0m \u001B[38;5;124;03mThe function evaluations are parallelised using Python threads, so this will only\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;124;03m    as `functions`.\u001B[39;00m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(devices) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m     57\u001B[0m     \u001B[38;5;66;03m# If we only have one device then just use the current thread to avoid overhead.\u001B[39;00m\n\u001B[0;32m---> 58\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m _execute_in_current_thread(devices[\u001B[38;5;241m0\u001B[39m], functions)\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m _execute_with_multithreading(devices, functions)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/parallel_execute.py:67\u001B[0m, in \u001B[0;36m_execute_in_current_thread\u001B[0;34m(device, functions)\u001B[0m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_execute_in_current_thread\u001B[39m(\n\u001B[1;32m     64\u001B[0m     device: torch\u001B[38;5;241m.\u001B[39mdevice, functions: Iterable[ParallelFunction[R_co]]\n\u001B[1;32m     65\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Generator[R_co]:\n\u001B[1;32m     66\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m function \u001B[38;5;129;01min\u001B[39;00m functions:\n\u001B[0;32m---> 67\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_parallel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/inference.py:555\u001B[0m, in \u001B[0;36mInferenceEngineCachePreprocessing._call_model\u001B[0;34m(self, device, is_parallel, X_train, X_test, y_train, cat_ix, autocast, only_return_standard_out)\u001B[0m\n\u001B[1;32m    541\u001B[0m     MemoryUsageEstimator\u001B[38;5;241m.\u001B[39mreset_peak_memory_if_required(\n\u001B[1;32m    542\u001B[0m         save_peak_mem\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msave_peak_mem,\n\u001B[1;32m    543\u001B[0m         model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    548\u001B[0m         safety_factor\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1.2\u001B[39m,\n\u001B[1;32m    549\u001B[0m     )\n\u001B[1;32m    551\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m (\n\u001B[1;32m    552\u001B[0m     get_autocast_context(device, enabled\u001B[38;5;241m=\u001B[39mautocast),\n\u001B[1;32m    553\u001B[0m     torch\u001B[38;5;241m.\u001B[39minference_mode(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minference_mode),\n\u001B[1;32m    554\u001B[0m ):\n\u001B[0;32m--> 555\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    556\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX_full\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    557\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    558\u001B[0m \u001B[43m        \u001B[49m\u001B[43monly_return_standard_out\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43monly_return_standard_out\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    559\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcategorical_inds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatched_cat_ix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    560\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/architectures/base/transformer.py:549\u001B[0m, in \u001B[0;36mPerFeatureTransformer.forward\u001B[0;34m(***failed resolving arguments***)\u001B[0m\n\u001B[1;32m    541\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    542\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThere should be no NaNs in the encoded x and y.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    543\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCheck that you do not feed NaNs or use a NaN-handling enocder.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    544\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYour embedded x and y returned the following:\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    545\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtorch\u001B[38;5;241m.\u001B[39misnan(embedded_x)\u001B[38;5;241m.\u001B[39many()\u001B[38;5;132;01m=}\u001B[39;00m\u001B[38;5;124m | \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtorch\u001B[38;5;241m.\u001B[39misnan(embedded_y)\u001B[38;5;241m.\u001B[39many()\u001B[38;5;132;01m=}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    546\u001B[0m     )\n\u001B[1;32m    547\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m embedded_y, embedded_x\n\u001B[0;32m--> 549\u001B[0m encoder_out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransformer_encoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    550\u001B[0m \u001B[43m    \u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    551\u001B[0m \u001B[43m        \u001B[49m\u001B[43membedded_input\u001B[49m\n\u001B[1;32m    552\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransformer_decoder\u001B[49m\n\u001B[1;32m    553\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43membedded_input\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43msingle_eval_pos\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m    554\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    555\u001B[0m \u001B[43m    \u001B[49m\u001B[43msingle_eval_pos\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msingle_eval_pos\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    556\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache_trainset_representation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcache_trainset_representation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    557\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# b s f+1 e -> b s f+1 e\u001B[39;00m\n\u001B[1;32m    559\u001B[0m \u001B[38;5;66;03m# If we are using a decoder\u001B[39;00m\n\u001B[1;32m    560\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransformer_decoder:\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/architectures/base/transformer.py:94\u001B[0m, in \u001B[0;36mLayerStack.forward\u001B[0;34m(self, x, **kwargs)\u001B[0m\n\u001B[1;32m     92\u001B[0m         x \u001B[38;5;241m=\u001B[39m checkpoint(partial(layer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs), x, use_reentrant\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m     93\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 94\u001B[0m         x \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     96\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/architectures/base/layer.py:421\u001B[0m, in \u001B[0;36mPerFeatureEncoderLayer.forward\u001B[0;34m(self, state, single_eval_pos, cache_trainset_representation, att_src)\u001B[0m\n\u001B[1;32m    411\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[1;32m    412\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPre-norm implementation is wrong, as the residual should never\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    413\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m be layer normed here.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    414\u001B[0m     )\n\u001B[1;32m    415\u001B[0m     state \u001B[38;5;241m=\u001B[39m layer_norm(\n\u001B[1;32m    416\u001B[0m         state,\n\u001B[1;32m    417\u001B[0m         allow_inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    418\u001B[0m         save_peak_mem_factor\u001B[38;5;241m=\u001B[39msave_peak_mem_factor,\n\u001B[1;32m    419\u001B[0m     )\n\u001B[0;32m--> 421\u001B[0m state \u001B[38;5;241m=\u001B[39m \u001B[43msublayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    422\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpre_norm:\n\u001B[1;32m    423\u001B[0m     state \u001B[38;5;241m=\u001B[39m layer_norm(\n\u001B[1;32m    424\u001B[0m         state,\n\u001B[1;32m    425\u001B[0m         allow_inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    426\u001B[0m         save_peak_mem_factor\u001B[38;5;241m=\u001B[39msave_peak_mem_factor,\n\u001B[1;32m    427\u001B[0m     )\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/architectures/base/mlp.py:132\u001B[0m, in \u001B[0;36mMLP.forward\u001B[0;34m(self, x, add_input, allow_inplace, save_peak_mem_factor)\u001B[0m\n\u001B[1;32m    130\u001B[0m input_shape \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mshape\n\u001B[1;32m    131\u001B[0m x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, x\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m))\n\u001B[0;32m--> 132\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_compute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    133\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    134\u001B[0m \u001B[43m    \u001B[49m\u001B[43madd_input\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43madd_input\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    135\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_inplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_inplace\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    136\u001B[0m \u001B[43m    \u001B[49m\u001B[43msave_peak_mem_factor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msave_peak_mem_factor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    137\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    138\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x\u001B[38;5;241m.\u001B[39mreshape(input_shape)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/architectures/base/memory.py:95\u001B[0m, in \u001B[0;36msupport_save_peak_mem_factor.<locals>.method_\u001B[0;34m(self, x, add_input, allow_inplace, save_peak_mem_factor, *args, **kwargs)\u001B[0m\n\u001B[1;32m     93\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m x_, \u001B[38;5;241m*\u001B[39margs_ \u001B[38;5;129;01min\u001B[39;00m split_args:\n\u001B[1;32m     94\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m add_input:\n\u001B[0;32m---> 95\u001B[0m         x_[:] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m method(\u001B[38;5;28mself\u001B[39m, x_, \u001B[38;5;241m*\u001B[39margs_, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     96\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     97\u001B[0m         x_[:] \u001B[38;5;241m=\u001B[39m method(\u001B[38;5;28mself\u001B[39m, x_, \u001B[38;5;241m*\u001B[39margs_, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
