{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T17:35:59.766509Z",
     "start_time": "2025-11-09T17:35:56.401434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Setup & Imports ---\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "# --- 1. Pfad-Setup (identisch zu ET/EN/LGBM) ---\n",
    "def _locate_repo_root(start: Path) -> Path:\n",
    "    cur = start.resolve()\n",
    "    for _ in range(6):\n",
    "        if (cur / \"src\").exists():\n",
    "            return cur\n",
    "        if cur.parent == cur:\n",
    "            break\n",
    "        cur = cur.parent\n",
    "    return start.resolve()\n",
    "\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "PROJECT_ROOT = _locate_repo_root(NOTEBOOK_DIR)\n",
    "os.environ[\"PROJECT_ROOT\"] = str(PROJECT_ROOT)\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(\"PROJECT_ROOT =\", PROJECT_ROOT)\n",
    "\n",
    "# --- 2. Repo-Imports (identisch zur ET-Logik) ---\n",
    "from src.config import (\n",
    "    GlobalConfig,\n",
    "    DEFAULT_CORR_SPEC,\n",
    "    EWMA_CORR_SPEC,\n",
    "    outputs_for_model,\n",
    ")\n",
    "from src.tuning import run_stageA, run_stageB\n",
    "from src.io_timesplits import (\n",
    "    load_target,\n",
    "    load_ifo_features,\n",
    "    load_full_lagged_features,\n",
    "    load_rolling_importance,\n",
    ")\n",
    "\n",
    "# --- MODELL-IMPORT (TabPFN-Wrapper) ---\n",
    "from src.models.TabPFN import ForecastModel\n"
   ],
   "id": "7421fec75963b3fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT = /Users/jonasschernich/Documents/Masterarbeit/Code\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T17:36:41.395174Z",
     "start_time": "2025-11-09T17:36:41.371878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 3. Master-Schalter & Modellname (wie ET) ---\n",
    "USE_DYNAMIC_FI_PIPELINE = False  # False => Full FE; True => Dynamic FI\n",
    "SEED   = 42\n",
    "\n",
    "if USE_DYNAMIC_FI_PIPELINE:\n",
    "    MODEL_NAME = \"tabpfn_dynamic_fi\"\n",
    "else:\n",
    "    MODEL_NAME = \"tabpfn\"\n",
    "\n",
    "outputs_for_model(MODEL_NAME)\n",
    "print(f\"Modell {MODEL_NAME} wird getunt.\")\n"
   ],
   "id": "385df6f048f62a06",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modell tabpfn wird getunt.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T17:36:42.891108Z",
     "start_time": "2025-11-09T17:36:42.762935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 4. Daten laden (identisch zu ET) ---\n",
    "FI_PATH = PROJECT_ROOT / \"outputs\" / \"feature_importance\" / \"outputs_no_missing\"\n",
    "\n",
    "y = load_target()           # ΔIP (DatetimeIndex)\n",
    "X_ifo = load_ifo_features() # ifo features (Full FE)\n",
    "\n",
    "if USE_DYNAMIC_FI_PIPELINE:\n",
    "    try:\n",
    "        X_full_lagged = load_full_lagged_features(base_dir=FI_PATH)\n",
    "        rolling_imp   = load_rolling_importance(base_dir=FI_PATH)\n",
    "        idx_fi = y.index.intersection(X_full_lagged.index).intersection(rolling_imp.index)\n",
    "        y_fi, X_full_lagged, rolling_imp = y.loc[idx_fi], X_full_lagged.loc[idx_fi], rolling_imp.loc[idx_fi]\n",
    "        print(\"Dynamic-FI Daten geladen. Shapes:\", X_full_lagged.shape, rolling_imp.shape, y_fi.shape)\n",
    "    except FileNotFoundError as e:\n",
    "        print(\"FEHLER: Dynamic-FI Artefakte fehlen:\", e)\n",
    "        print(\"Bitte erst feature_importance.ipynb (entsprechende Jobs) laufen lassen.\")\n",
    "        raise\n",
    "else:\n",
    "    X_full_lagged, rolling_imp = None, None\n",
    "    idx = y.index.intersection(X_ifo.index)\n",
    "    y, X_ifo = y.loc[idx], X_ifo.loc[idx]\n",
    "    print(\"Full-FE Daten geladen. Shapes:\", X_ifo.shape, y.shape)\n"
   ],
   "id": "4eef1eaac2c4e693",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO in load_ifo_features: Renaming columns to ensure validity.\n",
      "Full-FE Daten geladen. Shapes: (407, 2160) (407,)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T17:36:52.493749Z",
     "start_time": "2025-11-09T17:36:52.491115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 5. Base-Config & Policy (wie Thesis, identisch zu ET) ---\n",
    "def base_cfg() -> GlobalConfig:\n",
    "    cfg = GlobalConfig(preset=\"thesis\")\n",
    "    cfg.policy_window   = 24\n",
    "    cfg.policy_decay    = 0.95\n",
    "    cfg.policy_gain_min = 0.03\n",
    "    cfg.policy_cooldown = 3\n",
    "    return cfg\n",
    "\n",
    "cfg0 = base_cfg()\n",
    "\n",
    "# --- 6. Corr-Helper (identisch zu ET) ---\n",
    "def make_corr_spec(kind: str) -> dict:\n",
    "    if kind == \"expanding\":\n",
    "        return dict(DEFAULT_CORR_SPEC)\n",
    "    elif kind == \"ewm\":\n",
    "        return dict(EWMA_CORR_SPEC)\n",
    "    else:\n",
    "        raise ValueError(\"kind must be 'expanding' or 'ewm'\")\n"
   ],
   "id": "cb104adad719d80",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T17:36:55.482460Z",
     "start_time": "2025-11-09T17:36:55.473717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 7. TUNING-GRID (analog zur ET-Struktur, aber TabPFN hat kaum Modell-HPs) ---\n",
    "\n",
    "# WICHTIG: Die Device-Wahl soll NICHT über Grid getuned werden (konstant halten).\n",
    "USE_GPU_DEFAULT = False     # <— ändere hier, wenn du GPU nutzen willst\n",
    "FORCE_DEVICE = None         # 'cpu' | 'cuda' | 'mps' oder None (Auto basierend auf USE_GPU_DEFAULT)\n",
    "\n",
    "if USE_DYNAMIC_FI_PIPELINE:\n",
    "    print(\"Erstelle HP-Grid für 'Dynamic FI' ...\")\n",
    "\n",
    "    N_FEATURES_TO_USE = 20\n",
    "    weighting_options = [\n",
    "        {\"sample_weight_decay\": None},\n",
    "        {\"sample_weight_decay\": 0.98},\n",
    "    ]\n",
    "\n",
    "    def build_model_grid_dynamic_fi():\n",
    "        grid = []\n",
    "        base = {\n",
    "            \"n_features_to_use\": N_FEATURES_TO_USE,\n",
    "            \"seed\": SEED,\n",
    "            \"use_gpu\": USE_GPU_DEFAULT,\n",
    "            \"device\": FORCE_DEVICE,   # None => Auto im Wrapper\n",
    "        }\n",
    "        for w in weighting_options:\n",
    "            hp = dict(base)\n",
    "            hp.update(w)\n",
    "            grid.append(hp)\n",
    "        return grid\n",
    "\n",
    "    model_grid = build_model_grid_dynamic_fi()\n",
    "\n",
    "else:\n",
    "    print(\"Erstelle HP-Grid für 'Full FE' ...\")\n",
    "\n",
    "    # A) FE/DR-Listen (wie ET, reduziert)\n",
    "    corr_options = [\n",
    "        (\"expanding\", make_corr_spec(\"expanding\")),\n",
    "        (\"ewm\",       make_corr_spec(\"ewm\")),\n",
    "    ]\n",
    "    lag_candidates_list   = [(1, 2, 3, 6, 12)]\n",
    "    top_k_lags_list       = [1]\n",
    "    use_rm3_list          = [True]\n",
    "    k1_topk_list          = [100, 300]\n",
    "    redundancy_param_list = [0.90]\n",
    "    dr_options_list       = [\n",
    "        {\"dr_method\": \"none\"},\n",
    "        {\"dr_method\": \"pca\", \"pca_var_target\": 0.95, \"pca_kmax\": 50},\n",
    "        {\"dr_method\": \"pls\", \"pls_components\": 8},\n",
    "    ]\n",
    "\n",
    "    # B) Target Blocks & Weighting\n",
    "    target_block_options = [None, [\"AR1\"], [\"Chronos\"], [\"TSFresh\"]]\n",
    "    weighting_options    = [{\"sample_weight_decay\": None}]\n",
    "\n",
    "    # C) Grid zusammensetzen (TabPFN hat keine weiteren sinnvollen Modell-HPs hier)\n",
    "    def build_model_grid_full_fe():\n",
    "        hp_grid = []\n",
    "        fe_lists = [\n",
    "            lag_candidates_list,\n",
    "            top_k_lags_list,\n",
    "            use_rm3_list,\n",
    "            k1_topk_list,\n",
    "            redundancy_param_list,\n",
    "            dr_options_list,\n",
    "        ]\n",
    "        for (corr_tag, corr_spec) in corr_options:\n",
    "            for (lags, k_lags, rm3, k1, red, dr_opt) in product(*fe_lists):\n",
    "                if k1 == 100 and dr_opt[\"dr_method\"] != \"none\":\n",
    "                    continue\n",
    "                base = {\n",
    "                    \"lag_candidates\": lags,\n",
    "                    \"top_k_lags_per_feature\": k_lags,\n",
    "                    \"use_rm3\": rm3,\n",
    "                    \"k1_topk\": k1,\n",
    "                    \"redundancy_param\": red,\n",
    "                    **dr_opt,\n",
    "                    \"corr_tag\": corr_tag,\n",
    "                    \"corr_spec\": corr_spec,\n",
    "                    # TabPFN-spezifisch (konstant, kein Tuning):\n",
    "                    \"seed\": SEED,\n",
    "                    \"use_gpu\": USE_GPU_DEFAULT,\n",
    "                    \"device\": FORCE_DEVICE,\n",
    "                }\n",
    "                for block_set in target_block_options:\n",
    "                    for w in weighting_options:\n",
    "                        hp = {**base, \"target_block_set\": block_set, **w}\n",
    "                        hp_grid.append(hp)\n",
    "        return hp_grid\n",
    "\n",
    "    model_grid = build_model_grid_full_fe()\n",
    "\n",
    "print(\"Optimierte HP-Kombinationen:\", len(model_grid))\n",
    "print(\"Erstes HP-Set:\", model_grid[0] if model_grid else \"Grid ist leer\")\n"
   ],
   "id": "91975b7649277cb0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erstelle HP-Grid für 'Full FE' ...\n",
      "Optimierte HP-Kombinationen: 32\n",
      "Erstes HP-Set: {'lag_candidates': (1, 2, 3, 6, 12), 'top_k_lags_per_feature': 1, 'use_rm3': True, 'k1_topk': 100, 'redundancy_param': 0.9, 'dr_method': 'none', 'corr_tag': 'expanding', 'corr_spec': {'mode': 'expanding', 'window': None, 'lam': None}, 'seed': 42, 'use_gpu': False, 'device': None, 'target_block_set': None, 'sample_weight_decay': None}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T17:43:58.982747Z",
     "start_time": "2025-11-09T17:36:59.432868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 8. Stage A/B Lauf (identisch zur ET-Logik, inkl. Dynamic-FI Pfad) ---\n",
    "if model_grid:\n",
    "    if USE_DYNAMIC_FI_PIPELINE:\n",
    "        shortlist = run_stageA(\n",
    "            model_name=MODEL_NAME,\n",
    "            model_ctor=lambda hp: ForecastModel(hp),\n",
    "            model_grid=model_grid,\n",
    "            X=X_ifo,  # Platzhalter, Dynamic-FI nutzt X_full_lagged + rolling_imp\n",
    "            y=y_fi,\n",
    "            cfg=cfg0,\n",
    "            keep_top_k_final=min(10, len(model_grid)),\n",
    "            min_survivors_per_block=2,\n",
    "            X_full_lagged=X_full_lagged,\n",
    "            rolling_imp=rolling_imp,\n",
    "        )\n",
    "        run_stageB(\n",
    "            model_name=MODEL_NAME,\n",
    "            model_ctor=lambda hp: ForecastModel(hp),\n",
    "            shortlist=shortlist,\n",
    "            X=X_ifo,  # Platzhalter\n",
    "            y=y_fi,\n",
    "            cfg=cfg0,\n",
    "            X_full_lagged=X_full_lagged,\n",
    "            rolling_imp=rolling_imp,\n",
    "        )\n",
    "    else:\n",
    "        shortlist = run_stageA(\n",
    "            model_name=MODEL_NAME,\n",
    "            model_ctor=lambda hp: ForecastModel(hp),\n",
    "            model_grid=model_grid,\n",
    "            X=X_ifo,\n",
    "            y=y,\n",
    "            cfg=cfg0,\n",
    "            keep_top_k_final=min(10, len(model_grid)),\n",
    "            min_survivors_per_block=2,\n",
    "        )\n",
    "        run_stageB(\n",
    "            model_name=MODEL_NAME,\n",
    "            model_ctor=lambda hp: ForecastModel(hp),\n",
    "            shortlist=shortlist,\n",
    "            X=X_ifo,\n",
    "            y=y,\n",
    "            cfg=cfg0,\n",
    "        )\n",
    "else:\n",
    "    print(\"Keine gültigen HP-Kombinationen gefunden, Stages übersprungen.\")\n",
    "\n",
    "print(f\"\\nDone. Check outputs/stageA|stageB/{MODEL_NAME} for results.\")\n"
   ],
   "id": "6592455b98c43ae6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Stage A] Using FULL FE pipeline (Gleis 1 & 2).\n",
      "[Stage A][Block 1] train_end=180, OOS=181-200 | configs=32\n",
      "  - Config 1/32\n",
      "    · Month 5/20 processed | running...RMSE=1.6724\n",
      "    · Month 10/20 processed | running...RMSE=1.3424\n",
      "    · Month 15/20 processed | running...RMSE=1.2585\n",
      "    · Month 20/20 processed | running...RMSE=1.1273\n",
      "  - Config 2/32\n",
      "    · Month 5/20 processed | running...RMSE=1.6724\n",
      "    · Month 10/20 processed | running...RMSE=1.3424\n",
      "    · Month 15/20 processed | running...RMSE=1.2585\n",
      "    · Month 20/20 processed | running...RMSE=1.1273\n",
      "  - Config 3/32\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 27\u001B[0m\n\u001B[1;32m     16\u001B[0m         run_stageB(\n\u001B[1;32m     17\u001B[0m             model_name\u001B[38;5;241m=\u001B[39mMODEL_NAME,\n\u001B[1;32m     18\u001B[0m             model_ctor\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m hp: ForecastModel(hp),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     24\u001B[0m             rolling_imp\u001B[38;5;241m=\u001B[39mrolling_imp,\n\u001B[1;32m     25\u001B[0m         )\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 27\u001B[0m         shortlist \u001B[38;5;241m=\u001B[39m \u001B[43mrun_stageA\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     28\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mMODEL_NAME\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     29\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmodel_ctor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mhp\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mForecastModel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhp\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     30\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmodel_grid\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_grid\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     31\u001B[0m \u001B[43m            \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_ifo\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     32\u001B[0m \u001B[43m            \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     33\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcfg\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcfg0\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     34\u001B[0m \u001B[43m            \u001B[49m\u001B[43mkeep_top_k_final\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mmin\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mmodel_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     35\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmin_survivors_per_block\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mmax\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mmodel_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     36\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     37\u001B[0m         run_stageB(\n\u001B[1;32m     38\u001B[0m             model_name\u001B[38;5;241m=\u001B[39mMODEL_NAME,\n\u001B[1;32m     39\u001B[0m             model_ctor\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m hp: ForecastModel(hp),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     43\u001B[0m             cfg\u001B[38;5;241m=\u001B[39mcfg0,\n\u001B[1;32m     44\u001B[0m         )\n\u001B[1;32m     45\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/Documents/Masterarbeit/Code/src/tuning.py:565\u001B[0m, in \u001B[0;36mrun_stageA\u001B[0;34m(model_name, model_ctor, model_grid, X, y, cfg, keep_top_k_final, min_survivors_per_block, X_full_lagged, rolling_imp)\u001B[0m\n\u001B[1;32m    562\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:  \u001B[38;5;66;03m# Gleis 3 hat keine DR\u001B[39;00m\n\u001B[1;32m    563\u001B[0m     Xb_eval \u001B[38;5;241m=\u001B[39m x_eval\n\u001B[0;32m--> 565\u001B[0m y_hat \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_one\u001B[49m\u001B[43m(\u001B[49m\u001B[43mXb_eval\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    566\u001B[0m y_true \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mfloat\u001B[39m(y\u001B[38;5;241m.\u001B[39miloc[t \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m    567\u001B[0m y_true_block\u001B[38;5;241m.\u001B[39mappend(y_true)\n",
      "File \u001B[0;32m~/Documents/Masterarbeit/Code/src/models/TabPFN.py:172\u001B[0m, in \u001B[0;36mForecastModel.predict_one\u001B[0;34m(self, x_row)\u001B[0m\n\u001B[1;32m    170\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict_one\u001B[39m(\u001B[38;5;28mself\u001B[39m, x_row):\n\u001B[1;32m    171\u001B[0m     x \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(x_row)\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m--> 172\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mfloat\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m])\n",
      "File \u001B[0;32m~/Documents/Masterarbeit/Code/src/models/TabPFN.py:167\u001B[0m, in \u001B[0;36mForecastModel.predict\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    165\u001B[0m     X_np \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(X)\n\u001B[1;32m    166\u001B[0m X_np \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_clean(X_np)\n\u001B[0;32m--> 167\u001B[0m yhat \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_np\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    168\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39masarray(yhat, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mfloat\u001B[39m)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py:81\u001B[0m, in \u001B[0;36mContextDecorator.__call__.<locals>.inner\u001B[0;34m(*args, **kwds)\u001B[0m\n\u001B[1;32m     78\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[1;32m     79\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds):\n\u001B[1;32m     80\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_recreate_cm():\n\u001B[0;32m---> 81\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn_common_utils/telemetry/core/decorators.py:242\u001B[0m, in \u001B[0;36mtrack_model_call.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    240\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    241\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m--> 242\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_safe_call_with_telemetry\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    243\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_method\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparam_names\u001B[49m\n\u001B[1;32m    244\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn_common_utils/telemetry/core/decorators.py:286\u001B[0m, in \u001B[0;36m_safe_call_with_telemetry\u001B[0;34m(func, args, kwargs, model_method, param_names)\u001B[0m\n\u001B[1;32m    284\u001B[0m \u001B[38;5;66;03m# Step 2: Run the actual function\u001B[39;00m\n\u001B[1;32m    285\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[0;32m--> 286\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    287\u001B[0m duration_ms \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m((time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m1000\u001B[39m)\n\u001B[1;32m    289\u001B[0m \u001B[38;5;66;03m# Step 3: Send telemetry event\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/regressor.py:870\u001B[0m, in \u001B[0;36mTabPFNRegressor.predict\u001B[0;34m(self, X, output_type, quantiles)\u001B[0m\n\u001B[1;32m    863\u001B[0m X \u001B[38;5;241m=\u001B[39m process_text_na_dataframe(X, ord_encoder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreprocessor_)  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m    865\u001B[0m \u001B[38;5;66;03m# Runs over iteration engine\u001B[39;00m\n\u001B[1;32m    866\u001B[0m (\n\u001B[1;32m    867\u001B[0m     _,\n\u001B[1;32m    868\u001B[0m     outputs,  \u001B[38;5;66;03m# list of tensors [N_est, N_samples, N_borders] (after forward)\u001B[39;00m\n\u001B[1;32m    869\u001B[0m     borders,  \u001B[38;5;66;03m# list of numpy arrays containing borders for each estimator\u001B[39;00m\n\u001B[0;32m--> 870\u001B[0m ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_inference_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    872\u001B[0m \u001B[38;5;66;03m# --- Translate probs, average, get final logits ---\u001B[39;00m\n\u001B[1;32m    873\u001B[0m transformed_logits \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    874\u001B[0m     translate_probs_across_borders(\n\u001B[1;32m    875\u001B[0m         logits,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    879\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m logits, borders_t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(outputs, borders)\n\u001B[1;32m    880\u001B[0m ]\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/regressor.py:998\u001B[0m, in \u001B[0;36mTabPFNRegressor.forward\u001B[0;34m(self, X, use_inference_mode)\u001B[0m\n\u001B[1;32m    995\u001B[0m borders: \u001B[38;5;28mlist\u001B[39m[np\u001B[38;5;241m.\u001B[39mndarray] \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    997\u001B[0m \u001B[38;5;66;03m# Iterate over estimators\u001B[39;00m\n\u001B[0;32m--> 998\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43moutput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecutor_\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miter_outputs\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    999\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1000\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevices\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevices_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1001\u001B[0m \u001B[43m    \u001B[49m\u001B[43mautocast\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43muse_autocast_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1002\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m   1003\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msoftmax_temperature\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m!=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m:\u001B[49m\n\u001B[1;32m   1004\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43moutput\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msoftmax_temperature\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# noqa: PLW2901\u001B[39;49;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/inference.py:507\u001B[0m, in \u001B[0;36mInferenceEngineCachePreprocessing.iter_outputs\u001B[0;34m(self, X, devices, autocast, only_return_standard_out)\u001B[0m\n\u001B[1;32m    491\u001B[0m model_forward_functions \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    492\u001B[0m     partial(\n\u001B[1;32m    493\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_model,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    503\u001B[0m     )\n\u001B[1;32m    504\u001B[0m )\n\u001B[1;32m    505\u001B[0m outputs \u001B[38;5;241m=\u001B[39m parallel_execute(devices, model_forward_functions)\n\u001B[0;32m--> 507\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43moutput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mzip\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mensemble_configs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m    508\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m_move_and_squeeze_output\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevices\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\n\u001B[1;32m    510\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minference_mode:\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/parallel_execute.py:58\u001B[0m, in \u001B[0;36mparallel_execute\u001B[0;34m(devices, functions)\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Evaluate the given functions in parallel across `devices`.\u001B[39;00m\n\u001B[1;32m     40\u001B[0m \n\u001B[1;32m     41\u001B[0m \u001B[38;5;124;03mThe function evaluations are parallelised using Python threads, so this will only\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;124;03m    as `functions`.\u001B[39;00m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(devices) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m     57\u001B[0m     \u001B[38;5;66;03m# If we only have one device then just use the current thread to avoid overhead.\u001B[39;00m\n\u001B[0;32m---> 58\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m _execute_in_current_thread(devices[\u001B[38;5;241m0\u001B[39m], functions)\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m _execute_with_multithreading(devices, functions)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/parallel_execute.py:67\u001B[0m, in \u001B[0;36m_execute_in_current_thread\u001B[0;34m(device, functions)\u001B[0m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_execute_in_current_thread\u001B[39m(\n\u001B[1;32m     64\u001B[0m     device: torch\u001B[38;5;241m.\u001B[39mdevice, functions: Iterable[ParallelFunction[R_co]]\n\u001B[1;32m     65\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Generator[R_co]:\n\u001B[1;32m     66\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m function \u001B[38;5;129;01min\u001B[39;00m functions:\n\u001B[0;32m---> 67\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_parallel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/inference.py:555\u001B[0m, in \u001B[0;36mInferenceEngineCachePreprocessing._call_model\u001B[0;34m(self, device, is_parallel, X_train, X_test, y_train, cat_ix, autocast, only_return_standard_out)\u001B[0m\n\u001B[1;32m    541\u001B[0m     MemoryUsageEstimator\u001B[38;5;241m.\u001B[39mreset_peak_memory_if_required(\n\u001B[1;32m    542\u001B[0m         save_peak_mem\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msave_peak_mem,\n\u001B[1;32m    543\u001B[0m         model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    548\u001B[0m         safety_factor\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1.2\u001B[39m,\n\u001B[1;32m    549\u001B[0m     )\n\u001B[1;32m    551\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m (\n\u001B[1;32m    552\u001B[0m     get_autocast_context(device, enabled\u001B[38;5;241m=\u001B[39mautocast),\n\u001B[1;32m    553\u001B[0m     torch\u001B[38;5;241m.\u001B[39minference_mode(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minference_mode),\n\u001B[1;32m    554\u001B[0m ):\n\u001B[0;32m--> 555\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    556\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX_full\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    557\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    558\u001B[0m \u001B[43m        \u001B[49m\u001B[43monly_return_standard_out\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43monly_return_standard_out\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    559\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcategorical_inds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatched_cat_ix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    560\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/architectures/base/transformer.py:549\u001B[0m, in \u001B[0;36mPerFeatureTransformer.forward\u001B[0;34m(***failed resolving arguments***)\u001B[0m\n\u001B[1;32m    541\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    542\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThere should be no NaNs in the encoded x and y.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    543\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCheck that you do not feed NaNs or use a NaN-handling enocder.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    544\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYour embedded x and y returned the following:\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    545\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtorch\u001B[38;5;241m.\u001B[39misnan(embedded_x)\u001B[38;5;241m.\u001B[39many()\u001B[38;5;132;01m=}\u001B[39;00m\u001B[38;5;124m | \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtorch\u001B[38;5;241m.\u001B[39misnan(embedded_y)\u001B[38;5;241m.\u001B[39many()\u001B[38;5;132;01m=}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    546\u001B[0m     )\n\u001B[1;32m    547\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m embedded_y, embedded_x\n\u001B[0;32m--> 549\u001B[0m encoder_out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransformer_encoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    550\u001B[0m \u001B[43m    \u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    551\u001B[0m \u001B[43m        \u001B[49m\u001B[43membedded_input\u001B[49m\n\u001B[1;32m    552\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransformer_decoder\u001B[49m\n\u001B[1;32m    553\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43membedded_input\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43msingle_eval_pos\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m    554\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    555\u001B[0m \u001B[43m    \u001B[49m\u001B[43msingle_eval_pos\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msingle_eval_pos\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    556\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache_trainset_representation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcache_trainset_representation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    557\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# b s f+1 e -> b s f+1 e\u001B[39;00m\n\u001B[1;32m    559\u001B[0m \u001B[38;5;66;03m# If we are using a decoder\u001B[39;00m\n\u001B[1;32m    560\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransformer_decoder:\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/architectures/base/transformer.py:94\u001B[0m, in \u001B[0;36mLayerStack.forward\u001B[0;34m(self, x, **kwargs)\u001B[0m\n\u001B[1;32m     92\u001B[0m         x \u001B[38;5;241m=\u001B[39m checkpoint(partial(layer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs), x, use_reentrant\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m     93\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 94\u001B[0m         x \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     96\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/architectures/base/layer.py:421\u001B[0m, in \u001B[0;36mPerFeatureEncoderLayer.forward\u001B[0;34m(self, state, single_eval_pos, cache_trainset_representation, att_src)\u001B[0m\n\u001B[1;32m    411\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[1;32m    412\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPre-norm implementation is wrong, as the residual should never\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    413\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m be layer normed here.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    414\u001B[0m     )\n\u001B[1;32m    415\u001B[0m     state \u001B[38;5;241m=\u001B[39m layer_norm(\n\u001B[1;32m    416\u001B[0m         state,\n\u001B[1;32m    417\u001B[0m         allow_inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    418\u001B[0m         save_peak_mem_factor\u001B[38;5;241m=\u001B[39msave_peak_mem_factor,\n\u001B[1;32m    419\u001B[0m     )\n\u001B[0;32m--> 421\u001B[0m state \u001B[38;5;241m=\u001B[39m \u001B[43msublayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    422\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpre_norm:\n\u001B[1;32m    423\u001B[0m     state \u001B[38;5;241m=\u001B[39m layer_norm(\n\u001B[1;32m    424\u001B[0m         state,\n\u001B[1;32m    425\u001B[0m         allow_inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    426\u001B[0m         save_peak_mem_factor\u001B[38;5;241m=\u001B[39msave_peak_mem_factor,\n\u001B[1;32m    427\u001B[0m     )\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/architectures/base/mlp.py:132\u001B[0m, in \u001B[0;36mMLP.forward\u001B[0;34m(self, x, add_input, allow_inplace, save_peak_mem_factor)\u001B[0m\n\u001B[1;32m    130\u001B[0m input_shape \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mshape\n\u001B[1;32m    131\u001B[0m x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, x\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m))\n\u001B[0;32m--> 132\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_compute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    133\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    134\u001B[0m \u001B[43m    \u001B[49m\u001B[43madd_input\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43madd_input\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    135\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_inplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_inplace\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    136\u001B[0m \u001B[43m    \u001B[49m\u001B[43msave_peak_mem_factor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msave_peak_mem_factor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    137\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    138\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x\u001B[38;5;241m.\u001B[39mreshape(input_shape)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/architectures/base/memory.py:95\u001B[0m, in \u001B[0;36msupport_save_peak_mem_factor.<locals>.method_\u001B[0;34m(self, x, add_input, allow_inplace, save_peak_mem_factor, *args, **kwargs)\u001B[0m\n\u001B[1;32m     93\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m x_, \u001B[38;5;241m*\u001B[39margs_ \u001B[38;5;129;01min\u001B[39;00m split_args:\n\u001B[1;32m     94\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m add_input:\n\u001B[0;32m---> 95\u001B[0m         x_[:] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     96\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     97\u001B[0m         x_[:] \u001B[38;5;241m=\u001B[39m method(\u001B[38;5;28mself\u001B[39m, x_, \u001B[38;5;241m*\u001B[39margs_, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/architectures/base/mlp.py:95\u001B[0m, in \u001B[0;36mMLP._compute\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     93\u001B[0m \u001B[38;5;129m@support_save_peak_mem_factor\u001B[39m  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m     94\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_compute\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: torch\u001B[38;5;241m.\u001B[39mTensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor:\n\u001B[0;32m---> 95\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     96\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mactivation \u001B[38;5;129;01mis\u001B[39;00m Activation\u001B[38;5;241m.\u001B[39mGELU:\n\u001B[1;32m     97\u001B[0m         x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mfunctional\u001B[38;5;241m.\u001B[39mgelu(x)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/linear.py:116\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 116\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
