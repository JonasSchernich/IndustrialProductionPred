{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T09:46:09.839565Z",
     "start_time": "2026-01-27T09:44:12.404106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==============================================================================\n",
    "# TabPFN\n",
    "# ==============================================================================\n",
    "\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "# --- 1) Path setup ---\n",
    "def _locate_repo_root(start: Path) -> Path:\n",
    "    cur = start.resolve()\n",
    "    for _ in range(6):\n",
    "        if (cur / \"src\").exists():\n",
    "            return cur\n",
    "        if cur.parent == cur:\n",
    "            break\n",
    "        cur = cur.parent\n",
    "    return start.resolve()\n",
    "\n",
    "\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "PROJECT_ROOT = _locate_repo_root(NOTEBOOK_DIR)\n",
    "os.environ[\"PROJECT_ROOT\"] = str(PROJECT_ROOT)\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "\n",
    "# --- 2) Imports ---\n",
    "from src.config import (\n",
    "    GlobalConfig,\n",
    "    DEFAULT_CORR_SPEC,  # expanding\n",
    "    EWMA_CORR_SPEC,     # ewma\n",
    "    outputs_for_model,\n",
    ")\n",
    "from src.tuning import run_stageA, run_stageB\n",
    "from src.io_timesplits import (\n",
    "    load_target,\n",
    "    load_ifo_features,\n",
    "    load_full_lagged_features,\n",
    "    load_rolling_importance,\n",
    ")\n",
    "# Model import for TabPFN\n",
    "from src.models.TabPFN import ForecastModel\n",
    "\n",
    "\n",
    "# --- 3) Config ---\n",
    "USE_DYNAMIC_FI_PIPELINE = True  # False = standard setups (I & II)\n",
    "SEED = 42\n",
    "\n",
    "# TabPFN device config (CUDA or MPS)\n",
    "USE_GPU = True\n",
    "FORCE_DEVICE = None  # e.g. \"cuda\"\n",
    "\n",
    "MODEL_NAME = \"tabpfn_test\"\n",
    "\n",
    "outputs_for_model(MODEL_NAME)\n",
    "print(f\"--- Running tuning for: {MODEL_NAME} ---\")\n",
    "\n",
    "\n",
    "# --- 4) Load data ---\n",
    "y = load_target()\n",
    "X_ifo = load_ifo_features()\n",
    "\n",
    "# Align indices\n",
    "idx_common = y.index.intersection(X_ifo.index)\n",
    "y = y.loc[idx_common]\n",
    "X_ifo = X_ifo.loc[idx_common]\n",
    "\n",
    "X_full_lagged = None\n",
    "rolling_imp = None\n",
    "y_fi = None\n",
    "\n",
    "if USE_DYNAMIC_FI_PIPELINE:\n",
    "    FI_BASE_DIR = PROJECT_ROOT / \"outputs\" / \"feature_importance\" / \"outputs_no_missing\"\n",
    "    try:\n",
    "        X_full_lagged = load_full_lagged_features(base_dir=FI_BASE_DIR)\n",
    "        rolling_imp = load_rolling_importance(base_dir=FI_BASE_DIR)\n",
    "\n",
    "        idx_fi = y.index.intersection(X_full_lagged.index).intersection(rolling_imp.index)\n",
    "        y_fi = y.loc[idx_fi]\n",
    "        X_full_lagged = X_full_lagged.loc[idx_fi]\n",
    "        rolling_imp = rolling_imp.loc[idx_fi]\n",
    "        print(f\"Dynamic FI mode: loaded {X_full_lagged.shape[1]} features.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"ERROR: Dynamic FI artifacts not found.\")\n",
    "        sys.exit(1)\n",
    "else:\n",
    "    print(f\"Full FE mode (Setups I/II): {X_ifo.shape[1]} base features.\")\n",
    "\n",
    "\n",
    "# --- 5) Config defaults (thesis policy) ---\n",
    "def get_thesis_cfg() -> GlobalConfig:\n",
    "    cfg = GlobalConfig(preset=\"thesis\")\n",
    "    cfg.policy_window = 24\n",
    "    cfg.policy_decay = 0.97\n",
    "    cfg.selection_mode = \"decayed_best\"\n",
    "    return cfg\n",
    "\n",
    "\n",
    "cfg_obj = get_thesis_cfg()\n",
    "\n",
    "\n",
    "# --- 6) Grid definition ---\n",
    "def build_grid_full_fe():\n",
    "    \"\"\"Setup I (ifo) and Setup II (ifo + target blocks).\"\"\"\n",
    "    # FE & DR grid\n",
    "    lag_candidates = [tuple(range(7))]\n",
    "\n",
    "    corr_opts = [\n",
    "        {\"corr_spec\": dict(DEFAULT_CORR_SPEC)},\n",
    "        {\"corr_spec\": dict(EWMA_CORR_SPEC)},\n",
    "    ]\n",
    "\n",
    "    k1_opts = [10]\n",
    "    red_opts = [1.0]\n",
    "\n",
    "    dr_opts = [\n",
    "        {\"dr_method\": \"none\"},\n",
    "        {\"dr_method\": \"pca\", \"pca_kmax\": 30, \"pca_var_target\": 0.99},\n",
    "        {\"dr_method\": \"pls\", \"pls_components\": 30},\n",
    "    ]\n",
    "\n",
    "    # Setup II (target blocks)\n",
    "    block_opts = [\n",
    "        None,  # Setup I\n",
    "        # [\"AR1\", \"Chronos\", \"TSFresh\"]  # Setup IIb\n",
    "    ]\n",
    "\n",
    "    # TabPFN does not support sample weights (see src/models/TabPFN.py)\n",
    "    weight_opts = [{\"sample_weight_decay\": None}]\n",
    "\n",
    "    grid = []\n",
    "\n",
    "    # FE loop\n",
    "    for lags, corr, k1, red, dr in product(lag_candidates, corr_opts, k1_opts, red_opts, dr_opts):\n",
    "\n",
    "        if dr[\"dr_method\"] == \"none\" and k1 > 300:\n",
    "            continue\n",
    "\n",
    "        base_fe = {\n",
    "            \"lag_candidates\": lags,\n",
    "            \"k1_topk\": k1,\n",
    "            \"redundancy_param\": red,\n",
    "            **dr,\n",
    "            **corr,\n",
    "        }\n",
    "\n",
    "        # Blocks & weights & model params\n",
    "        for blocks, weights in product(block_opts, weight_opts):\n",
    "            hp = {\n",
    "                **base_fe,\n",
    "                \"target_block_set\": blocks,\n",
    "                **weights,\n",
    "                # TabPFN-specific\n",
    "                \"use_gpu\": USE_GPU,\n",
    "                \"device\": FORCE_DEVICE,\n",
    "                \"seed\": SEED,\n",
    "            }\n",
    "            grid.append(hp)\n",
    "\n",
    "    return grid\n",
    "\n",
    "\n",
    "def build_grid_dynamic_fi():\n",
    "    \"\"\"Setup III: dynamic feature importance via strict top-N.\"\"\"\n",
    "    n_features_list = [20]\n",
    "\n",
    "    # TabPFN ignores weights -> keep only None\n",
    "    weight_opts = [{\"sample_weight_decay\": None}]\n",
    "\n",
    "    grid = []\n",
    "    for n_feat, w in product(n_features_list, weight_opts):\n",
    "        hp = {\n",
    "            \"n_features_to_use\": n_feat,\n",
    "            **w,\n",
    "            \"use_gpu\": USE_GPU,\n",
    "            \"device\": FORCE_DEVICE,\n",
    "            \"seed\": SEED,\n",
    "        }\n",
    "        grid.append(hp)\n",
    "    return grid\n",
    "\n",
    "\n",
    "# --- 7) Run ---\n",
    "if USE_DYNAMIC_FI_PIPELINE:\n",
    "    grid = build_grid_dynamic_fi()\n",
    "    print(f\"Dynamic FI grid size (Setup III): {len(grid)} configurations.\")\n",
    "\n",
    "    shortlist = run_stageA(\n",
    "        model_name=MODEL_NAME,\n",
    "        model_ctor=lambda hp: ForecastModel(hp),\n",
    "        model_grid=grid,\n",
    "        X=X_ifo,  # dummy\n",
    "        y=y_fi,\n",
    "        cfg=cfg_obj,\n",
    "        X_full_lagged=X_full_lagged,\n",
    "        rolling_imp=rolling_imp,\n",
    "        keep_top_k_final=5,\n",
    "        min_survivors_per_block=5,\n",
    "    )\n",
    "\n",
    "    run_stageB(\n",
    "        model_name=MODEL_NAME,\n",
    "        model_ctor=lambda hp: ForecastModel(hp),\n",
    "        shortlist=shortlist,\n",
    "        X=X_ifo,  # dummy\n",
    "        y=y_fi,\n",
    "        cfg=cfg_obj,\n",
    "        X_full_lagged=X_full_lagged,\n",
    "        rolling_imp=rolling_imp,\n",
    "    )\n",
    "else:\n",
    "    grid = build_grid_full_fe()\n",
    "    print(f\"Full FE grid size (Setups I & II): {len(grid)} configurations.\")\n",
    "\n",
    "    shortlist = run_stageA(\n",
    "        model_name=MODEL_NAME,\n",
    "        model_ctor=lambda hp: ForecastModel(hp),\n",
    "        model_grid=grid,\n",
    "        X=X_ifo,\n",
    "        y=y,\n",
    "        cfg=cfg_obj,\n",
    "        keep_top_k_final=5,\n",
    "        min_survivors_per_block=5,\n",
    "    )\n",
    "\n",
    "    run_stageB(\n",
    "        model_name=MODEL_NAME,\n",
    "        model_ctor=lambda hp: ForecastModel(hp),\n",
    "        shortlist=shortlist,\n",
    "        X=X_ifo,\n",
    "        y=y,\n",
    "        cfg=cfg_obj,\n",
    "    )\n",
    "\n",
    "print(\"\\nTuning finished.\")\n"
   ],
   "id": "ea5eef511abadd0b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starte Tuning für: tabpfn_test ---\n",
      "INFO load_ifo_features: Renaming columns for validity.\n",
      "Dynamic FI Modus: 4320 Features geladen.\n",
      "Dynamic FI Grid Größe (Setup III): 1 Konfigurationen.\n",
      "[Stage A] Using DYNAMIC FI (track 3) pipeline.\n",
      "[Stage A][Block 1] train_end=180, OOS=181-200 | configs=1\n",
      "  - Config 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonasschernich/Documents/Masterarbeit/Code/src/models/TabPFN.py:73: UserWarning: GPU angefragt, aber weder CUDA noch (sicher nutzbares) MPS vorhanden -> 'cpu' verwendet.\n",
      "  warnings.warn(\"GPU angefragt, aber weder CUDA noch (sicher nutzbares) MPS vorhanden -> 'cpu' verwendet.\",\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    · Month 5/20 processed | running RMSE=1.6341\n",
      "    · Month 10/20 processed | running RMSE=1.3037\n",
      "    · Month 15/20 processed | running RMSE=1.2305\n",
      "    · Month 20/20 processed | running RMSE=1.1004\n",
      "[Stage A][Block 1] kept 1 configs (floor=5).\n",
      "[Stage A][Block 2] train_end=200, OOS=201-220 | configs=1\n",
      "  - Config 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonasschernich/Documents/Masterarbeit/Code/src/models/TabPFN.py:73: UserWarning: GPU angefragt, aber weder CUDA noch (sicher nutzbares) MPS vorhanden -> 'cpu' verwendet.\n",
      "  warnings.warn(\"GPU angefragt, aber weder CUDA noch (sicher nutzbares) MPS vorhanden -> 'cpu' verwendet.\",\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/regressor.py:563: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    · Month 5/20 processed | running RMSE=0.8830\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 204\u001B[0m\n\u001B[1;32m    201\u001B[0m     grid \u001B[38;5;241m=\u001B[39m build_grid_dynamic_fi()\n\u001B[1;32m    202\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDynamic FI Grid Größe (Setup III): \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(grid)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m Konfigurationen.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 204\u001B[0m     shortlist \u001B[38;5;241m=\u001B[39m \u001B[43mrun_stageA\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    205\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mMODEL_NAME\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    206\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_ctor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mhp\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mForecastModel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhp\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    207\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_grid\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgrid\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    208\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_ifo\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m# Dummy\u001B[39;49;00m\n\u001B[1;32m    209\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_fi\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    210\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcfg\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcfg_obj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    211\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX_full_lagged\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_full_lagged\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    212\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrolling_imp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrolling_imp\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    213\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkeep_top_k_final\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    214\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmin_survivors_per_block\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\n\u001B[1;32m    215\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    217\u001B[0m     run_stageB(\n\u001B[1;32m    218\u001B[0m         model_name\u001B[38;5;241m=\u001B[39mMODEL_NAME,\n\u001B[1;32m    219\u001B[0m         model_ctor\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m hp: ForecastModel(hp),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    225\u001B[0m         rolling_imp\u001B[38;5;241m=\u001B[39mrolling_imp\n\u001B[1;32m    226\u001B[0m     )\n\u001B[1;32m    228\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/Documents/Masterarbeit/Code/src/tuning.py:551\u001B[0m, in \u001B[0;36mrun_stageA\u001B[0;34m(model_name, model_ctor, model_grid, X, y, cfg, keep_top_k_final, min_survivors_per_block, X_full_lagged, rolling_imp)\u001B[0m\n\u001B[1;32m    548\u001B[0m         X_post_ev_np \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mnan_to_num(X_post_ev\u001B[38;5;241m.\u001B[39mvalues, nan\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.0\u001B[39m, posinf\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.0\u001B[39m, neginf\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.0\u001B[39m)\n\u001B[1;32m    549\u001B[0m         Xb_eval \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mhstack([Xb_eval, X_post_ev_np])\n\u001B[0;32m--> 551\u001B[0m y_hat \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_one\u001B[49m\u001B[43m(\u001B[49m\u001B[43mXb_eval\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    552\u001B[0m y_true \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mfloat\u001B[39m(y\u001B[38;5;241m.\u001B[39miloc[t \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m    554\u001B[0m y_true_block\u001B[38;5;241m.\u001B[39mappend(y_true)\n",
      "File \u001B[0;32m~/Documents/Masterarbeit/Code/src/models/TabPFN.py:197\u001B[0m, in \u001B[0;36mForecastModel.predict_one\u001B[0;34m(self, x_row)\u001B[0m\n\u001B[1;32m    195\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict_one\u001B[39m(\u001B[38;5;28mself\u001B[39m, x_row):\n\u001B[1;32m    196\u001B[0m     x \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(x_row)\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m--> 197\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mfloat\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m])\n",
      "File \u001B[0;32m~/Documents/Masterarbeit/Code/src/models/TabPFN.py:192\u001B[0m, in \u001B[0;36mForecastModel.predict\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    189\u001B[0m     X_np \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(X)\n\u001B[1;32m    191\u001B[0m X_std \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_standardize_apply(X_np)\n\u001B[0;32m--> 192\u001B[0m yhat \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_std\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    193\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39masarray(yhat, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mfloat\u001B[39m)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py:81\u001B[0m, in \u001B[0;36mContextDecorator.__call__.<locals>.inner\u001B[0;34m(*args, **kwds)\u001B[0m\n\u001B[1;32m     78\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[1;32m     79\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds):\n\u001B[1;32m     80\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_recreate_cm():\n\u001B[0;32m---> 81\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn_common_utils/telemetry/core/decorators.py:242\u001B[0m, in \u001B[0;36mtrack_model_call.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    240\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    241\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m--> 242\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_safe_call_with_telemetry\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    243\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_method\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparam_names\u001B[49m\n\u001B[1;32m    244\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn_common_utils/telemetry/core/decorators.py:286\u001B[0m, in \u001B[0;36m_safe_call_with_telemetry\u001B[0;34m(func, args, kwargs, model_method, param_names)\u001B[0m\n\u001B[1;32m    284\u001B[0m \u001B[38;5;66;03m# Step 2: Run the actual function\u001B[39;00m\n\u001B[1;32m    285\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[0;32m--> 286\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    287\u001B[0m duration_ms \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m((time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m1000\u001B[39m)\n\u001B[1;32m    289\u001B[0m \u001B[38;5;66;03m# Step 3: Send telemetry event\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/regressor.py:870\u001B[0m, in \u001B[0;36mTabPFNRegressor.predict\u001B[0;34m(self, X, output_type, quantiles)\u001B[0m\n\u001B[1;32m    863\u001B[0m X \u001B[38;5;241m=\u001B[39m process_text_na_dataframe(X, ord_encoder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreprocessor_)  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m    865\u001B[0m \u001B[38;5;66;03m# Runs over iteration engine\u001B[39;00m\n\u001B[1;32m    866\u001B[0m (\n\u001B[1;32m    867\u001B[0m     _,\n\u001B[1;32m    868\u001B[0m     outputs,  \u001B[38;5;66;03m# list of tensors [N_est, N_samples, N_borders] (after forward)\u001B[39;00m\n\u001B[1;32m    869\u001B[0m     borders,  \u001B[38;5;66;03m# list of numpy arrays containing borders for each estimator\u001B[39;00m\n\u001B[0;32m--> 870\u001B[0m ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_inference_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    872\u001B[0m \u001B[38;5;66;03m# --- Translate probs, average, get final logits ---\u001B[39;00m\n\u001B[1;32m    873\u001B[0m transformed_logits \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    874\u001B[0m     translate_probs_across_borders(\n\u001B[1;32m    875\u001B[0m         logits,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    879\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m logits, borders_t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(outputs, borders)\n\u001B[1;32m    880\u001B[0m ]\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/regressor.py:998\u001B[0m, in \u001B[0;36mTabPFNRegressor.forward\u001B[0;34m(self, X, use_inference_mode)\u001B[0m\n\u001B[1;32m    995\u001B[0m borders: \u001B[38;5;28mlist\u001B[39m[np\u001B[38;5;241m.\u001B[39mndarray] \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    997\u001B[0m \u001B[38;5;66;03m# Iterate over estimators\u001B[39;00m\n\u001B[0;32m--> 998\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43moutput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecutor_\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miter_outputs\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    999\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1000\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevices\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevices_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1001\u001B[0m \u001B[43m    \u001B[49m\u001B[43mautocast\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43muse_autocast_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1002\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m   1003\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msoftmax_temperature\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m!=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m:\u001B[49m\n\u001B[1;32m   1004\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43moutput\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msoftmax_temperature\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# noqa: PLW2901\u001B[39;49;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/inference.py:507\u001B[0m, in \u001B[0;36mInferenceEngineCachePreprocessing.iter_outputs\u001B[0;34m(self, X, devices, autocast, only_return_standard_out)\u001B[0m\n\u001B[1;32m    491\u001B[0m model_forward_functions \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    492\u001B[0m     partial(\n\u001B[1;32m    493\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_model,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    503\u001B[0m     )\n\u001B[1;32m    504\u001B[0m )\n\u001B[1;32m    505\u001B[0m outputs \u001B[38;5;241m=\u001B[39m parallel_execute(devices, model_forward_functions)\n\u001B[0;32m--> 507\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43moutput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mzip\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mensemble_configs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m    508\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m_move_and_squeeze_output\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevices\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\n\u001B[1;32m    510\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minference_mode:\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/parallel_execute.py:58\u001B[0m, in \u001B[0;36mparallel_execute\u001B[0;34m(devices, functions)\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Evaluate the given functions in parallel across `devices`.\u001B[39;00m\n\u001B[1;32m     40\u001B[0m \n\u001B[1;32m     41\u001B[0m \u001B[38;5;124;03mThe function evaluations are parallelised using Python threads, so this will only\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;124;03m    as `functions`.\u001B[39;00m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(devices) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m     57\u001B[0m     \u001B[38;5;66;03m# If we only have one device then just use the current thread to avoid overhead.\u001B[39;00m\n\u001B[0;32m---> 58\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m _execute_in_current_thread(devices[\u001B[38;5;241m0\u001B[39m], functions)\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m _execute_with_multithreading(devices, functions)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/parallel_execute.py:67\u001B[0m, in \u001B[0;36m_execute_in_current_thread\u001B[0;34m(device, functions)\u001B[0m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_execute_in_current_thread\u001B[39m(\n\u001B[1;32m     64\u001B[0m     device: torch\u001B[38;5;241m.\u001B[39mdevice, functions: Iterable[ParallelFunction[R_co]]\n\u001B[1;32m     65\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Generator[R_co]:\n\u001B[1;32m     66\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m function \u001B[38;5;129;01min\u001B[39;00m functions:\n\u001B[0;32m---> 67\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_parallel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/inference.py:555\u001B[0m, in \u001B[0;36mInferenceEngineCachePreprocessing._call_model\u001B[0;34m(self, device, is_parallel, X_train, X_test, y_train, cat_ix, autocast, only_return_standard_out)\u001B[0m\n\u001B[1;32m    541\u001B[0m     MemoryUsageEstimator\u001B[38;5;241m.\u001B[39mreset_peak_memory_if_required(\n\u001B[1;32m    542\u001B[0m         save_peak_mem\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msave_peak_mem,\n\u001B[1;32m    543\u001B[0m         model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    548\u001B[0m         safety_factor\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1.2\u001B[39m,\n\u001B[1;32m    549\u001B[0m     )\n\u001B[1;32m    551\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m (\n\u001B[1;32m    552\u001B[0m     get_autocast_context(device, enabled\u001B[38;5;241m=\u001B[39mautocast),\n\u001B[1;32m    553\u001B[0m     torch\u001B[38;5;241m.\u001B[39minference_mode(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minference_mode),\n\u001B[1;32m    554\u001B[0m ):\n\u001B[0;32m--> 555\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    556\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX_full\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    557\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    558\u001B[0m \u001B[43m        \u001B[49m\u001B[43monly_return_standard_out\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43monly_return_standard_out\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    559\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcategorical_inds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatched_cat_ix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    560\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/architectures/base/transformer.py:549\u001B[0m, in \u001B[0;36mPerFeatureTransformer.forward\u001B[0;34m(***failed resolving arguments***)\u001B[0m\n\u001B[1;32m    541\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    542\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThere should be no NaNs in the encoded x and y.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    543\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCheck that you do not feed NaNs or use a NaN-handling enocder.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    544\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYour embedded x and y returned the following:\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    545\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtorch\u001B[38;5;241m.\u001B[39misnan(embedded_x)\u001B[38;5;241m.\u001B[39many()\u001B[38;5;132;01m=}\u001B[39;00m\u001B[38;5;124m | \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtorch\u001B[38;5;241m.\u001B[39misnan(embedded_y)\u001B[38;5;241m.\u001B[39many()\u001B[38;5;132;01m=}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    546\u001B[0m     )\n\u001B[1;32m    547\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m embedded_y, embedded_x\n\u001B[0;32m--> 549\u001B[0m encoder_out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransformer_encoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    550\u001B[0m \u001B[43m    \u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    551\u001B[0m \u001B[43m        \u001B[49m\u001B[43membedded_input\u001B[49m\n\u001B[1;32m    552\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransformer_decoder\u001B[49m\n\u001B[1;32m    553\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43membedded_input\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43msingle_eval_pos\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m    554\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    555\u001B[0m \u001B[43m    \u001B[49m\u001B[43msingle_eval_pos\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msingle_eval_pos\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    556\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache_trainset_representation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcache_trainset_representation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    557\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# b s f+1 e -> b s f+1 e\u001B[39;00m\n\u001B[1;32m    559\u001B[0m \u001B[38;5;66;03m# If we are using a decoder\u001B[39;00m\n\u001B[1;32m    560\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransformer_decoder:\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/architectures/base/transformer.py:94\u001B[0m, in \u001B[0;36mLayerStack.forward\u001B[0;34m(self, x, **kwargs)\u001B[0m\n\u001B[1;32m     92\u001B[0m         x \u001B[38;5;241m=\u001B[39m checkpoint(partial(layer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs), x, use_reentrant\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m     93\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 94\u001B[0m         x \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     96\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/architectures/base/layer.py:421\u001B[0m, in \u001B[0;36mPerFeatureEncoderLayer.forward\u001B[0;34m(self, state, single_eval_pos, cache_trainset_representation, att_src)\u001B[0m\n\u001B[1;32m    411\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[1;32m    412\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPre-norm implementation is wrong, as the residual should never\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    413\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m be layer normed here.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    414\u001B[0m     )\n\u001B[1;32m    415\u001B[0m     state \u001B[38;5;241m=\u001B[39m layer_norm(\n\u001B[1;32m    416\u001B[0m         state,\n\u001B[1;32m    417\u001B[0m         allow_inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    418\u001B[0m         save_peak_mem_factor\u001B[38;5;241m=\u001B[39msave_peak_mem_factor,\n\u001B[1;32m    419\u001B[0m     )\n\u001B[0;32m--> 421\u001B[0m state \u001B[38;5;241m=\u001B[39m \u001B[43msublayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    422\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpre_norm:\n\u001B[1;32m    423\u001B[0m     state \u001B[38;5;241m=\u001B[39m layer_norm(\n\u001B[1;32m    424\u001B[0m         state,\n\u001B[1;32m    425\u001B[0m         allow_inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    426\u001B[0m         save_peak_mem_factor\u001B[38;5;241m=\u001B[39msave_peak_mem_factor,\n\u001B[1;32m    427\u001B[0m     )\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/architectures/base/layer.py:335\u001B[0m, in \u001B[0;36mPerFeatureEncoderLayer.forward.<locals>.attn_between_items\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m    332\u001B[0m     new_x_test \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    334\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m single_eval_pos:\n\u001B[0;32m--> 335\u001B[0m     new_x_train \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mself_attn_between_items\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    336\u001B[0m \u001B[43m        \u001B[49m\u001B[43mx\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43msingle_eval_pos\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtranspose\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    337\u001B[0m \u001B[43m        \u001B[49m\u001B[43mx\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43msingle_eval_pos\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtranspose\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    338\u001B[0m \u001B[43m        \u001B[49m\u001B[43msave_peak_mem_factor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msave_peak_mem_factor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    339\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_kv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_trainset_representation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    340\u001B[0m \u001B[43m        \u001B[49m\u001B[43monly_cache_first_head_kv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    341\u001B[0m \u001B[43m        \u001B[49m\u001B[43madd_input\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    342\u001B[0m \u001B[43m        \u001B[49m\u001B[43mallow_inplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    343\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_cached_kv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    344\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m    345\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    346\u001B[0m     new_x_train \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/architectures/base/attention/full_attention.py:365\u001B[0m, in \u001B[0;36mMultiHeadAttention.forward\u001B[0;34m(self, x, x_kv, cache_kv, add_input, allow_inplace, save_peak_mem_factor, reuse_first_head_kv, only_cache_first_head_kv, use_cached_kv)\u001B[0m\n\u001B[1;32m    348\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_k_cache \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mempty(\n\u001B[1;32m    349\u001B[0m             batch_size,\n\u001B[1;32m    350\u001B[0m             seqlen_kv,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    354\u001B[0m             dtype\u001B[38;5;241m=\u001B[39mx\u001B[38;5;241m.\u001B[39mdtype,\n\u001B[1;32m    355\u001B[0m         )\n\u001B[1;32m    356\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_v_cache \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mempty(\n\u001B[1;32m    357\u001B[0m             batch_size,\n\u001B[1;32m    358\u001B[0m             seqlen_kv,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    362\u001B[0m             dtype\u001B[38;5;241m=\u001B[39mx\u001B[38;5;241m.\u001B[39mdtype,\n\u001B[1;32m    363\u001B[0m         )\n\u001B[0;32m--> 365\u001B[0m output: torch\u001B[38;5;241m.\u001B[39mTensor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_compute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    366\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    367\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx_kv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    368\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_k_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    369\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_v_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    370\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_kv_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    371\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache_kv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_kv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    372\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cached_kv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cached_kv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    373\u001B[0m \u001B[43m    \u001B[49m\u001B[43madd_input\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43madd_input\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    374\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_inplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_inplace\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    375\u001B[0m \u001B[43m    \u001B[49m\u001B[43msave_peak_mem_factor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msave_peak_mem_factor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    376\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreuse_first_head_kv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreuse_first_head_kv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    377\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    378\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output\u001B[38;5;241m.\u001B[39mreshape(x_shape_after_transpose[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m+\u001B[39m output\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m:])\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/architectures/base/memory.py:95\u001B[0m, in \u001B[0;36msupport_save_peak_mem_factor.<locals>.method_\u001B[0;34m(self, x, add_input, allow_inplace, save_peak_mem_factor, *args, **kwargs)\u001B[0m\n\u001B[1;32m     93\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m x_, \u001B[38;5;241m*\u001B[39margs_ \u001B[38;5;129;01min\u001B[39;00m split_args:\n\u001B[1;32m     94\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m add_input:\n\u001B[0;32m---> 95\u001B[0m         x_[:] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     96\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     97\u001B[0m         x_[:] \u001B[38;5;241m=\u001B[39m method(\u001B[38;5;28mself\u001B[39m, x_, \u001B[38;5;241m*\u001B[39margs_, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/architectures/base/attention/full_attention.py:515\u001B[0m, in \u001B[0;36mMultiHeadAttention._compute\u001B[0;34m(self, x, x_kv, k_cache, v_cache, kv_cache, cache_kv, use_cached_kv, reuse_first_head_kv)\u001B[0m\n\u001B[1;32m    502\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Attention computation.\u001B[39;00m\n\u001B[1;32m    503\u001B[0m \u001B[38;5;124;03mCalled by 'forward', potentially on shards, once shapes have been normalized.\u001B[39;00m\n\u001B[1;32m    504\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    505\u001B[0m q, k, v, kv, qkv \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_qkv(\n\u001B[1;32m    506\u001B[0m     x,\n\u001B[1;32m    507\u001B[0m     x_kv,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    513\u001B[0m     reuse_first_head_kv\u001B[38;5;241m=\u001B[39mreuse_first_head_kv,\n\u001B[1;32m    514\u001B[0m )\n\u001B[0;32m--> 515\u001B[0m attention_head_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mMultiHeadAttention\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_attention_heads\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    516\u001B[0m \u001B[43m    \u001B[49m\u001B[43mq\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    517\u001B[0m \u001B[43m    \u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    518\u001B[0m \u001B[43m    \u001B[49m\u001B[43mv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    519\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    520\u001B[0m \u001B[43m    \u001B[49m\u001B[43mqkv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    521\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout_p\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    522\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msoftmax_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    523\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    524\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39meinsum(\n\u001B[1;32m    525\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m... h d, h d s -> ... s\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    526\u001B[0m     attention_head_outputs,\n\u001B[1;32m    527\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_w_out,\n\u001B[1;32m    528\u001B[0m )\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tabpfn/architectures/base/attention/full_attention.py:696\u001B[0m, in \u001B[0;36mMultiHeadAttention.compute_attention_heads\u001B[0;34m(q, k, v, kv, qkv, dropout_p, softmax_scale)\u001B[0m\n\u001B[1;32m    687\u001B[0m         k \u001B[38;5;241m=\u001B[39m MultiHeadAttention\u001B[38;5;241m.\u001B[39mbroadcast_kv_across_heads(\n\u001B[1;32m    688\u001B[0m             k,\n\u001B[1;32m    689\u001B[0m             share_kv_across_n_heads,\n\u001B[1;32m    690\u001B[0m         )\n\u001B[1;32m    691\u001B[0m         v \u001B[38;5;241m=\u001B[39m MultiHeadAttention\u001B[38;5;241m.\u001B[39mbroadcast_kv_across_heads(\n\u001B[1;32m    692\u001B[0m             v,\n\u001B[1;32m    693\u001B[0m             share_kv_across_n_heads,\n\u001B[1;32m    694\u001B[0m         )\n\u001B[0;32m--> 696\u001B[0m     attention_head_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunctional\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscaled_dot_product_attention\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    697\u001B[0m \u001B[43m        \u001B[49m\u001B[43mq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtranspose\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    698\u001B[0m \u001B[43m        \u001B[49m\u001B[43mk\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtranspose\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    699\u001B[0m \u001B[43m        \u001B[49m\u001B[43mv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtranspose\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    700\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdropout_p\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdropout_p\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    701\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mextra_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    702\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    703\u001B[0m     attention_head_outputs \u001B[38;5;241m=\u001B[39m attention_head_outputs\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m    704\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
