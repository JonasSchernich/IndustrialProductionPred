{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T07:15:43.199331Z",
     "start_time": "2026-01-13T07:15:42.942808Z"
    }
   },
   "source": [
    "# # ==============================================================================\n",
    "# Masterarbeit Ensemble Tuning & Evaluation (Full Timeline 2011-2024)\n",
    "# ==============================================================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Projekt-Root finden ---\n",
    "def _locate_repo_root(start: Path) -> Path:\n",
    "    cur = start.resolve()\n",
    "    for _ in range(5):\n",
    "        if (cur / \"src\").exists(): return cur\n",
    "        if cur.parent == cur: break\n",
    "        cur = cur.parent\n",
    "    return start.resolve()\n",
    "\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "PROJECT_ROOT = _locate_repo_root(NOTEBOOK_DIR)\n",
    "os.environ[\"PROJECT_ROOT\"] = str(PROJECT_ROOT)\n",
    "if str(PROJECT_ROOT) not in sys.path: sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# Imports\n",
    "from src.config import GlobalConfig\n",
    "from src.evaluation import rmse, mae\n",
    "from src.models.ensemble import (\n",
    "    load_level0_pool,\n",
    "    load_calibration_pool,\n",
    "    equal_weight_ensemble,\n",
    "    trimmed_mean_ensemble,\n",
    "    median_ensemble,\n",
    "    fit_stacking_ensemble,\n",
    "    fit_ewa_ensemble,\n",
    ")\n",
    "\n",
    "print(f\"Projekt-Root: {PROJECT_ROOT}\")\n",
    "\n",
    "# --- KONFIGURATION ---\n",
    "# Die exakten Ordnernamen unter outputs/stageB/\n",
    "BASE_MODELS = [\n",
    "    \"elastic_net_without_target_700\",\n",
    "    \"lightgbm_without_target_mac\",\n",
    "    \"svr_without_target\",\n",
    "    \"tabpfn_without_target\",\n",
    "]\n",
    "\n",
    "STACKING_LAMBDAS = [1e-2, 0.1, 1.0]\n",
    "EWA_ETAS = [0.1, 0.3, 0.2, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 2, 3]\n",
    "EWA_DELTA = 0.95\n",
    "\n",
    "OUT_DIR = PROJECT_ROOT / \"outputs\" / \"ensembles\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- DATEN LADEN (Stage A + Stage B) ---\n",
    "\n",
    "print(\"\\n1. Lade Stage B (Test Set)...\")\n",
    "try:\n",
    "    pool_test = load_level0_pool(BASE_MODELS)\n",
    "    F_test = pool_test.F\n",
    "    y_test = pool_test.y_true\n",
    "    dates_test = pool_test.dates\n",
    "    print(f\"   Test Period: {dates_test[0].date()} bis {dates_test[-1].date()} (n={len(dates_test)})\")\n",
    "except Exception as e:\n",
    "    print(f\"   FEHLER: Konnte Stage B nicht laden: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\"\\n2. Lade Stage A (Calibration Set, Block 3)...\")\n",
    "try:\n",
    "    pool_cal = load_calibration_pool(BASE_MODELS)\n",
    "    F_cal = pool_cal.F\n",
    "    y_cal = pool_cal.y_true\n",
    "    dates_cal = pool_cal.dates\n",
    "    print(f\"   Cal Period:  {dates_cal[0].date()} bis {dates_cal[-1].date()} (n={len(dates_cal)})\")\n",
    "\n",
    "    # Merge für Training (Historie A + B)\n",
    "    F_full = pd.concat([F_cal, F_test])\n",
    "    y_full = pd.concat([y_cal, y_test])\n",
    "    # Sicherstellen, dass Index sortiert ist\n",
    "    F_full.sort_index(inplace=True)\n",
    "    y_full.sort_index(inplace=True)\n",
    "\n",
    "    cal_dates_list = list(dates_cal) # Wir trainieren NUR auf A\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"   WARNUNG: Konnte Stage A nicht laden ({e}).\")\n",
    "    print(\"   Fallback: Nutze die ersten 24 Monate von Stage B als Kalibrierung (Verlust von Testdaten!).\")\n",
    "    split_idx = 24\n",
    "    F_full = F_test\n",
    "    y_full = y_test\n",
    "    cal_dates_list = list(dates_test[:split_idx])\n",
    "    # Für die Evaluation später schneiden wir dann ab\n",
    "\n",
    "# --- ENSEMBLE BERECHNUNG ---\n",
    "\n",
    "print(\"\\n--- Benchmark Ensembles (Equal/Trim/Median) ---\")\n",
    "# Diese brauchen kein Training, können direkt auf Test berechnet werden\n",
    "ens_equal = equal_weight_ensemble(F_test)\n",
    "ens_trim10 = trimmed_mean_ensemble(F_test, alpha=0.10)\n",
    "ens_median = median_ensemble(F_test)\n",
    "\n",
    "print(\"\\n--- Stacking (Learned on Stage A) ---\")\n",
    "stack_res = fit_stacking_ensemble(\n",
    "    y=y_full,\n",
    "    F=F_full,\n",
    "    cal_dates=cal_dates_list,\n",
    "    lambdas=STACKING_LAMBDAS\n",
    ")\n",
    "# Extrahiere Vorhersagen nur für Stage B\n",
    "ens_stack = stack_res.y_pred.loc[dates_test]\n",
    "\n",
    "print(f\"  Best Lambda: {stack_res.lambda_opt}\")\n",
    "print(\"  Weights (from Stage A):\")\n",
    "print(stack_res.weights)\n",
    "\n",
    "print(\"\\n--- EWA (Online Learning A -> B) ---\")\n",
    "# EWA läuft über die ganze Historie (A+B), damit es bei B schon \"schlau\" ist\n",
    "ewa_res = fit_ewa_ensemble(\n",
    "    y=y_full,\n",
    "    F=F_full,\n",
    "    cal_dates=cal_dates_list, # Tuning von Eta auf A\n",
    "    etas=EWA_ETAS,\n",
    "    delta=EWA_DELTA\n",
    ")\n",
    "ens_ewa = ewa_res.y_pred.loc[dates_test]\n",
    "\n",
    "print(f\"  Best Eta: {ewa_res.eta_opt}\")\n",
    "\n",
    "# --- EVALUATION ---\n",
    "\n",
    "df_ens = pd.DataFrame(index=dates_test)\n",
    "df_ens[\"y_true\"] = y_test\n",
    "for m in BASE_MODELS:\n",
    "    df_ens[f\"base_{m}\"] = F_test[m]\n",
    "\n",
    "df_ens[\"ens_equal\"] = ens_equal\n",
    "df_ens[\"ens_stack\"] = ens_stack\n",
    "df_ens[\"ens_ewa\"] = ens_ewa\n",
    "df_ens[\"dispersion\"] = F_test.std(axis=1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"RESULTS (Full Stage B: {dates_test[0].date()} - {dates_test[-1].date()})\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def score(y, y_hat, label):\n",
    "    r = rmse(y, y_hat)\n",
    "    print(f\"{label:<25} | RMSE: {r:.4f}\")\n",
    "\n",
    "print(\"--- Base Models ---\")\n",
    "for m in BASE_MODELS:\n",
    "    score(y_test, F_test[m], m)\n",
    "\n",
    "print(\"\\n--- Ensembles ---\")\n",
    "score(y_test, ens_equal, \"Equal-Weight\")\n",
    "score(y_test, ens_stack, \"Stacked (Static)\")\n",
    "score(y_test, ens_ewa, \"EWA (Online)\")\n",
    "\n",
    "# Speichern\n",
    "df_ens.to_csv(OUT_DIR / \"ensemble_predictions.csv\")\n",
    "print(f\"\\nSaved to {OUT_DIR}\")\n",
    "# ==============================================================================\n",
    "# 12. Export als \"Fake\" Stage B Modelle für einfache Vergleichbarkeit\n",
    "# ==============================================================================\n",
    "# Ziel: Erstelle Ordnerstruktur wie bei normalen Modellen:\n",
    "# outputs/stageB/ensemble_stacking/monthly/preds.csv\n",
    "# outputs/stageB/ensemble_ewa/monthly/preds.csv\n",
    "# ...\n",
    "\n",
    "def export_ensemble_to_stageB(\n",
    "    df_results: pd.DataFrame,\n",
    "    col_name: str,\n",
    "    model_export_name: str,\n",
    "    base_dir: Path\n",
    "):\n",
    "    \"\"\"\n",
    "    Speichert eine Ensemble-Spalte im Format der Stage B Predictions.\n",
    "    \"\"\"\n",
    "    # Zielverzeichnis erstellen\n",
    "    model_dir = base_dir / \"stageB\" / model_export_name\n",
    "    monthly_dir = model_dir / \"monthly\"\n",
    "    summary_dir = model_dir / \"summary\"\n",
    "\n",
    "    monthly_dir.mkdir(parents=True, exist_ok=True)\n",
    "    summary_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 1. preds.csv erstellen\n",
    "    # Das Format muss exakt den anderen Modellen entsprechen\n",
    "    df_out = pd.DataFrame()\n",
    "    df_out[\"date_t_plus_1\"] = df_results.index\n",
    "    # Wir brauchen eine Dummy 't' Spalte (Origin), nehmen wir einfach Monat davor\n",
    "    df_out[\"t\"] = df_results.index - pd.DateOffset(months=1)\n",
    "    df_out[\"y_true\"] = df_results[\"y_true\"].values\n",
    "    df_out[\"y_pred\"] = df_results[col_name].values\n",
    "\n",
    "    # Metadaten faken, damit die Analysis-Skripte nicht abstürzen\n",
    "    df_out[\"config_id\"] = \"ensemble_v1\" # Dummy Config ID\n",
    "    df_out[\"is_active\"] = True          # Ensembles sind immer \"aktiv\"\n",
    "\n",
    "    # Speichern\n",
    "    out_path = monthly_dir / \"preds.csv\"\n",
    "    df_out.to_csv(out_path, index=False)\n",
    "    print(f\"  Exportiert: {out_path}\")\n",
    "\n",
    "    # 2. summary.csv erstellen (wird oft zum Laden der Configs gesucht)\n",
    "    # Berechne RMSE für dieses Ensemble\n",
    "    mse = ((df_out[\"y_true\"] - df_out[\"y_pred\"])**2).mean()\n",
    "    rmse_val = np.sqrt(mse)\n",
    "\n",
    "    df_sum = pd.DataFrame([{\n",
    "        \"config_id\": \"ensemble_v1\",\n",
    "        \"model\": model_export_name,\n",
    "        \"rmse_overall\": rmse_val, # Gesamt-RMSE\n",
    "        \"setup_name\": \"Ensemble\"\n",
    "    }])\n",
    "    df_sum.to_csv(summary_dir / \"summary.csv\", index=False)\n",
    "\n",
    "print(\"\\n--- Exportiere Ensembles in Stage B Struktur ---\")\n",
    "\n",
    "# Mapping: Spaltenname im DataFrame -> Name des Ordners in outputs/stageB\n",
    "ensembles_to_export = {\n",
    "    \"ens_equal\":  \"ensemble_equal_weight\",\n",
    "    \"ens_trim10\": \"ensemble_trimmed\",\n",
    "    \"ens_median\": \"ensemble_median\",\n",
    "    \"ens_stack\":  \"ensemble_stacking\",\n",
    "    \"ens_ewa\":    \"ensemble_ewa\"\n",
    "}\n",
    "\n",
    "OUTPUTS_ROOT = PROJECT_ROOT / \"outputs\"\n",
    "\n",
    "for col, folder_name in ensembles_to_export.items():\n",
    "    if col in df_ens.columns:\n",
    "        export_ensemble_to_stageB(df_ens, col, folder_name, OUTPUTS_ROOT)\n",
    "\n",
    "print(\"\\nFertig! Die Ensembles sind jetzt bereit für die Vergleichs-Notebooks.\")"
   ],
   "id": "10dae65afde5a7eb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projekt-Root: /Users/jonasschernich/Documents/Masterarbeit/Code\n",
      "\n",
      "1. Lade Stage B (Test Set)...\n",
      "   Test Period: 2011-03-01 bis 2024-12-01 (n=166)\n",
      "\n",
      "2. Lade Stage A (Calibration Set, Block 3)...\n",
      "   Cal Period:  2009-07-01 bis 2011-02-01 (n=20)\n",
      "\n",
      "--- Benchmark Ensembles (Equal/Trim/Median) ---\n",
      "\n",
      "--- Stacking (Learned on Stage A) ---\n",
      "  Best Lambda: 0.01\n",
      "  Weights (from Stage A):\n",
      "elastic_net_without_target_700    4.858722e-01\n",
      "lightgbm_without_target_mac       1.721713e-16\n",
      "svr_without_target                2.711475e-01\n",
      "tabpfn_without_target             2.429803e-01\n",
      "Name: weights, dtype: float64\n",
      "\n",
      "--- EWA (Online Learning A -> B) ---\n",
      "  Best Eta: 0.2\n",
      "\n",
      "============================================================\n",
      "RESULTS (Full Stage B: 2011-03-01 - 2024-12-01)\n",
      "============================================================\n",
      "--- Base Models ---\n",
      "elastic_net_without_target_700 | RMSE: 2.3126\n",
      "lightgbm_without_target_mac | RMSE: 2.3156\n",
      "svr_without_target        | RMSE: 2.3072\n",
      "tabpfn_without_target     | RMSE: 2.1976\n",
      "\n",
      "--- Ensembles ---\n",
      "Equal-Weight              | RMSE: 2.2398\n",
      "Stacked (Static)          | RMSE: 2.2363\n",
      "EWA (Online)              | RMSE: 2.2411\n",
      "\n",
      "Saved to /Users/jonasschernich/Documents/Masterarbeit/Code/outputs/ensembles\n",
      "\n",
      "--- Exportiere Ensembles in Stage B Struktur ---\n",
      "  Exportiert: /Users/jonasschernich/Documents/Masterarbeit/Code/outputs/stageB/ensemble_equal_weight/monthly/preds.csv\n",
      "  Exportiert: /Users/jonasschernich/Documents/Masterarbeit/Code/outputs/stageB/ensemble_stacking/monthly/preds.csv\n",
      "  Exportiert: /Users/jonasschernich/Documents/Masterarbeit/Code/outputs/stageB/ensemble_ewa/monthly/preds.csv\n",
      "\n",
      "Fertig! Die Ensembles sind jetzt bereit für die Vergleichs-Notebooks.\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
