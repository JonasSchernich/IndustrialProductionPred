{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ==============================================================================\n",
    "# Ensemble Tuning & Evaluation\n",
    "# ==============================================================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt  # noqa: F401  # used in notebooks\n",
    "\n",
    "# --- Locate project root ---\n",
    "def _locate_repo_root(start: Path) -> Path:\n",
    "    cur = start.resolve()\n",
    "    for _ in range(5):\n",
    "        if (cur / \"src\").exists():\n",
    "            return cur\n",
    "        if cur.parent == cur:\n",
    "            break\n",
    "        cur = cur.parent\n",
    "    return start.resolve()\n",
    "\n",
    "\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "PROJECT_ROOT = _locate_repo_root(NOTEBOOK_DIR)\n",
    "os.environ[\"PROJECT_ROOT\"] = str(PROJECT_ROOT)\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# Imports\n",
    "from src.config import GlobalConfig  # noqa: F401\n",
    "from src.evaluation import rmse, mae  # noqa: F401\n",
    "from src.models.ensemble import (\n",
    "    load_level0_pool,\n",
    "    load_calibration_pool,\n",
    "    equal_weight_ensemble,\n",
    "    trimmed_mean_ensemble,\n",
    "    median_ensemble,\n",
    "    fit_stacking_ensemble,\n",
    "    fit_ewa_ensemble,\n",
    ")\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "\n",
    "# --- CONFIG ---\n",
    "# Exact folder names under outputs/stageB/\n",
    "BASE_MODELS = [\n",
    "    \"elastic_net_with_target_700\",\n",
    "    \"lightgbm_with_target_mac\",\n",
    "    \"svr_with_target\",\n",
    "    \"tabpfn_with_target\",\n",
    "]\n",
    "\n",
    "STACKING_LAMBDAS = [1e-2, 0.1, 1.0]\n",
    "EWA_ETAS = [0.1, 0.3, 0.2, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 2, 3]\n",
    "EWA_DELTA = 0.95\n",
    "\n",
    "OUT_DIR = PROJECT_ROOT / \"outputs\" / \"ensembles\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- LOAD DATA (Stage A + Stage B) ---\n",
    "\n",
    "print(\"\\n1) Loading Stage B (test set)...\")\n",
    "try:\n",
    "    pool_test = load_level0_pool(BASE_MODELS)\n",
    "    F_test = pool_test.F\n",
    "    y_test = pool_test.y_true\n",
    "    dates_test = pool_test.dates\n",
    "    print(f\"   Test period: {dates_test[0].date()} to {dates_test[-1].date()} (n={len(dates_test)})\")\n",
    "except Exception as e:\n",
    "    print(f\"   ERROR: Could not load Stage B: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\"\\n2) Loading Stage A (calibration set, block 3)...\")\n",
    "try:\n",
    "    pool_cal = load_calibration_pool(BASE_MODELS)\n",
    "    F_cal = pool_cal.F\n",
    "    y_cal = pool_cal.y_true\n",
    "    dates_cal = pool_cal.dates\n",
    "    print(f\"   Cal period:  {dates_cal[0].date()} to {dates_cal[-1].date()} (n={len(dates_cal)})\")\n",
    "\n",
    "    # Merge history for training (A + B)\n",
    "    F_full = pd.concat([F_cal, F_test])\n",
    "    y_full = pd.concat([y_cal, y_test])\n",
    "\n",
    "    # Keep index sorted\n",
    "    F_full.sort_index(inplace=True)\n",
    "    y_full.sort_index(inplace=True)\n",
    "\n",
    "    # Train/tune only on Stage A dates\n",
    "    cal_dates_list = list(dates_cal)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"   WARNING: Could not load Stage A ({e}).\")\n",
    "    print(\"   Fallback: using the first 24 months of Stage B for calibration (reduces test data!).\")\n",
    "    split_idx = 24\n",
    "    F_full = F_test\n",
    "    y_full = y_test\n",
    "    cal_dates_list = list(dates_test[:split_idx])\n",
    "\n",
    "# --- ENSEMBLES ---\n",
    "\n",
    "print(\"\\n--- Benchmark ensembles (equal/trimmed/median) ---\")\n",
    "ens_equal = equal_weight_ensemble(F_test)\n",
    "ens_trim10 = trimmed_mean_ensemble(F_test, alpha=0.10)\n",
    "ens_median = median_ensemble(F_test)\n",
    "\n",
    "print(\"\\n--- Stacking (trained on Stage A) ---\")\n",
    "stack_res = fit_stacking_ensemble(\n",
    "    y=y_full,\n",
    "    F=F_full,\n",
    "    cal_dates=cal_dates_list,\n",
    "    lambdas=STACKING_LAMBDAS,\n",
    ")\n",
    "ens_stack = stack_res.y_pred.loc[dates_test]\n",
    "\n",
    "print(f\"  Best lambda: {stack_res.lambda_opt}\")\n",
    "print(\"  Weights (from Stage A):\")\n",
    "print(stack_res.weights)\n",
    "\n",
    "print(\"\\n--- EWA (online learning A -> B) ---\")\n",
    "ewa_res = fit_ewa_ensemble(\n",
    "    y=y_full,\n",
    "    F=F_full,\n",
    "    cal_dates=cal_dates_list,  # tune eta on Stage A\n",
    "    etas=EWA_ETAS,\n",
    "    delta=EWA_DELTA,\n",
    ")\n",
    "ens_ewa = ewa_res.y_pred.loc[dates_test]\n",
    "\n",
    "print(f\"  Best eta: {ewa_res.eta_opt}\")\n",
    "\n",
    "# --- EVALUATION ---\n",
    "\n",
    "df_ens = pd.DataFrame(index=dates_test)\n",
    "df_ens[\"y_true\"] = y_test\n",
    "for m in BASE_MODELS:\n",
    "    df_ens[f\"base_{m}\"] = F_test[m]\n",
    "\n",
    "df_ens[\"ens_equal\"] = ens_equal\n",
    "df_ens[\"ens_stack\"] = ens_stack\n",
    "df_ens[\"ens_ewa\"] = ens_ewa\n",
    "df_ens[\"dispersion\"] = F_test.std(axis=1)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"RESULTS (Full Stage B: {dates_test[0].date()} - {dates_test[-1].date()})\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "\n",
    "def score(y, y_hat, label):\n",
    "    r = rmse(y, y_hat)\n",
    "    print(f\"{label:<25} | RMSE: {r:.4f}\")\n",
    "\n",
    "\n",
    "print(\"--- Base models ---\")\n",
    "for m in BASE_MODELS:\n",
    "    score(y_test, F_test[m], m)\n",
    "\n",
    "print(\"\\n--- Ensembles ---\")\n",
    "score(y_test, ens_equal, \"Equal-weight\")\n",
    "score(y_test, ens_stack, \"Stacked (static)\")\n",
    "score(y_test, ens_ewa, \"EWA (online)\")\n",
    "\n",
    "# Save\n",
    "df_ens.to_csv(OUT_DIR / \"ensemble_predictions.csv\")\n",
    "print(f\"\\nSaved to {OUT_DIR}\")\n",
    "\n",
    "\n",
    "def export_ensemble_to_stageB(\n",
    "    df_results: pd.DataFrame,\n",
    "    col_name: str,\n",
    "    model_export_name: str,\n",
    "    base_dir: Path,\n",
    "):\n",
    "    \"\"\"Save one ensemble column in the Stage B prediction format.\"\"\"\n",
    "    model_dir = base_dir / \"stageB\" / model_export_name\n",
    "    monthly_dir = model_dir / \"monthly\"\n",
    "    summary_dir = model_dir / \"summary\"\n",
    "\n",
    "    monthly_dir.mkdir(parents=True, exist_ok=True)\n",
    "    summary_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 1) preds.csv (match the format of other models)\n",
    "    df_out = pd.DataFrame()\n",
    "    df_out[\"date_t_plus_1\"] = df_results.index\n",
    "    df_out[\"t\"] = df_results.index - pd.DateOffset(months=1)  # dummy origin date\n",
    "    df_out[\"y_true\"] = df_results[\"y_true\"].values\n",
    "    df_out[\"y_pred\"] = df_results[col_name].values\n",
    "\n",
    "    # Fake metadata so analysis scripts keep working\n",
    "    df_out[\"config_id\"] = \"ensemble_v1\"\n",
    "    df_out[\"is_active\"] = True\n",
    "\n",
    "    out_path = monthly_dir / \"preds.csv\"\n",
    "    df_out.to_csv(out_path, index=False)\n",
    "    print(f\"  Exported: {out_path}\")\n",
    "\n",
    "    # 2) summary.csv (often used to load configs)\n",
    "    mse = ((df_out[\"y_true\"] - df_out[\"y_pred\"]) ** 2).mean()\n",
    "    rmse_val = np.sqrt(mse)\n",
    "\n",
    "    df_sum = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"config_id\": \"ensemble_v1\",\n",
    "                \"model\": model_export_name,\n",
    "                \"rmse_overall\": rmse_val,\n",
    "                \"setup_name\": \"Ensemble\",\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    df_sum.to_csv(summary_dir / \"summary.csv\", index=False)\n",
    "\n",
    "\n",
    "print(\"\\n--- Exporting ensembles into Stage B structure ---\")\n",
    "\n",
    "# Mapping: df column name -> folder name under outputs/stageB/\n",
    "ensembles_to_export = {\n",
    "    \"ens_equal\": \"ensemble_equal_weight\",\n",
    "    \"ens_trim10\": \"ensemble_trimmed\",\n",
    "    \"ens_median\": \"ensemble_median\",\n",
    "    \"ens_stack\": \"ensemble_stacking\",\n",
    "    \"ens_ewa\": \"ensemble_ewa\",\n",
    "}\n",
    "\n",
    "OUTPUTS_ROOT = PROJECT_ROOT / \"outputs\"\n",
    "\n",
    "for col, folder_name in ensembles_to_export.items():\n",
    "    if col in df_ens.columns:\n",
    "        export_ensemble_to_stageB(df_ens, col, folder_name, OUTPUTS_ROOT)\n",
    "\n",
    "print(\"\\nDone! The ensembles are now ready for the comparison notebooks.\")\n"
   ],
   "id": "10dae65afde5a7eb",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
