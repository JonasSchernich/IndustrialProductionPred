{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T13:30:51.808411Z",
     "start_time": "2025-11-11T13:30:51.259483Z"
    }
   },
   "source": [
    "\n",
    "# notebooks/ensemble_eval.py\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.4f}')\n",
    "\n",
    "# --- Pfad-Setup --------------------------------------------------------------\n",
    "def _locate_repo_root(start: Path) -> Path:\n",
    "    cur = start.resolve()\n",
    "    for _ in range(6):\n",
    "        if (cur / \"src\").exists():\n",
    "            return cur\n",
    "        if cur.parent == cur:\n",
    "            break\n",
    "        cur = cur.parent\n",
    "    return start.resolve()\n",
    "\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "PROJECT_ROOT = _locate_repo_root(NOTEBOOK_DIR)\n",
    "os.environ[\"PROJECT_ROOT\"] = str(PROJECT_ROOT)\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(\"PROJECT_ROOT =\", PROJECT_ROOT)\n",
    "\n",
    "# --- Imports -----------------------------------------------------------------\n",
    "from src.config import GlobalConfig, OUTPUTS\n",
    "from src.io_timesplits import load_target\n",
    "from src.evaluation import rmse, mae\n",
    "from src.models.ensemble import (\n",
    "    load_level1_data,\n",
    "    get_pred_cols,\n",
    "    apply_equal_weight,\n",
    "    apply_trimmed_mean,   # use_median=True möglich\n",
    "    apply_bates_granger,\n",
    "    apply_ewa,\n",
    "    tune_stacking_weights,\n",
    "    apply_stacking,\n",
    "    save_ensemble_predictions,\n",
    "    rmse_table,\n",
    ")\n",
    "\n",
    "# --- Setupwahl ---------------------------------------------------------------\n",
    "# Welches Setup (Suffix in den Modellordnern)?\n",
    "# Erwartete Ordnerstruktur der Basismodelle:\n",
    "#   outputs/stageA/<model>_setup_I/...\n",
    "#   outputs/stageB/<model>_setup_I/...\n",
    "MODEL_SETUP = \"I\"  # \"I\" | \"II\" | \"III\"\n",
    "\n",
    "# --- Konfiguration -----------------------------------------------------------\n",
    "# Basismodelle (Präfix vor '_setup_<X>')\n",
    "MODEL_NAMES = [\n",
    "    #\"extra_trees\",\n",
    "    #\"svr\",\n",
    "    \"sfm\",\n",
    "     \"lgbm\",\n",
    "    # \"tabpfn\",\n",
    "]\n",
    "\n",
    "# Daraus die konkreten \"Tags\" für dieses Setup bauen\n",
    "MODEL_TAGS = [f\"{name}_setup_{MODEL_SETUP}\" for name in MODEL_NAMES]\n",
    "\n",
    "BG_WINDOW = 24\n",
    "EWA_ETA   = 0.1\n",
    "EWA_DELTA = 1.0\n",
    "STACKING_RIDGE_LAMBDA = 0.1\n",
    "\n",
    "print(f\"[INFO] Modell-Setup: {MODEL_SETUP}\")\n",
    "print(f\"[INFO] Modell-Tags: {MODEL_TAGS}\")\n",
    "print(f\"[INFO] OUTPUTS-Basis: {OUTPUTS}\")\n",
    "\n",
    "# --- 1) Zielvariable laden ---------------------------------------------------\n",
    "cfg = GlobalConfig(preset=\"thesis\")\n",
    "y_full = load_target()\n",
    "\n",
    "# --- 2) Level-1 Daten laden: Stage A (für Stacking-Fit) ---------------------\n",
    "print(\"[INFO] Lade Stage-A Level-1 Daten (echte OOS für Stacking-Fit) ...\")\n",
    "df_l1_A = load_level1_data(\n",
    "    model_tags=MODEL_TAGS,\n",
    "    base_dir=OUTPUTS,\n",
    "    y_true_series=y_full,\n",
    "    stage=\"A\",                     # <- Stage-Schalter: Stage A\n",
    ")\n",
    "pred_cols_A = get_pred_cols(df_l1_A)\n",
    "if len(pred_cols_A) < 2:\n",
    "    raise RuntimeError(\n",
    "        f\"Zu wenige Modelle in Stage A gefunden (gefunden: {pred_cols_A}). Mindestens 2 benötigt.\"\n",
    "    )\n",
    "print(df_l1_A.head())\n",
    "\n",
    "# --- 3) Stacking-Gewichte auf Stage A fitten & einfrieren -------------------\n",
    "print(\"[INFO] Tune Stacking-Gewichte auf Stage-A OOS ...\")\n",
    "stack_weights = tune_stacking_weights(\n",
    "    df_tune=df_l1_A,\n",
    "    pred_cols=pred_cols_A,\n",
    "    ridge_lambda=STACKING_RIDGE_LAMBDA,\n",
    ")\n",
    "print(\"\\n--- Gefrorene Stacking-Gewichte ---\")\n",
    "print(pd.Series(stack_weights, index=pred_cols_A).sort_values(ascending=False))\n",
    "print(f\"Summe: {stack_weights.sum():.6f}\")\n",
    "\n",
    "# --- 4) Stage B laden (für Anwendung/Evaluierung) ---------------------------\n",
    "print(\"[INFO] Lade Stage-B Level-1 Daten (Anwendung/Evaluierung) ...\")\n",
    "df_l1_B = load_level1_data(\n",
    "    model_tags=MODEL_TAGS,\n",
    "    base_dir=OUTPUTS,\n",
    "    y_true_series=y_full,\n",
    "    stage=\"B\",                     # <- Stage-Schalter: Stage B\n",
    ")\n",
    "pred_cols_B = get_pred_cols(df_l1_B)\n",
    "print(df_l1_B.head())\n",
    "\n",
    "# --- 5) Ensembles berechnen (auf vollem Stage-B-Stream) ---------------------\n",
    "res = df_l1_B.copy()\n",
    "\n",
    "# Statisch / Frozen\n",
    "res[\"ENS_EqualWeight\"] = apply_equal_weight(res, pred_cols_B)\n",
    "res[\"ENS_Median\"]      = apply_trimmed_mean(res, pred_cols_B, use_median=True)\n",
    "\n",
    "# Stacking: ACHTUNG -> Spaltenreihenfolge zwischen Stage A & B angleichen\n",
    "# (falls Modelle in A/B-Join unterschiedlich)\n",
    "order = [c for c in pred_cols_A if c in pred_cols_B]\n",
    "if len(order) != len(pred_cols_A):\n",
    "    # Falls Stage B weniger Spalten hat, normalisiere die Gewichte entsprechend\n",
    "    idxs = [i for i, c in enumerate(pred_cols_A) if c in order]\n",
    "    w = stack_weights[idxs]\n",
    "    w = w / (w.sum() + 1e-12)\n",
    "    res[\"ENS_Stacking\"] = apply_stacking(res, order, w)\n",
    "else:\n",
    "    res[\"ENS_Stacking\"] = apply_stacking(res, pred_cols_A, stack_weights)\n",
    "\n",
    "# Dynamisch (BG/EWA) – auf dem gesamten Stage-B-Stream (keine Kalstart-Bias)\n",
    "res[\"ENS_BG_24M\"]     = apply_bates_granger(df_l1_B, pred_cols_B, window=BG_WINDOW)\n",
    "res[\"ENS_EWA_eta0.1\"] = apply_ewa(df_l1_B, pred_cols_B, eta=EWA_ETA, delta=EWA_DELTA)\n",
    "\n",
    "# --- 6) RMSE-Tabelle ---------------------------------------------------------\n",
    "all_cols = pred_cols_B + [c for c in res.columns if c.startswith(\"ENS_\")]\n",
    "rmse_dict = {col: rmse(res[\"y_true\"], res[col]) for col in all_cols}\n",
    "df_final_rmse = (\n",
    "    pd.Series(rmse_dict)\n",
    "    .sort_values()\n",
    "    .to_frame(\"RMSE\")\n",
    "    .rename_axis(\"Model\")\n",
    ")\n",
    "\n",
    "print(\"\\n--- Finale RMSE (Stage B, kompletter OOS-Stream) ---\")\n",
    "print(df_final_rmse)\n",
    "\n",
    "# --- 7) (Optional) Speichern -------------------------------------------------\n",
    "SAVE_ENSEMBLE = False\n",
    "RUN_NAME = f\"ensemble_setup_{MODEL_SETUP}\"\n",
    "\n",
    "if SAVE_ENSEMBLE:\n",
    "    # Basispfad für Ensemble-Outputs (separat von Basismodell-Läufen)\n",
    "    ENSEMBLE_BASE_DIR = OUTPUTS / \"stageB\" / \"ensemble\"\n",
    "    ens_series = {col: res[col] for col in res.columns if col.startswith(\"ENS_\")}\n",
    "\n",
    "    # Zeitreihen speichern (pro Ensemble + ALL)\n",
    "    save_ensemble_predictions(\n",
    "        y_true=res[\"y_true\"],\n",
    "        ens_preds=ens_series,\n",
    "        save_dir=ENSEMBLE_BASE_DIR,\n",
    "        run_name=RUN_NAME,\n",
    "    )\n",
    "\n",
    "    # RMSE-Übersicht dazu\n",
    "    out_dir = ENSEMBLE_BASE_DIR / RUN_NAME\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    df_final_rmse.to_csv(out_dir / \"ensemble_rmse_summary.csv\")\n",
    "    print(f\"[INFO] Ensemble-Outputs gespeichert unter: {out_dir}\")\n",
    "\n"
   ],
   "id": "10dae65afde5a7eb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT = /Users/jonasschernich/Documents/Masterarbeit/Code\n",
      "[INFO] Modell-Setup: I\n",
      "[INFO] Modell-Tags: ['sfm_setup_I', 'lgbm_setup_I']\n",
      "[INFO] OUTPUTS-Basis: /Users/jonasschernich/Documents/Masterarbeit/Code/outputs\n",
      "[INFO] Lade Stage-A Level-1 Daten (echte OOS für Stacking-Fit) ...\n",
      "            y_true  y_pred_sfm_setup_I  y_pred_lgbm_setup_I\n",
      "1995-03-01 -1.4157              0.4491              -0.1713\n",
      "1995-04-01  0.5222              0.5412              -0.1713\n",
      "1995-05-01  0.6494              0.5412              -0.1713\n",
      "1995-06-01 -1.1613              0.5412              -0.1713\n",
      "1995-07-01 -0.2611              0.5412              -0.1713\n",
      "[INFO] Tune Stacking-Gewichte auf Stage-A OOS ...\n",
      "\n",
      "--- Gefrorene Stacking-Gewichte ---\n",
      "y_pred_lgbm_setup_I   0.6663\n",
      "y_pred_sfm_setup_I    0.3337\n",
      "dtype: float64\n",
      "Summe: 1.000000\n",
      "[INFO] Lade Stage-B Level-1 Daten (Anwendung/Evaluierung) ...\n",
      "            y_true  y_pred_sfm_setup_I  y_pred_lgbm_setup_I\n",
      "1997-04-01 -0.3876              0.6812              -0.1721\n",
      "1997-05-01 -1.1673              0.4442              -0.8742\n",
      "1997-06-01  3.0184              0.6909               1.8490\n",
      "1997-07-01  1.2739              0.8609               1.1155\n",
      "1997-08-01 -3.2704              0.3587              -1.3252\n",
      "\n",
      "--- Finale RMSE (Stage B, kompletter OOS-Stream) ---\n",
      "                      RMSE\n",
      "Model                     \n",
      "y_pred_lgbm_setup_I 0.6387\n",
      "ENS_EWA_eta0.1      0.6764\n",
      "ENS_BG_24M          0.7859\n",
      "ENS_Stacking        1.0062\n",
      "ENS_EqualWeight     1.2187\n",
      "ENS_Median          1.2187\n",
      "y_pred_sfm_setup_I  1.8957\n"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
