{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-09T15:44:29.008233Z",
     "start_time": "2025-11-09T15:44:07.411957Z"
    }
   },
   "source": [
    "# =========================\n",
    "# Elastic Net – Tuning-Pipeline (ET-Logik)\n",
    "# =========================\n",
    "# - Ein Master-Schalter:\n",
    "#     USE_DYNAMIC_FI_PIPELINE = False -> Full FE (ifo + optionale Target-Blöcke)\n",
    "#     USE_DYNAMIC_FI_PIPELINE = True  -> Dynamic FI (rolling Feature Importance Top-N)\n",
    "# - Modell: src.models.EN.ForecastModel\n",
    "# - Grid-Erzeugung mit itertools.product (keine tiefen For-Schachtelungen)\n",
    "\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "\n",
    "# --- 1) Pfad-Setup (wie in ET.ipynb) ---\n",
    "def _locate_repo_root(start: Path) -> Path:\n",
    "    cur = start.resolve()\n",
    "    for _ in range(6):\n",
    "        if (cur / \"src\").exists():\n",
    "            return cur\n",
    "        if cur.parent == cur:\n",
    "            break\n",
    "        cur = cur.parent\n",
    "    return start.resolve()\n",
    "\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "PROJECT_ROOT = _locate_repo_root(NOTEBOOK_DIR)\n",
    "os.environ[\"PROJECT_ROOT\"] = str(PROJECT_ROOT)\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(\"PROJECT_ROOT =\", PROJECT_ROOT)\n",
    "\n",
    "# --- 2) Imports aus dem Repo ---\n",
    "from src.config import (\n",
    "    GlobalConfig,\n",
    "    DEFAULT_CORR_SPEC,    # expanding\n",
    "    EWMA_CORR_SPEC,       # ewma\n",
    "    outputs_for_model,\n",
    ")\n",
    "from src.tuning import run_stageA, run_stageB\n",
    "from src.io_timesplits import (\n",
    "    load_target,\n",
    "    load_ifo_features,\n",
    "    load_full_lagged_features,\n",
    "    load_rolling_importance,\n",
    ")\n",
    "from src.models.EN import ForecastModel  # ElasticNet-Wrapper\n",
    "\n",
    "# --- 3) Master-Schalter & Meta ---\n",
    "USE_DYNAMIC_FI_PIPELINE = False  # False => Full FE; True => Dynamic FI\n",
    "SEED   = 42\n",
    "\n",
    "if USE_DYNAMIC_FI_PIPELINE:\n",
    "    MODEL_NAME = \"elastic_net_dynamic_fi\"\n",
    "else:\n",
    "    MODEL_NAME = \"elastic_net\"\n",
    "\n",
    "outputs_for_model(MODEL_NAME)\n",
    "print(f\"Modell {MODEL_NAME} wird getunt.\")\n",
    "\n",
    "# --- 4) Daten laden ---\n",
    "y = load_target()             # ΔIP (DatetimeIndex)\n",
    "X_ifo = load_ifo_features()   # ifo features (für Full FE)\n",
    "\n",
    "FI_BASE_DIR = PROJECT_ROOT / \"outputs\" / \"feature_importance\" / \"outputs_no_missing\"\n",
    "if USE_DYNAMIC_FI_PIPELINE:\n",
    "    try:\n",
    "        X_full_lagged = load_full_lagged_features(base_dir=FI_BASE_DIR)\n",
    "        rolling_imp   = load_rolling_importance(base_dir=FI_BASE_DIR)\n",
    "        idx_fi = y.index.intersection(X_full_lagged.index).intersection(rolling_imp.index)\n",
    "        y_fi          = y.loc[idx_fi]\n",
    "        X_full_lagged = X_full_lagged.loc[idx_fi]\n",
    "        rolling_imp   = rolling_imp.loc[idx_fi]\n",
    "        print(\"Dynamic-FI Daten gefunden. Shapes:\", X_full_lagged.shape, rolling_imp.shape, y_fi.shape)\n",
    "    except FileNotFoundError as e:\n",
    "        print(\"FEHLER beim Laden der Dynamic-FI Artefakte:\", e)\n",
    "        print(\"Bitte erst die FI-Jobs laufen lassen (feature_importance.ipynb).\")\n",
    "        raise\n",
    "else:\n",
    "    # Full FE: Indizes alignen\n",
    "    idx_common = y.index.intersection(X_ifo.index)\n",
    "    y    = y.loc[idx_common]\n",
    "    X_ifo = X_ifo.loc[idx_common]\n",
    "    X_full_lagged = rolling_imp = y_fi = None\n",
    "    print(\"Full-FE Daten geladen. Shapes:\", X_ifo.shape, y.shape)\n",
    "\n",
    "# --- 5) Base-Config (wie Thesis-Policy in ET) ---\n",
    "def base_cfg_thesis() -> GlobalConfig:\n",
    "    cfg = GlobalConfig(preset=\"thesis\")  # Offizielle Splits\n",
    "    cfg.policy_window   = 24\n",
    "    cfg.policy_decay    = 0.95\n",
    "    cfg.policy_gain_min = 0.03\n",
    "    cfg.policy_cooldown = 3\n",
    "    return cfg\n",
    "\n",
    "cfg0 = base_cfg_thesis()\n",
    "\n",
    "# --- 6) Corr-Helper (wie ET) ---\n",
    "def make_corr_spec(kind: str) -> dict:\n",
    "    if kind == \"expanding\":\n",
    "        return dict(DEFAULT_CORR_SPEC)\n",
    "    elif kind == \"ewm\":\n",
    "        return dict(EWMA_CORR_SPEC)\n",
    "    else:\n",
    "        raise ValueError(\"kind must be 'expanding' or 'ewm'\")\n",
    "\n",
    "# --- 7) Grids -------------------------------------------------\n",
    "if USE_DYNAMIC_FI_PIPELINE:\n",
    "    # --------- Dynamic FI (nur Modell-HPs + n_features_to_use) ----------\n",
    "    print(\"Erstelle HP-Grid für 'Dynamic FI'...\")\n",
    "\n",
    "    N_FEATURES_TO_USE = 20\n",
    "\n",
    "    # Elastic Net HPs (Thesis-Notation):\n",
    "    alpha_list   = [0.1, 0.5, 0.9]               # -> l1_ratio\n",
    "    lambda_list  = [1e-4, 1e-3, 1e-2, 1e-1]      # -> sklearn alpha\n",
    "    weight_opts  = [{\"sample_weight_decay\": None},\n",
    "                    {\"sample_weight_decay\": 0.98}]\n",
    "\n",
    "    def build_model_grid_dynamic_fi():\n",
    "        grid = []\n",
    "        for a, lam in product(alpha_list, lambda_list):\n",
    "            base = {\n",
    "                \"alpha\": a,\n",
    "                \"lambda\": lam,\n",
    "                \"seed\": SEED,\n",
    "                \"n_features_to_use\": N_FEATURES_TO_USE,\n",
    "            }\n",
    "            for w in weight_opts:\n",
    "                hp = dict(base)\n",
    "                hp.update(w)\n",
    "                grid.append(hp)\n",
    "        return grid\n",
    "\n",
    "    model_grid = build_model_grid_dynamic_fi()\n",
    "\n",
    "else:\n",
    "    # ----------------- Full FE (ET-Logik) ---------------------\n",
    "    print(\"Erstelle HP-Grid für 'Full FE'...\")\n",
    "\n",
    "    # A) FE/DR-Listen (reduziert wie ET.ipynb)\n",
    "    corr_options = [\n",
    "        (\"expanding\", make_corr_spec(\"expanding\")),\n",
    "        (\"ewm\",       make_corr_spec(\"ewm\")),\n",
    "    ]\n",
    "    lag_candidates_list   = [(1, 2, 3, 6, 12)]\n",
    "    top_k_lags_list       = [1]\n",
    "    use_rm3_list          = [True]\n",
    "    k1_topk_list          = [100, 300]\n",
    "    redundancy_param_list = [0.90]\n",
    "    dr_options_list       = [\n",
    "        {\"dr_method\": \"none\"},\n",
    "        {\"dr_method\": \"pca\", \"pca_var_target\": 0.95, \"pca_kmax\": 50},\n",
    "        {\"dr_method\": \"pls\", \"pls_components\": 8},\n",
    "    ]\n",
    "\n",
    "    # B) EN-HPs (kompakt)\n",
    "    alpha_list   = [0.1, 0.5, 0.9]               # Mixing -> l1_ratio\n",
    "    lambda_list  = [1e-4, 1e-3, 1e-2, 1e-1]      # Penalty -> sklearn alpha\n",
    "\n",
    "    # C) Target Blocks & Weighting\n",
    "    target_block_options = [None, [\"AR1\"], [\"Chronos\"], [\"TSFresh\"]]\n",
    "    weight_opts          = [{\"sample_weight_decay\": None}]\n",
    "\n",
    "    def build_model_grid_full_fe():\n",
    "        hp_grid = []\n",
    "\n",
    "        # FE/DR-Produkt\n",
    "        fe_lists = [\n",
    "            lag_candidates_list,      # lags\n",
    "            top_k_lags_list,          # k_lags\n",
    "            use_rm3_list,             # rm3\n",
    "            k1_topk_list,             # k1\n",
    "            redundancy_param_list,    # red\n",
    "            dr_options_list,          # dr_opt (dict)\n",
    "        ]\n",
    "\n",
    "        for (corr_tag, corr_spec) in corr_options:\n",
    "            for (lags, k_lags, rm3, k1, red, dr_opt) in product(*fe_lists):\n",
    "                # gleiche kleine Einschränkung wie ET:\n",
    "                if k1 == 100 and dr_opt[\"dr_method\"] != \"none\":\n",
    "                    continue\n",
    "\n",
    "                base_fe = {\n",
    "                    \"lag_candidates\": lags,\n",
    "                    \"top_k_lags_per_feature\": k_lags,\n",
    "                    \"use_rm3\": rm3,\n",
    "                    \"k1_topk\": k1,\n",
    "                    \"redundancy_param\": red,\n",
    "                    **dr_opt,\n",
    "                    \"corr_tag\": corr_tag,\n",
    "                    \"corr_spec\": corr_spec,\n",
    "                }\n",
    "\n",
    "                for a, lam in product(alpha_list, lambda_list):\n",
    "                    base_model = {\"alpha\": a, \"lambda\": lam, \"seed\": SEED}\n",
    "                    for block_set in target_block_options:\n",
    "                        for w in weight_opts:\n",
    "                            hp = {\n",
    "                                **base_fe,\n",
    "                                **base_model,\n",
    "                                \"target_block_set\": block_set,\n",
    "                                **w,\n",
    "                            }\n",
    "                            hp_grid.append(hp)\n",
    "\n",
    "        return hp_grid\n",
    "\n",
    "    model_grid = build_model_grid_full_fe()\n",
    "\n",
    "print(\"Optimierte HP-Kombinationen:\", len(model_grid))\n",
    "print(\"Erstes HP-Set:\", model_grid[0] if model_grid else \"Grid ist leer\")\n",
    "\n",
    "# --- 8) Stage A/B Lauf (wie ET) ------------------------------------------\n",
    "if model_grid:\n",
    "    if USE_DYNAMIC_FI_PIPELINE:\n",
    "        # Dynamic FI Lauf\n",
    "        shortlist = run_stageA(\n",
    "            model_name=MODEL_NAME,\n",
    "            model_ctor=lambda hp: ForecastModel(hp),\n",
    "            model_grid=model_grid,\n",
    "            X=X_ifo,   # Platzhalter\n",
    "            y=y_fi,\n",
    "            cfg=cfg0,\n",
    "            keep_top_k_final=min(5, len(model_grid)),\n",
    "            min_survivors_per_block=max(1, len(model_grid)//4),\n",
    "            X_full_lagged=X_full_lagged,\n",
    "            rolling_imp=rolling_imp,\n",
    "        )\n",
    "        run_stageB(\n",
    "            model_name=MODEL_NAME,\n",
    "            model_ctor=lambda hp: ForecastModel(hp),\n",
    "            shortlist=shortlist,\n",
    "            X=X_ifo,  # Platzhalter\n",
    "            y=y_fi,\n",
    "            cfg=cfg0,\n",
    "            X_full_lagged=X_full_lagged,\n",
    "            rolling_imp=rolling_imp,\n",
    "        )\n",
    "    else:\n",
    "        # Full FE Lauf\n",
    "        shortlist = run_stageA(\n",
    "            model_name=MODEL_NAME,\n",
    "            model_ctor=lambda hp: ForecastModel(hp),\n",
    "            model_grid=model_grid,\n",
    "            X=X_ifo,\n",
    "            y=y,\n",
    "            cfg=cfg0,\n",
    "            keep_top_k_final=min(5, len(model_grid)),\n",
    "            min_survivors_per_block=max(1, len(model_grid)//4),\n",
    "        )\n",
    "        run_stageB(\n",
    "            model_name=MODEL_NAME,\n",
    "            model_ctor=lambda hp: ForecastModel(hp),\n",
    "            shortlist=shortlist,\n",
    "            X=X_ifo,\n",
    "            y=y,\n",
    "            cfg=cfg0,\n",
    "        )\n",
    "else:\n",
    "    print(\"Keine gültigen HP-Kombinationen gefunden, Stages übersprungen.\")\n",
    "\n",
    "print(f\"\\nDone. Check outputs/stageA|stageB/{MODEL_NAME} for results.\")\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT = /Users/jonasschernich/Documents/Masterarbeit/Code\n",
      "INFO in load_ifo_features: Renaming columns to ensure validity.\n",
      "Shapes (Setup I/II Basis): (407, 2160) (407,)\n",
      "Dynamic-FI Inputs gefunden. Shapes: (407, 2160) (407, 2160) (407,)\n",
      "\n",
      "=== Setup I (ifo-only) :: elastic_net_setup1_ifo_only ===\n",
      "Grid size: 1680\n",
      "[Stage A] Using FULL FE pipeline (Gleis 1 & 2).\n",
      "[Stage A][Block 1] train_end=180, OOS=181-200 | configs=1680\n",
      "  - Config 1/1680\n",
      "    · Month 5/20 processed | running...RMSE=16.7824\n",
      "    · Month 10/20 processed | running...RMSE=18.2129\n",
      "    · Month 15/20 processed | running...RMSE=18.7451\n",
      "    · Month 20/20 processed | running...RMSE=18.9708\n",
      "  - Config 2/1680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.548e+01, tolerance: 3.108e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    · Month 5/20 processed | running...RMSE=16.6593\n",
      "    · Month 10/20 processed | running...RMSE=18.0823\n",
      "    · Month 15/20 processed | running...RMSE=18.6121\n",
      "    · Month 20/20 processed | running...RMSE=18.8366\n",
      "  - Config 3/1680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.554e+01, tolerance: 3.108e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    · Month 5/20 processed | running...RMSE=15.5151\n",
      "    · Month 10/20 processed | running...RMSE=16.8682\n",
      "    · Month 15/20 processed | running...RMSE=17.3758\n",
      "    · Month 20/20 processed | running...RMSE=17.5889\n",
      "  - Config 4/1680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.474e+01, tolerance: 3.108e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    · Month 5/20 processed | running...RMSE=8.2350\n",
      "    · Month 10/20 processed | running...RMSE=9.1387\n",
      "    · Month 15/20 processed | running...RMSE=9.5058\n",
      "    · Month 20/20 processed | running...RMSE=9.6434\n",
      "  - Config 5/1680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.267e+01, tolerance: 3.108e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    · Month 5/20 processed | running...RMSE=1.6207\n",
      "    · Month 10/20 processed | running...RMSE=1.9438\n",
      "    · Month 15/20 processed | running...RMSE=2.1564\n",
      "    · Month 20/20 processed | running...RMSE=2.1763\n",
      "  - Config 6/1680\n",
      "    · Month 5/20 processed | running...RMSE=16.7784\n",
      "    · Month 10/20 processed | running...RMSE=18.2087\n",
      "    · Month 15/20 processed | running...RMSE=18.7408\n",
      "    · Month 20/20 processed | running...RMSE=18.9665\n",
      "  - Config 7/1680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.540e+01, tolerance: 3.108e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    · Month 5/20 processed | running...RMSE=16.6137\n",
      "    · Month 10/20 processed | running...RMSE=18.0339\n",
      "    · Month 15/20 processed | running...RMSE=18.5628\n",
      "    · Month 20/20 processed | running...RMSE=18.7869\n",
      "  - Config 8/1680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.466e+01, tolerance: 3.108e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    · Month 5/20 processed | running...RMSE=13.9620\n",
      "    · Month 10/20 processed | running...RMSE=15.2199\n",
      "    · Month 15/20 processed | running...RMSE=15.6975\n",
      "    · Month 20/20 processed | running...RMSE=15.8950\n",
      "  - Config 9/1680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.674e+01, tolerance: 3.108e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    · Month 5/20 processed | running...RMSE=2.3182\n",
      "    · Month 10/20 processed | running...RMSE=2.7982\n",
      "    · Month 15/20 processed | running...RMSE=3.0468\n",
      "    · Month 20/20 processed | running...RMSE=3.0989\n",
      "  - Config 10/1680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.899e-02, tolerance: 3.108e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    · Month 5/20 processed | running...RMSE=1.8056\n",
      "    · Month 10/20 processed | running...RMSE=1.4598\n",
      "    · Month 15/20 processed | running...RMSE=1.3583\n",
      "    · Month 20/20 processed | running...RMSE=1.2277\n",
      "  - Config 11/1680\n",
      "    · Month 5/20 processed | running...RMSE=16.7743\n",
      "    · Month 10/20 processed | running...RMSE=18.2043\n",
      "    · Month 15/20 processed | running...RMSE=18.7363\n",
      "    · Month 20/20 processed | running...RMSE=18.9620\n",
      "  - Config 12/1680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.532e+01, tolerance: 3.108e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    · Month 5/20 processed | running...RMSE=16.5569\n",
      "    · Month 10/20 processed | running...RMSE=17.9737\n",
      "    · Month 15/20 processed | running...RMSE=18.5015\n",
      "    · Month 20/20 processed | running...RMSE=18.7250\n",
      "  - Config 13/1680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.362e+01, tolerance: 3.108e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    · Month 5/20 processed | running...RMSE=11.9566\n",
      "    · Month 10/20 processed | running...RMSE=13.0913\n",
      "    · Month 15/20 processed | running...RMSE=13.5301\n",
      "    · Month 20/20 processed | running...RMSE=13.7072\n",
      "  - Config 14/1680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.661e+01, tolerance: 3.108e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 381\u001B[0m\n\u001B[1;32m    377\u001B[0m \u001B[38;5;66;03m# -------------------------\u001B[39;00m\n\u001B[1;32m    378\u001B[0m \u001B[38;5;66;03m# 8) Ausführen\u001B[39;00m\n\u001B[1;32m    379\u001B[0m \u001B[38;5;66;03m# -------------------------\u001B[39;00m\n\u001B[1;32m    380\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m RUN_SETUP_I:\n\u001B[0;32m--> 381\u001B[0m     \u001B[43mrun_setup_1\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    383\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m RUN_SETUP_II:\n\u001B[1;32m    384\u001B[0m     run_setup_2()\n",
      "Cell \u001B[0;32mIn[1], line 296\u001B[0m, in \u001B[0;36mrun_setup_1\u001B[0;34m()\u001B[0m\n\u001B[1;32m    294\u001B[0m grid \u001B[38;5;241m=\u001B[39m build_en_grid_setup12(BUDGET_LEVEL, include_target_blocks\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    295\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGrid size:\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mlen\u001B[39m(grid))\n\u001B[0;32m--> 296\u001B[0m shortlist \u001B[38;5;241m=\u001B[39m \u001B[43mrun_stageA\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    297\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    298\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel_ctor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mhp\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mForecastModel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhp\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    299\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel_grid\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgrid\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    300\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_ifo\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    301\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    302\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcfg\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcfg0\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    303\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# Stage-A Halving-Parameter (skaliere ruhig mit Gridgröße)\u001B[39;49;00m\n\u001B[1;32m    304\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkeep_top_k_final\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mmin\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mmax\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mgrid\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    305\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmin_survivors_per_block\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mmax\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mgrid\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    306\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    307\u001B[0m run_stageB(\n\u001B[1;32m    308\u001B[0m     model_name\u001B[38;5;241m=\u001B[39mmodel_name,\n\u001B[1;32m    309\u001B[0m     model_ctor\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m hp: ForecastModel(hp),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    313\u001B[0m     cfg\u001B[38;5;241m=\u001B[39mcfg0,\n\u001B[1;32m    314\u001B[0m )\n\u001B[1;32m    315\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDone: outputs/stageA|stageB/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/Masterarbeit/Code/src/tuning.py:482\u001B[0m, in \u001B[0;36mrun_stageA\u001B[0;34m(model_name, model_ctor, model_grid, X, y, cfg, keep_top_k_final, min_survivors_per_block, X_full_lagged, rolling_imp)\u001B[0m\n\u001B[1;32m    479\u001B[0m target_block_set_eff \u001B[38;5;241m=\u001B[39m hp\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtarget_block_set\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    480\u001B[0m hp_corr \u001B[38;5;241m=\u001B[39m hp\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcorr_spec\u001B[39m\u001B[38;5;124m\"\u001B[39m, cfg\u001B[38;5;241m.\u001B[39mcorr_spec)\n\u001B[0;32m--> 482\u001B[0m lag_map, _, D, taus \u001B[38;5;241m=\u001B[39m \u001B[43mselect_lags_per_feature\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    483\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mI_t\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mI_t_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mL\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mL_eff\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtopk_lags_eff\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcorr_spec\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhp_corr\u001B[49m\n\u001B[1;32m    484\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    485\u001B[0m X_eng \u001B[38;5;241m=\u001B[39m build_engineered_matrix(X, lag_map)\n\u001B[1;32m    486\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_rm3_eff: X_eng \u001B[38;5;241m=\u001B[39m apply_rm3(X_eng)\n",
      "File \u001B[0;32m~/Documents/Masterarbeit/Code/src/features.py:224\u001B[0m, in \u001B[0;36mselect_lags_per_feature\u001B[0;34m(X, y, I_t, L, k, corr_spec)\u001B[0m\n\u001B[1;32m    221\u001B[0m r_y_eff_masked \u001B[38;5;241m=\u001B[39m r_y_eff[x_mask]\n\u001B[1;32m    222\u001B[0m D_eff_masked \u001B[38;5;241m=\u001B[39m D_eff[x_mask, :]\n\u001B[0;32m--> 224\u001B[0m r_x_eff \u001B[38;5;241m=\u001B[39m \u001B[43m_residualize_vec\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_eff\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mD_eff_masked\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    225\u001B[0m sc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mabs\u001B[39m(pw_corr(r_x_eff, r_y_eff_masked, corr_spec))\n\u001B[1;32m    226\u001B[0m lag_scores\u001B[38;5;241m.\u001B[39mappend((sc, lag))\n",
      "File \u001B[0;32m~/Documents/Masterarbeit/Code/src/features.py:34\u001B[0m, in \u001B[0;36m_residualize_vec\u001B[0;34m(v, D)\u001B[0m\n\u001B[1;32m     30\u001B[0m     ones \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mones((\u001B[38;5;28mlen\u001B[39m(taus), \u001B[38;5;241m1\u001B[39m), dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mfloat\u001B[39m)\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mconcatenate([ones, y_lag1\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m)], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m---> 34\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_residualize_vec\u001B[39m(v: np\u001B[38;5;241m.\u001B[39mndarray, D: np\u001B[38;5;241m.\u001B[39mndarray) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m np\u001B[38;5;241m.\u001B[39mndarray:\n\u001B[1;32m     35\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Residualisiere Vektor v auf Nuisance-Matrix D via OLS.\"\"\"\u001B[39;00m\n\u001B[1;32m     36\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(v) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m D\u001B[38;5;241m.\u001B[39msize \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
